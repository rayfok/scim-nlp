{"paper_id": "uist-4", "sentences": ["Todays smartphones enable a wide range of functionalities.", "At present, most of the devices rely on touch as the primary input approach.", "However, simply tapping on the screen with a ngertip lacks expressivity.", "Given the limited screen size and hierarchical UI layouts, reaching a desired item often requires multiple steps of sliding and clicking.", "In addition, interactions can be more inconvenient when the users hands are occupied (e.g. holding a cup of coffee, wearing gloves in winter, etc.).", "In order to augment the input ability on a mobile device, several approaches have been explored previously, such as onscreen gestures [35, 1], keyboard shortcuts [32, 2], and extending the input space to the edge [7], back [49, 5], and above area [20, 9] of the device.", "Unfortunately, these gesture-based approaches suffer from one or more of the following issues: gesture designing, scalability of the gesture set, and gesture learning and memorizing.", "On the other hand, voice input is an alternative channel that offers rich expressivity and enables always-available interaction.", "However, voice recognition can be easily affected by ambient noise and people do not use it in many circumstances due to the privacy concerns [40].", "Lip interaction; silent speech; mobile interaction; touch-free; semantic gesture; vision-based recognition.", "In this paper, we introduce Lip-Interact, which enables users to access functionality on the smartphone by issuing silent speech commands (Figure 1).", "Lip-Interact repurposes the devices front camera to capture the users mouth, segment silently speaking sequences and recognize lip movements into", "Author Keywords", "CCS Concepts", "Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for prot or commercial advantage and that copies bear this notice and the full citation on the rst page.", "Copyrights for components of this work owned by others than ACM mustbehonored.", "Abstractingwithcreditispermitted.", "Tocopyotherwise,orrepublish, to post on servers or to redistribute to lists, requires prior specic permission and/or a fee.", "Request permissions from permissions@acm.org.", "UIST 18, October 1417, 2018, Berlin, Germany", "Human-centered computing  Interaction techniques;", "ISBN 978-1-4503-5948-1/18/10..", "DOI: https://doi.org/10.1145/3242587.3242599", "The goal of Lip-Interact is to provide a simple, yet powerful approach to issuing commands on the smartphone.", "Compared with search-and-click-based touch interaction, Lip-Interact is essentially a kind of gesture (where the user performs one of a set of dened actions to express the input intention), thus enabling efcient one-step functionality access.", "Meanwhile, because the \"gestures\" in Lip-Interact are based on the natural language, it also avoids many limitations of conventional gesture input, such as the goodness of gesture-command mapping, the scalability of gesture set and the learning cost.", "Finally, in contrast to general audible voice input, the main difference is that Lip-Interact commands are silent and recognized by the camera.", "Therefore, the interaction is immune to ambient noise and largely alleviates the issues surrounding personal privacy and social norms in public environment.", "commands by a deep-learning-based image sequence recognition technology.", "For example, to take a sele, a user can simply mouth the verbal command \" open camera \" to directly launch the app in one step instead of searching for it manually, and then mouth \" capture \" to trigger the shutter button rather than reaching it with the unstable thumb and causing the picture to blur.", "Also, a user can issue commands such as: \" home \", \" back \", \" screenshot \", \" ashlight \" and so on to easily control the devices settings.", "One of the main challenges when designing interfaces for touch-based mobile devices is the limited size of the display.", "Touch on GUIs is straightforward but may require a lot of search and multiple operations to reach the desired item [13].", "To enhance the smartphones input ability, researchers have explored access to functionalities through gestures [33, 2, 31, 8, 34, 1].", "Gestures can be very useful on small command sets [48].", "However, with larger sets, the design and the scalability of the gesture set, the effort required to learn and memorize it limit its widespread use.", "A silent speech interface (SSI) [16] is a system that allows speech communication without using the sound made when people vocalize their speech sounds.", "Researchers have used various sensors (e.g. magnetic [17], EEG [39], EMG [46, 26], ultrasound imaging [18, 22] and non-audible murmur (NAM) microphone [36, 21]) to detect tongue, facial, throat movements and recover the speech content.", "Brumberg et al.", "[6] used an intracortical microelectrode brain computer interface (BCI) to predict users intended speech information.", "Hueber et al.", "[22] adopted a customized helmet where an ultrasound transducer was locked at a xed position beneath the chin while an optical camera was xed in front of the mouth.", "Features extracted from the two image sources were used for recognition.", "Recently, Kapur et al.", "[26] presented a wearable interface: AlterEgo, on which ve EMG sensors were carefully placed above the face to capture the neuromuscular signals.", "The key difference between AlterEgo and previous SSIs is that their system works even when the user does not open the mouth.", "However, these prior works all use an invasive setup, impeding the scalability of these solutions in real-world scenarios.", "Multimodal interfaces process two or more combined user inputs to create new interaction possibilities, such as Pen+Voice [15] and Gaze+Touch [38].", "Multimodal interfaces can support more exible, efcient and expressive means of humancomputer interaction [14], especially in mobile interaction when mobility may cause temporary disability and the user is unable to use a particular input [37].", "A successful example is voice assistant, which is being integrated into modern smartphones, such as Googles Assistant [19] and Siri [3].", "Users can instruct the assistant to open apps, tap buttons and access specic settings without touching the screen.", "Although voice interaction is accurate and efcient, in our pilot survey of 15 users, only one user occasionally uses voice assistant to set calendar and another two users use speech for text input.", "All of them concerned about privacy issues (i.e. \"I dont want my interactions to be observed by others in my immediate surroundings\") and social norms (i.e. \"my voice may disturb the surrounding environment\"), especially in public environments [40].", "Lip-Interact moves one step further by keeping the external form of voice interaction but not vocalizing any sound.", "Therefore, Lip-Interact is expected to be less noticeable and be able to largely increase users privacy.", "Lip-Interact intersects with three key literatures: gesture interaction, voice input and silent speech interfaces.", "The concept of silent speech is not new.", "Previous work has studied silent speech interfaces, but mainly focusing on sensing technologies.", "Most of the solutions attached additional sensors, for example on a helmet [22], facemask [26], or neckband [16].", "To our knowledge, none has studied to use the on-device front camera to combine silent speech with the smartphone as a command input approach.", "We deem this to be a promising setup for practical use.", "We also for the rst time study the feasibility of Lip-Interact from three aspects:", "(1) Design and Implementation .", "We discuss the design principles and present a set of interface mechanisms that support novice learning, visual feedback and online model personalization.", "We describe algorithms that automatically segment the mouth image sequences and recognize the commands with an end-to-end deep learning model.", "We nally implement a working Lip-Interact system that allows users to operate the smartphone in real time.", "(2) Accuracy .", "We collect silent speech data of 44 commands from 22 participants.", "The commands cover both system-level functions (launching apps, system quick settings, and handling pop-up windows) and applicationlevel ones ( Notepad and WeChat ).", "Results show that for a context-based set of around 20 commands, the mean recognition accuracy is 95 .", "4% for user-independent setting and can reach 98 .", "9% for user-dependent setting.", "(3) Evaluation .", "With two controlled experiments, we show that Lip-Interact provides a more efcient and stable way of accessing functionality on a smartphone than touch, especially for single-handed input.", "In comparison with audible voice input, participants report signicantly higher levels of agreement for Lip-Interact on privacy and social acceptance.", "With the recent advance of computer vision technologies, lipreading from vision has achieved signicant improvement", "With the development of computer vision technology, the front camera on mobile devices has enabled a variety of new features, such as sele beautication, face-based AR animation and face unlock.", "Lip-Interact offers users an opportunity to use the camera to \" actively \" interact with the device.", "The user silently issues commands by mouthing the verbal commands but not vocalizing the sound.", "The camera recognizes the commands, and the system triggers corresponding functionalities.", "Before implementing the Lip-Interact system, we rst describe several key design principles of the technique.", "With Lip-Interact on a smartphone, the user should be clearly informed about commands that are currently available.", "When a feature is exposed to a user for the rst time, a oating window is displayed around the icon with its command words on it (Figure 3.a).", "When the system detects that the user is issuing commands, a real-time visual indicator appears at the top of the screen (Figure 3.b).", "Recognition results will be displayed at the indicators location for two seconds after the user nishes issuing a command.", "If the result is incorrect, the user is allowed to tap it and assign it to the correct class to improve the recognition model in subsequent use.", "The commands silently spoken by the user must be recognized accurately and robustly.", "A false-positive error in mobile interaction can be annoying to users and requires heavy effort to undo.", "However, silent speech recognition has intrinsic limitations.", "There are two main reasons for this.", "First, several phonemes often look the same (from human eye or sensing signals) when produced in general speech.", "This leads to a low recognition accuracy in general sentence lip reading with only a 50.2% word error rate [11], which is unusable for an interactive input system.", "Second, in everyday conversation people do very little or even no mouth movement so that the amount of information presented is not sufcient for recognition.", "This exacerbates the problem of low recognition accuracy.", "In order to make silent speech truly usable on a smartphone, we add the following two design constraints:", "through deep learning methods [45, 12, 11, 4].", "We see this as a great opportunity to apply silent speech on mobile devices to expand the interaction channel and improve user experience.", "When the user is operating a smartphone, the front camera is a natural sensor to capture the motion of the mouth.", "Different from previous lip-reading researches that use recorded video or news as the dataset, we validate the feasibility of Lip-Interact by collecting data and evaluating the system when users are actually using the smartphone.", "We also improve the recognition model with Spatial Transformer Networks [24] to solve the variability of mouth orientation in the mobile context.", "Since touch is straightforward and performs well in many contexts on mobile devices, the goal of Lip-Interact is to offer users an alternative based on their current cognitive and motor conditions when touch is inferior.", "In addition, Lip-Interact can also work together with touch to enable a more efcient and uent user input experience.", "For example, a user may prefer to type with ngers while using Lip-Interact for fast text editing (e.g. bold, highlight, undo, etc).", "Please note that in this work, we cannot cover all the functionalities on smartphones in Lip-Interact because of their immense quantity, especially the built-in features of various apps.", "To evaluate the feasibility of Lip-Interact, we selected 44 popular commands (including those for two representative apps) to collect data, implement system and conduct user studies.", "Such process and implementation can be easily generalized to other command sets.", "We will describe the details of the commands and their elicitation process in the next section.", "lip movements.", "Please note that the required exaggeration is still within a normal speaking range.", "Users only need to mouth the command by thinking that their lip movement can present each syllable clearly.", "Figure 2 illustrates how Lip-Interact is integrated into smartphone usage.", "Lip-Interact is context aware: covering different aspects of functionality when using different applications.", "The system identies the current state and uses the corresponding model to recognize users input.", "When on the homescreen or on the recent-applications interface, the user can open a desired app by issuing e.g., \" open camera \".", "Within a specic app, the supported functions are determined by the app itself.", "For example, after entering Camera , the user is allowed to issue \" sele \" to reverse the camera, \" video \" to switch the shooting mode, and \" capture \" to trigger the shutter button, etc.", "When a message arrives or a dialog pops up, the user can easily process them by issuing \" reply \", \" mark as read \", \" cancel \", etc.", "Besides the features specially supported by the current context, the user is allowed at any time to access universal system functionalities such as \" home \", \" back \", and \" screenshot \".", "Users are instructed to issue commands in a more \"standard\" way than when they are casually talking by exaggerating their", "Lip-Interact only considers short and visually distinguishable commands rather than long sentences such as those in a conversational system.", "This also allows users to have quick access to functionalities since most of the functionalities on mobile devices are discrete.", "Concise and Differentiable Commands", "Properly Exaggerating Lip Movements", "To implement the Lip-Interact prototype, we equipped a smartphone (Huawei P9 Plus with a 5.5 inch screen running Android 7.0) with a 720p/30-fps camera at the top (see Figure 5.a).", "The camera was connected to a computer which ran the image processing and neural network classier.", "The computer and the smartphone communicated over local network to share interface information and send commands in real time.", "Although introducing some latency, this setup afforded us a exible framework for faster prototyping.", "However, with full access to a cutting-edge devices camera and neural processing unit, it seems likely that Lip-Interact could be realized on a real product with no additional computing resources.", "is a common mobile activity, and we hoped to learn how LipInteract can assist touch and improve the experience on some tasks where touch could be limited (e.g. undo/redo, adjust cursor position).", "We developed the Notepad app (3.b) by ourselves which supported basic text editing functionalities.", "For both apps, we elicited the most frequently-used functionalities as above.", "Figure 4 shows the nal command set in Chinese and the corresponding English translation.", "We used Standard Chinese as the experiment language to facilitate data collection and user evaluation locally.", "The command set was determined through a user-elicitation study with 15 participants.", "Each participant was asked to list his/her most frequently-used mobile apps, system settings, and actions to handle pop-up messages and dialogs.", "For each category, we calculated the average ranking of every item across participants and selected the top results into the nal command set.", "The frames from the front camera are processed with the DLib face detector [29].", "In each frame, the method of Kazemi and Sullivan [27] is used to identify the facial landmarks, 20 of which describe the feature points of the mouth (Figure 5.b).", "The Opening Degree ( OD ) of the mouth is measured by the distance h between the upper and lower lips divided by the distance w between the left and the right corners of the mouth.", "Our recognition method built on the latest research [4, 12] on lip reading in computer vision and was improved to adapt to", "We also chose two representative apps for evaluation: WeChat 1 and Notepad .", "WeChat is a multi-purpose social media mobile app and the largest app by active users in China.", "WeChat has a wide range of functionalities including messaging, moments (a social feed of friends updates), payment services, etc.", "To access frequently-used features, users often need to tap and swipe multiple times or choose from a hierarchical menu (3.a).", "We selected Notepad as the second app because text editing", "To segment the command issuing sequence, an online sliding window algorithm [28] is used to to detect and transfer between the following four states: begin speaking, continue speaking, stop speaking and other (Figure 5.c).", "Within each sliding window, seven statistical features of OD are calculated: current value, sum, mean, max, standard deviation, number of frames between max and min, and absolute energy .", "If and only if all of these features satisfy certain thresholds (learned from training data with a C4.5 decision tree [41]), the algorithm decides whether or not to remain in the current state or move to the next state.", "For per frame between begin speaking and stop speaking , an afne transformation is applied based on the lip landmarks to extract a mouth crop image of size H  W = 100  80 pixels (Figure 5.b).", "The RGB channels of the mouth images over the speaking interval T are normalized to have zero mean and unit variance, forming a T  H  W  3 input for the next step of command recognition.", "1 https://en.wikipedia.org/wiki/WeChat", "The output frames of each Spatial Transformer module are concatenated along the time dimension, forming a T  H  W  3input for the following 3  (3D Convolutions, 3D maxpooling, spatial dropout) layers.", "3D convolutional networks are more suitable for spatiotemporal feature learning than 2D convolutional networks [44, 25].", "The features extracted by the convolutional nets are then attened and passed into two bidirectional Gated Recurrent Units (GRU) [10] for the modelling of dynamics.", "Finally, the output at the last time-step of the second GRU is followed by a fully connected layer with a softmax function to predict the lip-command class.", "The architecture starts with a Spatial Transformer network [24] on each input frame whose dimension is H  W  3.", "The Spatial Transformer (ST) is a learnable module which has the ability to spatially transform feature maps, allowing the model to learn invariance to rotation.", "Unlike conventional lip-reading tasks [47, 4, 12] where the mouth position is relatively xed, for Lip-Interact in smartphone use, the orientation between the user and the camera may vary each time a command is issued, and may even change while the user issues a single command.", "Our spatial transformer module uses bilinear sampling and a 16-point thin plate spline transformation (TPS) with a regular grid of control points as the transformation function to solve relative mouth positioning towards the camera.", "The localization network inside the module is a two-layer CNN (32 and 64 lters respectively) + one fully connected layer (512 units).", "Table 1 summarizes the hyperparameters of the recognition model.", "The number of frames T is set to 70 (  2.33s).", "Longer image sequences are truncated and shorter sequences are padded with zeros at the end.", "We use the ReLU activation function and batch-normalize [23] the outputs of each convolution layer.", "Dropout [43] of 0.5 is applied after each max-pooling layer.", "The models are trained end-to-end by the Adam optimizer [30] with the multinomial cross entropy loss and a batch size of 32.", "The learning rate is initially set to 10  3 and scheduled to decrease to 10  5 over time.", "Lip-Interact in mobile interactions.", "Figure 6 illustrates our deep-learning architecture, combining the steps of spatial transformation, representation learning and dynamic modelling into a single end-to-end model.", "After the recognizer returns the result, a vocal check is applied to distinguish Lip-Interact from users normal speaking.", "For example, talking to other people while using the device will also result in mouth movement but should not be detected as issuing a Lip-Interact command.", "As a counter-example, Figure 7 shows the analog audio signal from the devices microphone when a user speaks \" open WeChat \" in a dining room.", "We rst apply a band-pass lter on the audio signal to remove part of the background noise, and then calculate the peaks (syllables) of the signal.", "If the number of the syllables does match the command words of the recognition result, it is decided that the user is not using Lip-Interact.", "Our implementation on the smartphone uses Android Accessibility Service 2 .", "The service runs in the background and retrieves window content in real-time.", "It provides a layout", "2 https://developer.android.com/training/accessibility/service.html", "Participants were rst given a short introduction to our task.", "At the beginning of each block, the participant tapped the START button on the devices screen to start the task.", "Then the participant repeated the command 28 times: the rst three times in normal audible speaking manner and the last 25 times in the Lip-Interact manner.", "A circular view on the devices", "tree in which each node gives information (e.g. content, size, position, possible actions) about a window element.", "We use this service to monitor the state of the device, set the suitable recognition model and automatically perform input actions (e.g. tapping on a view).", "As described previously, we also create system-level oating windows to guide novice to use Lip-Interact and provide real-time visual feedbacks.", "We conducted the experiment in a laboratory space with participants sitting or standing comfortably (Figure 5.a) near a window.", "We recorded participants mouth image sequences of issuing silent speech commands using the system described above.", "Each participant completed 44 blocks.", "Each block corresponded to one of the 44 commands listed in Figure 4.", "During the whole data collection process, participants experienced varied lighting conditions: bright and cloudy daylight, natural indoor light and lamplight in the evening, etc.", "We were trying to make the data diverse and the result representative.", "screen showed the progress: red indicated that the participant was issuing a lip command with signicant mouth movements, while green indicated the other states.", "During the experiment, the participant was asked to hold the phone as he or she normally would in everyday use.", "To increase the data diversity, the participant was also instructed to randomly change the orientation between the face and the device within a certain range each time before issuing a command.", "A one-minute break was scheduled between blocks.", "The whole experiment took around 90 minutes.", "We recruited 22 participants (12M/10F, P1-P22), aged between 20 and 28 years ( M = 24.5).", "All were full-time undergraduate and graduate students on campus.", "Participants rated their level of previous experience with speech interaction at 2.36 ( SD = 0 . 79) on a 1 to 5 scale (no experience to very experienced).", "Table 2 summarizes the overall classication accuracies of the four groups.", "On average, the accuracy of leave-one-subject-out was 95 .", "464%, indicating that our system could accurately identify even a new users commands.", "Looking into the  4 .", "54% misclassied samples, we found that these errors were not evenly distributed in different classes.", "Instead, the common", "The computing is conducted on a host with CPU of Intel Core i7 4.20 GHz  8 and GPU of GeForce GTX 1080 Ti.", "The length of the sliding window for segmenting image sequences is set to 7.", "The system has an overall latency of 7/30s SEGMENTING + 0.0362s RECOGNIZING + 6ms NETWORK  0.275s.", "The goal of our rst study was to verify the feasibility of using Lip-Interact on a mobile device.", "We collected data and examined the recognition performance.", "Before feeding the data to our model, we augmented the dataset by applying a horizontally mirrored transformation on the mouth crop images.", "In total, there were 48,335 command samples, with at least 1,092 samples for a single command.", "Of the 22 participants, the samples of one participant were retained as the validation data for evaluating the model, and the samples of the other 21 participants were used as the training data.", "The cross-validation process was repeated 22 times, and the accuracies were averaged to produce the nal result.", "This experiment is a predictor of the real-world performance when a user uses Lip-Interact for the rst time.", "For training and evaluation, we divided the 44 commands into four groups based on the principle of [ system functionality + current context ].", "The four groups were SH (20), SW (19), SN (19), and SP (16), where S denotes systems global functions, H denotes homescreen app-launching, W / N denotes WeChat / Notepad s built-in features and P denotes actions to respond to pop-up messages and dialogs (see Figure 4).", "The numbers in parentheses indicate the number of commands in the group.", "We performed model training and evaluation on each group.", "We quantied the exaggeration of lip movements by comparing the Maximum Mouth Opening Degree ( MMOD ) of the \"exaggerated\" silent speech vs. normal audible speech when the participants were issuing the same commands.", "On average, MMOD increased by only 7% when participants were issuing silent speech commands.", "All participants understood the \"exaggerating lip movements\" requirement after we explained the reason and felt comfortable throughout the experiment.", "This section evaluates recognition accuracy across time to simulate real-world scenarios when the pre-trained model improves as the number of uses increases.", "For each participant, we denoted the pre-trained leave-her/him-out model as M 0 and all of her/his samples as S 0 .", "For each time t , a sample was randomly selected from each class in S t .", "The parameters of M t were updated with the selected samples, forming the new model M t + 1 , which was then evaluated by the remaining samples S t + 1 of the participant.", "The models were updated with the batch size of 2  the number of classes and with the epoch of 30.", "The other settings were the same as those in the implementation section.", "Each participant was rst exposed to a practice session.", "The participant was given two minutes to get familiar with the GUI and touch interactions on the device.", "Next, the participant was instructed to traverse all the functionality of Lip-Interact.", "The prompt oating window was displayed for learning.", "For each function the participant met, he or she was asked to issue the lip command once.", "This data was used later to update the pre-trained models for personalization.", "Finally, the participant was asked to remember the task contents.", "The experiment was conducted in a laboratory space with participants sitting comfortably.", "Each participant was asked to complete a series of interaction tasks on the smartphone under three input conditions : Lip-Interact, touch operation with two hands, and touch operation with one hand.", "Figure 9 shows the whole interaction task.", "The task simulated daily smartphone usage, including 22 of the 44 functionalities supported by our Lip-Interact system.", "The order of the three conditions were counter-balanced across participants.", "The above results verify the feasibility of Lip-Interact from two aspects.", "(1) On a limited set of mobile interactions, the commands issued by users through silent speech can be distinguished accurately by vision-only methods.", "Our deep learning model has sufcient generalization ability for new users with a recognition accuracy of over 95%.", "(2) The model is expected to have a strong learning ability in real-world scenarios, since smartphones are usually used by only a single user.", "Figure 8 shows the results.", "The classication accuracies of all four groups improved signicantly as the number of updates increased, reaching 99.22%, 99.21%, 98.37% and 99.11% respectively at the 6th update.", "The accuracies increased the most at the 1st update with an average improvement of 1.74%.", "For P4, the classication accuracy of SW raised to 98.78% after the 1st update and nally reached 99.40%.", "The results showed that Lip-Interact could quickly learn and personalized the model as users made more use of it.", "situation for a participant was that the recognition of a command was either almost entirely correct or almost entirely wrong.", "For example, the classication accuracy of SW of P4 was 96.625%.", "Among the 19 commands, 18 could be accurately recognized.", "But for the command \" Like \", 25 of the 47 samples were misclassied into \" Bluetooth \".", "Current smartphones use buttons, icons and menus to trigger functionality because they are easy to perceive and use.", "This experiment examines the interaction performance of LipInteract on a smartphone, with a focus on efciency in comparison with general touch.", "Research questions include:", "We recruited 10 right-handed participants (P1-P10, 5M/5F), aged between 22 and 30.", "None had participated in the previous data-collection experiment.", "The interaction task in Study 2 consists of 24 subtasks.", "Please Note that some of the subtasks contain two steps of operation (e.g. #18: place the cursor & paste, #19: select a word & bold).", "In such cases, the input time of the second operation is calculated from the completion of the previous one.", "The participant was then exposed to the experimental session.", "For each input condition , the participant consecutively completed three times (blocks) of the interaction task.", "In each block, the experimenter advanced the task by controlling a sounder.", "The \"Di\" sound from the experimenter was used as the starting signal for the current subtask.", "Upon hearing it, the participant was asked to complete the subtask as quickly as possible and then wait for the next sound.", "In the experimental session, the prompt window was not displayed.", "Table 4 lists participants quantitative rating of overall input easiness for the three input conditions , from strongly disagree 1 to strongly agree 5.", "An analysis using Friedman test showed that for our tasks participants reported signicantly stronger agreement for Lip-Interact than the two touch conditions on input easiness ( p = . 00015,  2 r = 17 . 64).", "Table 3 shows the mean input time of accessing the seven types of functionality under three input conditions .", "For each interaction type, the input time was signicantly affected by input condition ( Type I: F 1 , 29 = 4 . 9 , p < . 05; Type II: F 1 , 29 = 41 . 9 , p < . 0001; Type III: F 1 , 29 = 85 . 6 , p < . 0001; Type IV: F 1 , 29 = 30 . 3 , p < . 0001; Type V: F 1 , 29 = 9 . 34 , p < . 01; Type VI: F 1 , 29 = 13 . 7 , p < . 001).", "On average, participants spent less time with Lip-Interact on all interaction types except for Type V .", "Lip-Interact increased input speed the most for Type II , Type III and Type IV , with an improvement of 26 .", "05% compared to touch with two hands and 46 .", "In particular, participants enjoyed input with two channels: touch + Lip-Interact together in the Notepad app.", "P2 said \" It felt like reading incantations. I did not have to select the command from the menu every time so that I could concentrate on the text itself \".", "Two of the participants (P2, P4) reported that they took advantage of the parallelism of the two channels to speed up interaction pairs.", "P4 commented: \" For the task of selecting a word and then highlight/bold it, I initially performed the two steps in sequence in the rst block. But since using Lip-Interact always took some time, in the next blocks, I tried to start issuing the command before I nished the selection. It is faster .\"", "We calculated the whole input time from the beginning of the word selection to the end of marking it.", "The cases using Lip-Interact in parallel (2.37s) were 22 .", "8% faster than using Lip-Interact sequentially (3.06s).", "A total of 735 valid instances were collected.", "For the segmentation of the silent speech sequence, the recall was 99.18%, and the precision was 99.59%.", "For the command recognition, the mean accuracy was 97.9%.", "Lip-Interact also had the smallest standard deviation of input time on all interaction types, showing that Lip-Interact provided a more stable and dependable way to access functionality.", "The efciency of common touch interaction was strongly inuenced by the target location and user familiarity.", "We measured input time in seconds to quantify the efciency.", "For each functionality access, input time was dened as the time interval from the starting signal (or the end of the last operation) to the time when the device began to respond to the user input.", "For analysis, we divided the tasks into six types based on their touch interaction properties.", "These types were:", "All participants expressed that Lip-Interact was easy to understand and learn.", "P3 commented that \" I could remember all the commands right after the practice session. These commands are concise and intuitive. \" Six participants expressed surprise at the accuracy of the recognition.", "P9 said \" I had never thought these things could be identied. When I rst silently spoke the command and saw the correct response, It felt really good. \"", "compared to touch with one hand.", "These tasks generally require multiple steps of touch operations to complete.", "We collected a total of 90 blocks of task (10 participants  3 input conditions  3 replications).", "For each task type, we ran a one-way repeated-measures ANOVA for input condition .", "Type II : Accessing between pages across different levels of the hierarchy.", "This often happens within an app (e.g. from the current page, perform several \" back \" actions, then navigate to enter a new page, and nally access the desired functionality).", "Type III : Opening a menu and selecting a command.", "Type I : Accessing between multiple pages at the same level of the hierarchy (e.g. on the home screen, scroll left and right to locate and then tap to launch an app).", "The denition of each input type was determined based on the participants actual operation, which was recorded on video and labelled manually later.", "Input Time", "Type VI : Single tap out of the comfortable nger range (e.g. tap the back button in the upper left corner).", "Type VII : Precise pointing which is difcult for touch because of the \" fat nger \"problem [42] (e.g. adjust a cursor in text).", "Type V : Single tap within the comfortable nger range (e.g. tap the home button).", "Type IV : Accessing a functionality on the Quick Settings Dropdown panel (e.g. ashlight).", "The ten participants were divided into ve groups.", "Each group of two participants (referred as P a and P b ) participated in the study together.", "First, P a simulated the person using the phone, while P b simulated a stranger nearby.", "P a was asked to operate the phone rst with Lip-Interact and then with voice input.", "With each technique, P a was free to use the device for three minutes, accessing any of the functionalities that our system supported.", "Then P a and P b swapped roles and repeated the process above.", "Finally, both participants answered a 5-point Likert-style questionnaire to access their preference on three measures: Privacy , Comfort as user , and Comfort as others in the surrounding environment .", "The order of using Lip-Interact and voice input was balanced across all participants.", "The computer which powered the Lip-Interact system was put in the participants backpack.", "For the implementation of input control, we used the XunFei SDK 3 for command recognition.", "Theoretically, issuing audible commands can achieve similar results to Lip-Interact in Study 2 with a higher and more stable input speed than touch.", "The main difference is that LipInteract does not require the vocalization.", "We argue that this simple difference signicantly enhances the user experience.", "In this study, we preliminarily investigate the user preference between Lip-Interact and voice input in public environment.", "The ten participants in Study 2 were recruited again.", "When watching videos on a smartphone, the users hands are not always available.", "For example, holding the device with one hand while having meals, or waching the phone that is xed on a stand while lying down.", "In these cases, Lip-Interact should allow users to operate the interface by issuing \" play \", \" stop \", \" fast-forward \", \" rewind \", \" louder \" and \" softer \" commands.", "Finally, we encouraged participants to suggest more applications for Lip-Interact.", "We list several representative examples.", "This example application comes from a real-life experience of one of our participants.", "\" Days ago, I came out of the lab", "For Comfort as user , participants expressed two concerns about voice control.", "The rst concern was that \" making sound may disturb people around me \" (P6).", "The second concern was self-embarrassment.", "P2 said \" Every time I spoke out a command, I felt like someone else was watching me. It was strange and sometimes awkward \".", "With Lip-Interact, however, \" it was much less noticeable \".", "However, participants also thought that there was room for improvement for Lip-Interact.", "Three expressed that the mapping from command words to a single function could be n to 1.", "P5 said \" There was a time when I wanted to say back to home instead of the required home. Although I ended up successfully issuing the correct command, a more exible mapping would further improve the experience of this technology. \"", "After \" open camera \", the use can quickly switch shooting mode and settings by issuing \" photo \", \" video \", \" panorama \", \" sele \", \" reverse camera \", \" ash on/off \" lip commands instead of recalling where the buttons are.", "When the user has posed for a sele with one hand holding the device, he or she can simply mouth \"capture\" rather than awkwardly adjusting the hand and reaching it with the thumb.", "For Privacy , P4 commented that \" If there are other people around me, there is no privacy when using the voice interaction. People will know what I am doing on my device. Using the silent speech can largely protect my interaction privacy, unless others are looking at me very carefully. \"", "We chose the subway as our experimental environment.", "When taking the subway, touch is usually limited (e.g. user is holding the handrail) and there are usually many people around.", "During this study, participants issued a total of 367 Lip-Interact commands.", "For the segmentation of the silent speaking se-", "As for Comfort as people in the surrounding environment , most participants rated 3 (neutral) on voice input.", "P5 commented \" The feeling of being a passerby was related to the current environment. It did not matter in most cases, but sometimes I could not help but wonder what he or she was doing \".", "But for Lip-Interact, \" I rarely detected a noticeable difference. \".", "Video Player", "quence, the recall was 97.8%, and the precision was 97.3%.", "For command recognition, the mean accuracy was 97.5%.", "An analysis using the Friedman test showed that participants reported signicantly higher levels of satisfaction for LipInteract than for voice input on all three measures ( p = . 00157,  2 r = 10).", "The results are listed in Table 5.", "3 http://www.xfyun.cn/services/commandWord", "Lip-Interact Voice Command", "Although in our study, Lip-Interact outperformed touch-based input on most of the investigated tasks with a shorter completion time and higher input easiness, our purpose is not to substitute touch with Lip-Interact but to provide an alternative input approach.", "This is because touch-based input is still faster and more direct for many tasks (e.g. scrolling a list) and enables more complex interactions (e.g. typing).", "The use of Lip-Interact depends on the current task as well as users cognitive and motor skills.", "The advantages of Lip-Interact can be summarized as: (1) allowing for access to functionality efciently in one step, (2) providing necessary interaction ability when hands are not available, and (3) assisting touch to make device use more efcient and uent.", "In addition, Lip-Interact also has potential to be applied to other interaction platforms (e.g. accessibility, smartwatch, head-worn devices), which deserves to be further studied.", "constraints: (1) limited command set based on current context and (2) properly exaggerating the lip movements in the interaction designs as well as (3) incorporate Spatial Transformer Networks in the recognition model.", "The performance outperformed prior research which handled even smaller command sets [26, 12].", "Although the size of the command set is still limited in our work, Lip-Interact can be easy to be generalized to support other applications.", "Our empirical experience indicates that as long as the mouth image sequence of the commands can be distinguished by human eyes, the model can accurately recognize them.", "Future work should be done to try Lip-Interact on more applications.", "For the \"exaggeration\" requirement, our participants understood the necessity, and did not report any discomfort during the studies.", "At the same time, we admit that this is an interaction limitation on users.", "and intended to rent a smart shared bike.", "I was wearing gloves.", "I had to take off my gloves, scroll several times to locate the app, then tap the unlock button to scan the QR code, and nally put on my gloves again.", "\" Lip-Interact can greatly reduce such temporary disability with two simple commands: \" open Mobike \" and \" unlock \".", "For the intention recognition, at present we solve it by detecting the changes of the mouth opening degree and the audio signal.", "It worked well under our experimental conditions.", "But we do not rule out that the performance will be affected by more noise in real-life use cases.", "The algorithms need to be improved and tested in more various environments.", "To address this, we can also consider some explicit mode-switch methods, such as pressing a button or squeezing the phones edge.", "Similar methods are often used in HCI research and commercial products.", "For command recognition, the bottleneck lies in the expressivity of silent speech the information conveyed by the mouth movements.", "Our research shows high accuracy for recognizing about 20 commands.", "Future work should be done to improve the algorithm and explore the theoretical upper bound.", "Some commercial smartphones like the iPhone X are already equipped with special hardwares to ensure the robustness of face detection.", "Therefore, the robustness of the Lip-Interact system mainly relies on two factors: the robustness of recognizing the users intention to use silent speech and the robustness of recognizing the issued commands.", "This work focuses on the implementation and evaluation of Lip-Interact for smartphone, but we also foresee the potential of Lip-Interact on other platforms.", "Smartwatch has an ultrasmall screen on which UI layouts and touch interaction are more limited.", "Lip-Interact is expected to allow hands-free interaction on smartwatches with a built-in camera sensor on the front panel.", "Head-worn devices (AR/VR glasses) separate the space of displaying and the interaction interface.", "For current mainstream solutions, mid-air gestures suffer from limited size of the command set and arm fatigue, while voice input has the inherent issue about privacy and social norms.", "We envision that a tiny camera is integrated into the microphone, capturing users mouth movement and enabling Lip-Interact.", "Our implementation uses an additional mounted camera and host server for computing.", "We are trying to integrate LipInteract into a self-contained smartphone, which will reduce the response time and improve the user experience further.", "Our experiment results reect the performance of Lip-Interact in a controlled setting.", "We compared Lip-Interact with touch input on only one device.", "Different device sizes and UI designs can lead to different performance.", "This is also why we classied each input into different types and analyzed respectively.", "Besides, we have only tested the Chinese language.", "But we think Lip-Interact can be easily applied to other languages as long as the mouth movements of commands are differentiable.", "We have described Lip-Interact, a novel interaction technique that repurposes the front camera of smartphones to detect lip movement and recognize it into commands.", "Lip-Interact provides an alternative input method on smartphones with both simplicity and expressivity.", "We verify the feasibility of LipInteract by implementing a real-working prototype and conducting three experiments.", "We demonstrate that the model of a [ spatial transformer network + CNN + RNN ] architecture can accurately recognize around 20 silent speech commands with training data collected from dozens of users.", "We incorporate voice check and design visual feedback to offer an accurate, robust and friendly user experience.", "We also research on-line personalization, which conrms the potential and benet of adapting the machine learning model to end users.", "This work is supported by the National Key Research and Development Plan under Grant No. 2016YFB1001200, the Natural Science Foundation of China under Grant No. 61672314 and No. 61572276, Tsinghua University Research Funding No. 20151080408, and also by Beijing Key Lab of Networked Multimedia.", "In order to raise the recognition accuracy of silent speech to a practically usable level in a mobile input system, we add two", "Lastly, we discuss the main limitations of our work, which also points to the directions of future work.", "Improve Recognition Accuracy of Silent Speech Commands", "1. What is the advantage of Lip-Interact compared with touch interaction?", "2.Whatisthe behavior of users using Lip-Interact, and how does it change over time?"]}
