{
  "2102.09087": [
    {
      "sentence": "Touchscreen as the sole method of mobile device input is increasingly challenged by its inherent limitations.",
      "label": "Background",
      "prob": 0.9562709927558899
    },
    {
      "sentence": "The aforementioned use cases can be particularly useful in challenging situations when one-handed and non-contact interactions are preferable or required.",
      "label": "Background",
      "prob": 0.9374908208847046
    },
    {
      "sentence": "TapNet opens up new interaction opportunities such as onehanded interaction that uses off-screen tapping or designated tap gestures.",
      "label": "Background",
      "prob": 0.927699625492096
    },
    {
      "sentence": "Such additional guidance or supervision can potentially prevent over-fitting especially given few training samples.",
      "label": "Background",
      "prob": 0.9249740242958069
    },
    {
      "sentence": "Although TapNet is rather lightweight compared with vision-based convolutional networks, performing recognition per frame generates unnecessary overheads.",
      "label": "Background",
      "prob": 0.9212140440940857
    },
    {
      "sentence": "It thus indicates that IMU-based tap location recognition can be viable and useful in situations which does not require very high resolution and when capacitive sensing is inadequate (e.g. wearing gloves or under water).",
      "label": "Background",
      "prob": 0.9053282141685486
    },
    {
      "sentence": "Prior studies has focused on the recognition of a single tap property, based on a limited amount of data as a proof-of-concept.",
      "label": "Background",
      "prob": 0.9037473201751709
    },
    {
      "sentence": "These accessibility modes occupy the common on-screen gestures (e.g. swipe and touch), and their users need to learn a more complicated system navigation gestures.",
      "label": "Background",
      "prob": 0.8993501663208008
    },
    {
      "sentence": "However, a large number of filters are required to depict the fine-grained signal alignment combinations of the six-channel signals, and thus increases the model training difficulty and the demand for data.",
      "label": "Background",
      "prob": 0.8975276947021484
    },
    {
      "sentence": "It can be beneficial in situations, where one-handed interaction is preferable or even required.",
      "label": "Background",
      "prob": 0.8963229060173035
    },
    {
      "sentence": "For example, AssistiveTap exploits back tap and titling to partially address the issue of limited thumb reaching area during one-handed interaction.",
      "label": "Background",
      "prob": 0.8936628699302673
    },
    {
      "sentence": "In general, a convolutional filter in early layers describes the basic shape features, such as a peak, a valley, or a certain degree of slope.",
      "label": "Background",
      "prob": 0.8901527523994446
    },
    {
      "sentence": "tap location from force and angle changes, it can function even when capacitive sensing fails (Figure 9d).",
      "label": "Background",
      "prob": 0.8897502422332764
    },
    {
      "sentence": "Common use situations include when users are wearing gloves, having long fingernails, or when there are waterdrops on the touchscreen.",
      "label": "Background",
      "prob": 0.8855305910110474
    },
    {
      "sentence": "This high generalizability is probably because the inter-class differences (e.g. finger pad vs. nail in the finger part classification task) are generally much greater than the inter-person differences, such that the personal biomechanics only imposes a neglectable effect.",
      "label": "Background",
      "prob": 0.8802459836006165
    },
    {
      "sentence": "Multi-task learning contributes to tap direction classification, especially with a small amount (no more than 3K) of training samples.",
      "label": "Background",
      "prob": 0.8762245774269104
    },
    {
      "sentence": "Off-screen tap recognition makes it possible to interact with objects living in different interface layers, such as background targets that do not react to on-screen touch.",
      "label": "Background",
      "prob": 0.8750761151313782
    },
    {
      "sentence": "Some of the TapNet building blocks are not novel in fields such as computer vision, but to bring them into building an interaction gesture to a practical performance level required original research.",
      "label": "Background",
      "prob": 0.8704140782356262
    },
    {
      "sentence": "Although this resolution is much less precise compared to the touchscreen, such resolution can already enlarge the interaction design space, by for example enabling users to perform selection by tapping on the back of the phone, even when they wear gloves.",
      "label": "Background",
      "prob": 0.8700175285339355
    },
    {
      "sentence": "A convolutional filter in later layers, with a large receptive field, is more likely to contain shape semantics, such as a large magnitude peak or an impulse with double peaks.",
      "label": "Background",
      "prob": 0.8673235177993774
    },
    {
      "sentence": "In contrast, TapNet is a multi-task network that gives predictions for all five tasks at a time.",
      "label": "Background",
      "prob": 0.847108006477356
    },
    {
      "sentence": "Multi-task models employ multiple loss functions thus more supervisions during training that can potentially helps learning.",
      "label": "Background",
      "prob": 0.842710018157959
    },
    {
      "sentence": "Sensor system on smartphones provides motion data in a number of formats, including the raw signal, its gravity excluded counterpart, and rotation vector.",
      "label": "Background",
      "prob": 0.8414826989173889
    },
    {
      "sentence": "As non-tap data does not have annotations about tap finger part, direction, and location, it cannot be used to train the rest of the network.",
      "label": "Background",
      "prob": 0.8330045342445374
    },
    {
      "sentence": "The difficulty of onehanded use and the visual occlusion by the operating finger are two of them.",
      "label": "Background",
      "prob": 0.8277772665023804
    },
    {
      "sentence": "They can back tap to change the flashcard or news feeds, or edge tap to switch a different set of them, and these can be done even on the lock screen.",
      "label": "Background",
      "prob": 0.8253999352455139
    },
    {
      "sentence": "This architecture not only shares knowledge across tap properties and devices during training, but also shares computation and memory at run time.",
      "label": "Background",
      "prob": 0.8222945332527161
    },
    {
      "sentence": "These are just a few application examples of tapping into TapNets ability to detect multiple tap properties.",
      "label": "Background",
      "prob": 0.8221480250358582
    },
    {
      "sentence": "It, therefore, solves the conflicts with system navigation gestures, and thus can be helpful for users with low vision and print disability, who need quick and temporary access to the accessibility mode.",
      "label": "Background",
      "prob": 0.8216284513473511
    },
    {
      "sentence": "The major latency (105 ms) of the whole pipeline lies in waiting to observe the complete tap signal in the feature window.",
      "label": "Background",
      "prob": 0.8064336776733398
    },
    {
      "sentence": "The risks of this strategy include the potential lack of diverse tapping patterns that a single person can not fully represent as well as the impact of the biomechanics.",
      "label": "Background",
      "prob": 0.8060689568519592
    },
    {
      "sentence": "As such, using this representation conduces to the reuse of convolutional filters and alleviates network training difficulty.",
      "label": "Background",
      "prob": 0.805236279964447
    },
    {
      "sentence": "In the implementation, training to recognize the presence of tap event requires tap and non-tap data (e.g. phone shaking and rubbing motions).",
      "label": "Background",
      "prob": 0.7888789176940918
    },
    {
      "sentence": "Different from most computer vision tasks that heavily rely on multi-person data to achieve user generalizability [12, 44], a well-performing ML model for HCI (interactive) tasks may not necessarily demand multi-person training data.",
      "label": "Background",
      "prob": 0.7867925763130188
    },
    {
      "sentence": "Copyrights for third-party components of this work must be honored.",
      "label": "Background",
      "prob": 0.7854674458503723
    },
    {
      "sentence": "Gating signal alone may not be enough for accurate recognition of tap properties, it is sufficient for tap-like (high recall low precision) event detection, and thus qualified as gating for the CNN recognition.",
      "label": "Background",
      "prob": 0.7786137461662292
    },
    {
      "sentence": "To reach the ideal performance, it becomes a must to know the person-specific information, i.e. how exactly the target user acts.",
      "label": "Background",
      "prob": 0.7769194841384888
    },
    {
      "sentence": "Multi-task learning with neural network leads to a multi-branch architecture.",
      "label": "Background",
      "prob": 0.776482343673706
    },
    {
      "sentence": "The usage of this dataset (135,260 samples including tap and non-tap) was solely in training (or teaching).",
      "label": "Background",
      "prob": 0.775713324546814
    },
    {
      "sentence": "2) multi-task learning is more data efficient, showing greater advantage particularly with a limited amount of training data;",
      "label": "Background",
      "prob": 0.773517906665802
    },
    {
      "sentence": "Finger part, direction, and location are not conditional on the event detection.",
      "label": "Background",
      "prob": 0.7708414196968079
    },
    {
      "sentence": "Therefore, TapNet requires less computation and memory than multiple networks each trained for a single task.",
      "label": "Background",
      "prob": 0.75786292552948
    },
    {
      "sentence": "TapNet employs a multi-task convoluational neural network with motion signals as primary input and phone form factor as auxiliary information.",
      "label": "Background",
      "prob": 0.7556371688842773
    },
    {
      "sentence": "In other words, AssistiveTap provides the back-of-device alternatives for the most commonly used on-screen gestures, by using the gesture combination of back tap and tilting.",
      "label": "Background",
      "prob": 0.7553301453590393
    },
    {
      "sentence": "AssistiveTap allows users to complete a number of system interactions using back tap and tilting.",
      "label": "Background",
      "prob": 0.7537125945091248
    },
    {
      "sentence": "4) established a benchmark with opensource code and datasets for off-screen tapping recognition, which will be reproducible and accessible by others.",
      "label": "Background",
      "prob": 0.7505750060081482
    },
    {
      "sentence": "This is an improvement for the visual impairment accessibility modes, such as Voice Over on iOS and Talk Back on Android.",
      "label": "Background",
      "prob": 0.7479086518287659
    },
    {
      "sentence": "TapNet, a multi-input, multioutput convolutional neural network, takes this feature vector and a device vector as input.",
      "label": "Background",
      "prob": 0.7441054582595825
    },
    {
      "sentence": "The other advantage of our approach is that an expert design could intentionally push the variations of an intentional tap gesture in terms of speed, strength, angle, and hand posture, However, it is possible certain recognition tasks, such as higher resolution tap location classification, could demand more fine-grained information only available in person-specific data.",
      "label": "Background",
      "prob": 0.7425965070724487
    },
    {
      "sentence": "1) TapNet significantly outperformed the state of the art especially in difficult recognition tasks such as tap location estimation;",
      "label": "Background",
      "prob": 0.7397472262382507
    },
    {
      "sentence": "As such, the two parts of the network (tap event v.s. the rest of the tap properties) were trained in turn.",
      "label": "Background",
      "prob": 0.7317356467247009
    },
    {
      "sentence": "To our knowledge, no attempt has been made to apply multi-task learning for off-screen tap recognition and the multi-task architecture can conduce to the learning of each tap recognition task from their interrelationship.",
      "label": "Background",
      "prob": 0.7216614484786987
    },
    {
      "sentence": "The network could simultaneously recognize a set of tap properties, including tap direction and location;",
      "label": "Background",
      "prob": 0.7189434170722961
    },
    {
      "sentence": "3) data augmentation by temporally shifting the samples conduces to the performance gain but scaling the samples does not.",
      "label": "Background",
      "prob": 0.7050370573997498
    },
    {
      "sentence": "That said, we also learned that tap location recognition relies on very subtle IMU responses, which may relate to personal biomechanics and are hard to simulate by a single person.",
      "label": "Background",
      "prob": 0.6996737718582153
    },
    {
      "sentence": "BackTap [40] and BeyondTouch [39] classified four-corner tap based on accelerometer, gyroscope, and microphone signals.",
      "label": "Background",
      "prob": 0.6988921165466309
    },
    {
      "sentence": "velocity, and they stay at zero when the phone is stationary.",
      "label": "Background",
      "prob": 0.6958338618278503
    },
    {
      "sentence": "Without adding new sensor hardware, TapNet enables many new input possibilities on smartphones.",
      "label": "Background",
      "prob": 0.691341757774353
    },
    {
      "sentence": "Neighboring region above or below the target in a 5x7 grid has an index offset of five.",
      "label": "Background",
      "prob": 0.6900993585586548
    },
    {
      "sentence": "We marked down a number of factors that may affect tapping signal responses, including finger length, finger nail length, hand size, and handedness.",
      "label": "Background",
      "prob": 0.6888283491134644
    },
    {
      "sentence": "It enables the user to utilize the bits and pieces of time for their favorite spare time activity.",
      "label": "Background",
      "prob": 0.6887674927711487
    },
    {
      "sentence": "Following the shared layers, there are branches of fully connected layers, each of which extracts property-specific patterns for individual task.",
      "label": "Background",
      "prob": 0.6885040998458862
    },
    {
      "sentence": "Although the performance improvement of SIMO over SISO is modest in this specific task, its advantages of reusing computation (for the shared layers) across recognition tasks and memory saving to avoid running multiple models on small processing units are essential.",
      "label": "Background",
      "prob": 0.6820563077926636
    },
    {
      "sentence": "4) one-channel CNN can achieve cross-channel signal alignment more efficiently than its multi-channel counterpart.",
      "label": "Background",
      "prob": 0.6814972758293152
    },
    {
      "sentence": "SISO TapNet is the truncated single-input and single-output variant.",
      "label": "Background",
      "prob": 0.6807103157043457
    },
    {
      "sentence": "Our hypothesis is that a welldesigned data collection protocol can ensure training data diversity even from one person and be sufficient for some tap recognition tasks .",
      "label": "Background",
      "prob": 0.6785712838172913
    },
    {
      "sentence": "These studies relied on simple features (e.g. mean, kurtosis, and skewness) and statistical methods typically based on shallow neural networks [8, 19, 26, 39, 40], thus only achieved limited precision of tap location detection.",
      "label": "Background",
      "prob": 0.6776313185691833
    },
    {
      "sentence": "Multi-task learning allows for good alignment between feature embeddings of different tasks.",
      "label": "Background",
      "prob": 0.6772918701171875
    },
    {
      "sentence": "Specifically, The first major peak in the accelerometer z-axis is aligned to a designated frame (=106th) in the feature vector, and this determines the feature window location.",
      "label": "Background",
      "prob": 0.6759620904922485
    },
    {
      "sentence": "1) it is low-cost and convenient for rapid development iteration,",
      "label": "Background",
      "prob": 0.675444483757019
    },
    {
      "sentence": "with phone form factor as auxiliary information and joint prediction of tap-related tasks, including tap event, direction, finger part, location classification, and the regression of tap location.",
      "label": "Background",
      "prob": 0.6740788221359253
    },
    {
      "sentence": "Despite the line of research on detecting tapping from motion signals captured by the built-in IMU sensors on smartphones [8, 26, 39, 40], there is room for improvement.",
      "label": "Background",
      "prob": 0.6696315407752991
    },
    {
      "sentence": "1) high sensor sampling rate is crucial to tap recognition accuracy;",
      "label": "Background",
      "prob": 0.667699933052063
    },
    {
      "sentence": "Unlike using the IMU, these detection methods require additional hardware installed on the already very compact mobile devices, increasing manufacturing and material cost and potentially reducing available space to the largest possible battery.",
      "label": "Background",
      "prob": 0.6649152636528015
    },
    {
      "sentence": "locality to capture signal dynamics and shared weights to reduce trainable parameters.",
      "label": "Background",
      "prob": 0.6568431854248047
    },
    {
      "sentence": "2) the use of gyroscope in our task configuration is important; and",
      "label": "Background",
      "prob": 0.6488968133926392
    },
    {
      "sentence": "Dividing the shape extraction and alignment analysis conceivably mitigates the model training difficulty and achieves an efficient use of data.",
      "label": "Background",
      "prob": 0.6446517109870911
    },
    {
      "sentence": "Inertial Touch estimates tap force from the IMU signals and tap location from the TapNet output.",
      "label": "Background",
      "prob": 0.6283679604530334
    },
    {
      "sentence": "Therefore, these signals represent the change of force on the housing of the phone and the resulting change of rotation",
      "label": "Background",
      "prob": 0.6283251047134399
    },
    {
      "sentence": "In this architecture, different tap-related tasks share four convolutional layers, which extract the common shape patterns that are indicative across tap properties.",
      "label": "Background",
      "prob": 0.6245893836021423
    },
    {
      "sentence": "Beyond research explorations, we began to see off-screen occlusion-free alternatives in mainstream products, such as double pressing power button to activate the camera, squeezing the Active",
      "label": "Background",
      "prob": 0.624426543712616
    },
    {
      "sentence": "ExplorativeTap allows for the coordination between on-screen and off-screen interactions and thus saves the need for learning additional set of on-screen gestures.",
      "label": "Background",
      "prob": 0.6157041192054749
    },
    {
      "sentence": "In practice, shared layers for tap properties also means shared computation.",
      "label": "Background",
      "prob": 0.6144141554832458
    },
    {
      "sentence": "Note that the state of the art for this topic can only be advanced if there are well-established benchmarks with accessible datasets and codebases.",
      "label": "Background",
      "prob": 0.6141870617866516
    },
    {
      "sentence": "For instance, TapNet can enable users to interact with flashcards or news feeds shown in the wallpaper (see Figure 9c).",
      "label": "Background",
      "prob": 0.6113506555557251
    },
    {
      "sentence": "It allows for joint learning on data across devices and simultaneous estimation of multiple tap properties.",
      "label": "Background",
      "prob": 0.6035399436950684
    },
    {
      "sentence": "This sheds light on the conceptual relation between model performance and ML training strategy in IMU-based input systems.",
      "label": "Background",
      "prob": 0.59644615650177
    },
    {
      "sentence": "Such temporal alignment allows the network to focus on the shape differences induced by a tap.",
      "label": "Background",
      "prob": 0.5927167534828186
    },
    {
      "sentence": "InfiniTouchrecognizedfingerlocationfromcapacitiveimageoutsidethetouchscreen[16].",
      "label": "Background",
      "prob": 0.5907609462738037
    },
    {
      "sentence": "TapNet: The Design, Training, Implementation, and Applications of a Multi-Task Learning CNN for Off-Screen Mobile Input",
      "label": "Background",
      "prob": 0.578288197517395
    },
    {
      "sentence": "For every condition, participants were asked to tap for five to ten times and take rest at various intervals to avoid fatigue.",
      "label": "Background",
      "prob": 0.5755149126052856
    },
    {
      "sentence": "A simplified TapNet can also be run in real time (9ms) on the embedding DSP using Tensor Lite for microcontroller [31], but this is beyond the scope of this paper.",
      "label": "Background",
      "prob": 0.5675341486930847
    },
    {
      "sentence": "More recently, researchers started to explore neural networks for tap location classification for PIN code inference in the field of privacy and security [17, 21].",
      "label": "Background",
      "prob": 0.5627373456954956
    },
    {
      "sentence": "In the end, the one-person data collection took over 30 sessions (around half an hour for each) over 69 days.",
      "label": "Background",
      "prob": 0.5602924227714539
    },
    {
      "sentence": "Users can use the exploration finger on the screen to glide over the on-screen objects, hear them, and perform a back tap to confirm selection.",
      "label": "Background",
      "prob": 0.5596224069595337
    },
    {
      "sentence": "In contrast, ExplorativeTap starts the accessibility mode by a double back tap, selects object by a single back tap, and exits by lifting the exploration finger.",
      "label": "Background",
      "prob": 0.5567068457603455
    },
    {
      "sentence": "SISO refersto atruncated single-inputand single-output (SISO)TapNet.",
      "label": "Background",
      "prob": 0.5558232665061951
    },
    {
      "sentence": "In practice, especially for learning-based gesture studies, it can be beneficial to identify the curve in Figure 8, and then decide the needed number of training participants for specific tasks.",
      "label": "Background",
      "prob": 0.5514890551567078
    },
    {
      "sentence": "the phone (based on the same IMU signal input to TapNet) to select gesture, and back tap to perform the selected gesture (e.g. back gesture, scrolling, app switch).",
      "label": "Background",
      "prob": 0.5504537224769592
    },
    {
      "sentence": "Conventional methods applied multi-channel CNN to describe signal alignment across channels, and it has been widely use to handle EEG [25] and IMU [36] data.",
      "label": "Background",
      "prob": 0.5496594309806824
    },
    {
      "sentence": "Together, TapNet offers a one-model-for-all solution [13] across devices.",
      "label": "Background",
      "prob": 0.5439670085906982
    },
    {
      "sentence": "Such location error is similar to the distance between two icons on the phone home screen",
      "label": "Background",
      "prob": 0.5341777801513672
    },
    {
      "sentence": "This section reviews two related concepts: multi-task learning [3] and learning with auxiliary information.",
      "label": "Background",
      "prob": 0.533638060092926
    },
    {
      "sentence": "The shared layers of all branches extract the common knowledge across tasks, whose generalizability is ensured by the regularization effect across tasks.",
      "label": "Background",
      "prob": 0.5310564041137695
    },
    {
      "sentence": "The experimenter can examine the finger alignment with the target location by turning the phone back and forth to ensure the annotation correctness.",
      "label": "Background",
      "prob": 0.5307804942131042
    },
    {
      "sentence": "Support Vector Machine (SVM) represents a line of studies [19, 39] that used traditional machine learning methods.",
      "label": "Background",
      "prob": 0.529373288154602
    },
    {
      "sentence": "1) developed a multi-task network that can be jointly trained across devices.",
      "label": "Background",
      "prob": 0.5264005661010742
    },
    {
      "sentence": "This peak detection yields a set of peaks and valleys and their corresponding timestamps.",
      "label": "Background",
      "prob": 0.5220973491668701
    },
    {
      "sentence": "This suggests that the minimal model capacity can be task-dependent; simple tasks may not be benefited from a model capacity increase, but the more complicated tasks can be.",
      "label": "Background",
      "prob": 0.5181651711463928
    },
    {
      "sentence": "If the signal passes the gating, the six-channel IMU signals within a 120-ms feature window will be concatenated into a one-dimensional feature vector.",
      "label": "Background",
      "prob": 0.5135911703109741
    },
    {
      "sentence": "TapNet is robust to phone case and fabric, and thus can be used for wearable interaction without specialized smart fabrics [7].",
      "label": "Background",
      "prob": 0.5099789500236511
    },
    {
      "sentence": "One of us produced the entire training data following a comprehensive data collection protocol, which aims to cover the diversity in real use.",
      "label": "Background",
      "prob": 0.4984741508960724
    },
    {
      "sentence": "Further adapting the model to multi-person data may teach the model to understand the artifacts of personal",
      "label": "Background",
      "prob": 0.4918839633464813
    },
    {
      "sentence": "AcousticsensingexploitssoundpropagationpropertiestorecognizeBoDgesture[29],gripforce[32],andcontactfingerpart[9],andelec-tricfieldsensingdetectsaround-devicegesturesinanon-intrusive",
      "label": "Background",
      "prob": 0.4893091320991516
    },
    {
      "sentence": "Someexploitedsmallwidgetstoenableoff-screengesturesensing.Wearingamagnetcanallowmagnetometertotrackthe3Dfingermovement[4,24].",
      "label": "Background",
      "prob": 0.48471373319625854
    },
    {
      "sentence": "In comparison to many alternatives, this neural network architecture worked the best towards our goal of increasing the UI design space of off-screen interactions.",
      "label": "Background",
      "prob": 0.4843181371688843
    },
    {
      "sentence": "This study is related to off-screen interaction, in particular, tapbased interaction, as well as multi-task neural networks [3].",
      "label": "Background",
      "prob": 0.48199227452278137
    },
    {
      "sentence": "3) offered new perspectives on alleviating the data hurdle in ML based HCI research;",
      "label": "Background",
      "prob": 0.4809383153915405
    },
    {
      "sentence": "Inertial Touch offers auxiliary impact information beyond capacitive sensing.",
      "label": "Background",
      "prob": 0.4782716929912567
    },
    {
      "sentence": "The output of TapNet contains multiple branches.",
      "label": "Background",
      "prob": 0.46789437532424927
    },
    {
      "sentence": "Edge [23] of Google Pixel phones and long-press power button [30] of the iPhones for voice command invocation.",
      "label": "Background",
      "prob": 0.46707525849342346
    },
    {
      "sentence": "This strategy allows to use the researchers intuition of the problem space to push the recognition envelope to the fullest degree, for example, by including the training data with different grip gestures and forces.",
      "label": "Background",
      "prob": 0.4661848247051239
    },
    {
      "sentence": "In addition to providing shortcuts to quick activations of apps or functions such as camera and screenshot, this section sketches out four applications enabled by TapNets capability of measuring multiple proprieties in addition to the presence of tap event, such as direction and location.",
      "label": "Background",
      "prob": 0.4522961974143982
    },
    {
      "sentence": "We designed, developed, and evaluated a set of deep learning methods for on-device IMU signal based off-screen input, in particular TapNet, a multi-task network that allows for cross-device training",
      "label": "Background",
      "prob": 0.4463553726673126
    },
    {
      "sentence": "biomechanics, and thus further improves the performance until its next plateau.",
      "label": "Background",
      "prob": 0.44516295194625854
    },
    {
      "sentence": "We also discovered encouraging generalizability across users when the model was trained (or \"taught\") by a one person.",
      "label": "Background",
      "prob": 0.444587379693985
    },
    {
      "sentence": "By doing so, each onechannel convolutional filter can be reused to detect shape features across channels, and then rely on the fully connected layers to draw decision by associating filter activations in different parts of the signals.",
      "label": "Background",
      "prob": 0.44349074363708496
    },
    {
      "sentence": "TapNet uses the inertial measurement unit (IMU) signals as primary input and the phone form factor as auxiliary information [28] for cross-device training , i.e. joint training on cross-device data.",
      "label": "Background",
      "prob": 0.44037479162216187
    },
    {
      "sentence": "In addition to orientation invariance, we also see that the first-order derivatives accelerometer and gyroscope signals have high shape similarity.",
      "label": "Background",
      "prob": 0.43829455971717834
    },
    {
      "sentence": "To avoid unnecessary down-stream computation for recognizing tap properties, a heuristic-based gating mechanism using the z-axis signal of the accelerometer is performed to reject obvious non-tap motions.",
      "label": "Method",
      "prob": 0.436125785112381
    },
    {
      "sentence": "None was used in any testing to ensure the validity and generalizability of the efficacy measures reported later.",
      "label": "Background",
      "prob": 0.43447157740592957
    },
    {
      "sentence": "For all other uses, contact the owner/author(s).",
      "label": "Background",
      "prob": 0.43279722332954407
    },
    {
      "sentence": "TapNet contains shared convolutional layers for task-agnostic knowledge",
      "label": "Background",
      "prob": 0.4317547678947449
    },
    {
      "sentence": "Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.",
      "label": "Other",
      "prob": 0.4596655070781708
    },
    {
      "sentence": "This section presents the ablation studies on the TapNet architecture: the use of multi-task learning (i.e. multi-output) and crossdevice training with auxiliary information (i.e. multi-input).",
      "label": "Background",
      "prob": 0.4281272888183594
    },
    {
      "sentence": "We have tested TapNet on those who had not been in any set of the data collection and encouraged them to explore the effects of TapNet freely on their own device in daily use (for such functions as taking screenshot).",
      "label": "Background",
      "prob": 0.4276182949542999
    },
    {
      "sentence": "TapNet generally outperforms its SISO variant, implying that the MIMO architecture also contributes to performance improvement in addition to the computation and memory benefits.",
      "label": "Result",
      "prob": 0.5056643486022949
    },
    {
      "sentence": "To verify the efficacy of one-channel CNN for tap recognition, we performed a comparison on tap direction classification, which is a representative task and demonstrated to require subtle signal alignment across channels.",
      "label": "Background",
      "prob": 0.423225462436676
    },
    {
      "sentence": "The tap event branch was trained once after every ten epochs of training the rest of the tap property branches.",
      "label": "Background",
      "prob": 0.41532352566719055
    },
    {
      "sentence": "We hypothesized that training on diverse but one-person data can still achieve generalizability for unseen users in some tap recognition tasks.",
      "label": "Result",
      "prob": 0.48936769366264343
    },
    {
      "sentence": "During data collection, the experiment interface would adapt to the handedness of individual participant to ensure the comfort range was valid.",
      "label": "Background",
      "prob": 0.41053837537765503
    },
    {
      "sentence": "The overall performance measured by the weighted average F1 score and MAE across participants and devices are shown in Table 4.",
      "label": "Result",
      "prob": 0.40850454568862915
    },
    {
      "sentence": "2) it produces systematic and diverse data, and",
      "label": "Background",
      "prob": 0.4019763767719269
    },
    {
      "sentence": "Using this auxiliary information helps to accommodate the difference of device form factor and achieves the cross-device training.",
      "label": "Background",
      "prob": 0.4015480875968933
    },
    {
      "sentence": "TapNet uses a multi-input and multi-output architecture.",
      "label": "Method",
      "prob": 0.4895760118961334
    },
    {
      "sentence": "We use IMU signals as primary input and device vector that describes the phone form factor as auxiliary input.",
      "label": "Method",
      "prob": 0.4065747559070587
    },
    {
      "sentence": "Then 50 sensor samples (  120ms) from each IMU channel are concatenated to form a 300-element feature vector for each tap-like event.",
      "label": "Background",
      "prob": 0.3915719985961914
    },
    {
      "sentence": "The datasets were collected on Phone A and Phone B that ran on Android 9, and the IMU sampling rate was approximately 416Hz.",
      "label": "Result",
      "prob": 0.4919598400592804
    },
    {
      "sentence": "3) cross-device training with phone form factor increases the efficiency of data utilization; and",
      "label": "Result",
      "prob": 0.4334929883480072
    },
    {
      "sentence": "The overall performance of different models increases with training samples and they flats out after 4.5K samples per device.",
      "label": "Result",
      "prob": 0.5012850165367126
    },
    {
      "sentence": "The device vector depicts the phone size, IMU pointing direction, and installation location relative to the upper left corner of the device housing.",
      "label": "Result",
      "prob": 0.4391597509384155
    },
    {
      "sentence": "First, thanks to the MIMO architecture, TapNet increased tap property recognition accuracy over the prior art methods, particularly for the more difficult tasks such as tap location recognition.",
      "label": "Result",
      "prob": 0.41116616129875183
    },
    {
      "sentence": "To provide the most natural feeling, we assigned phone size in the collection based on participants personal phone size.",
      "label": "Background",
      "prob": 0.3699519634246826
    },
    {
      "sentence": "TapNet then outputs the predictions of five tap properties at a time as shown in Table 1.",
      "label": "Background",
      "prob": 0.36254581809043884
    },
    {
      "sentence": "Our observation, as well as previous findings [17], suggests that a peak or valley in the z-axis output is a necessary (high recall) but not sufficient (low precision) signal to a tapping event on the device.",
      "label": "Result",
      "prob": 0.5177301168441772
    },
    {
      "sentence": "Most importantly, small-capacity one-channel CNN (purple dashed) and large-capacity six channel CNN (blue) have almost equivalent performance with 6K-12K training samples.",
      "label": "Result",
      "prob": 0.48753997683525085
    },
    {
      "sentence": "As illustrated in Figure 2, a one-channel CNN is used for tap recognition.",
      "label": "Background",
      "prob": 0.36125653982162476
    },
    {
      "sentence": "Users can perform a back double tap to invoke the AssistiveTap interface (see Figure 9a), then tilt",
      "label": "Background",
      "prob": 0.35882920026779175
    },
    {
      "sentence": "Although these studies yielded promising result, their network capacity was relatively small and the reported accuracy was still far from practical level.",
      "label": "Result",
      "prob": 0.5991201400756836
    },
    {
      "sentence": "In contrast to the detection of tap event alone, BackPat recognized tapping in three locations based on gyroscope and microphone signals [26].",
      "label": "Other",
      "prob": 0.5376731753349304
    },
    {
      "sentence": "To improve tap recognition, we develop a multi-input and multioutput a neural network that can estimate multiple tap properties.",
      "label": "Objective",
      "prob": 0.39672917127609253
    },
    {
      "sentence": "extraction, meanwhile each of its output branch retains the taskspecific information.",
      "label": "Background",
      "prob": 0.350615918636322
    },
    {
      "sentence": "computed by the Euclidean distance between ground truth location (   ,  ) and TapNet output (   ,  ) normalized by screen width  and height  .",
      "label": "Background",
      "prob": 0.34822437167167664
    },
    {
      "sentence": "Back-of-device(BoD)[5,6,14,16]andedge-of-deviceinteractions[10,16,37,41]haveattractedmuchattention,however,mostofthemre-liedonspecializedsensorsthatarenotreadilyavailableonphones.Forinstance,BackXPressstudiedfingerpressureforBoDinterac-tionusingasandwichedsmartphone[5].",
      "label": "Other",
      "prob": 0.46336889266967773
    },
    {
      "sentence": "Compared with the solution of one model for each task, a joint model (see Figure 1) can exploit the interrelation among multiple tap properties during training and also saves run-time computation and memory.",
      "label": "Background",
      "prob": 0.344856321811676
    },
    {
      "sentence": "This study also offers new potential for other research domains, including biometrics.",
      "label": "Result",
      "prob": 0.4860348701477051
    },
    {
      "sentence": "Unrealistic reach for targets on the back surface of the phone were excluded.",
      "label": "Result",
      "prob": 0.4222745895385742
    },
    {
      "sentence": "We are also the first to exploit the form factor of the phone as auxiliary information, which has been shown to be beneficial for training.",
      "label": "Result",
      "prob": 0.37625646591186523
    },
    {
      "sentence": "As shown in Figure 2, the system listens to the six-channel IMU (three-axis accelerometer and three-axis gyroscope) data and maintains a 150-ms data window.",
      "label": "Background",
      "prob": 0.3309137225151062
    },
    {
      "sentence": "Training on incremental oneperson data can increase performance up to a certain level and then plateaus (see Figure 8).",
      "label": "Background",
      "prob": 0.32741641998291016
    },
    {
      "sentence": "To achieve a balance ratio, we selected participants according to their personal phone size in recruitment.",
      "label": "Method",
      "prob": 0.38573142886161804
    },
    {
      "sentence": "Note that in the case of training with 15K samples, TapNet was jointly trained on 7.5K samples from Phone A and another 7.5K samples from Phone B. Similarly, its counterparts were pre-trained on 7.5K samples from one device and fine tuned on the other.",
      "label": "Result",
      "prob": 0.4853149652481079
    },
    {
      "sentence": "This performance gain is from knowing how much people can vary.",
      "label": "Result",
      "prob": 0.5050963759422302
    },
    {
      "sentence": "Each task aims to recognize one tap property , such as direction and location.",
      "label": "Objective",
      "prob": 0.5443041324615479
    },
    {
      "sentence": "However, the joint training architecture has been shown effective and this is a promising step toward a device adaptive model.",
      "label": "Result",
      "prob": 0.6277874708175659
    },
    {
      "sentence": "It uses the same training configuration (Adam optimizer and learning rate) as the MIMO TapNet, and it gives performance reference if TapNet is configured for a single task.",
      "label": "Result",
      "prob": 0.34525829553604126
    },
    {
      "sentence": "More interestingly, cross-device training with sensor location as auxiliary information",
      "label": "Result",
      "prob": 0.3482382893562317
    },
    {
      "sentence": "Our work is set to help create a benchmark with extensive dataset development, neural network model design, model training, and experimentation.",
      "label": "Objective",
      "prob": 0.4187467098236084
    },
    {
      "sentence": "We can define Inertial Touch as a fast touch event with a strong tapping momentum .",
      "label": "Result",
      "prob": 0.3984636068344116
    },
    {
      "sentence": "Each branch addresses one of the recognition tasks, such as different targets in tracking [22], languages in translation [13], and head poses in gaze estimation [43].",
      "label": "Other",
      "prob": 0.5388532876968384
    },
    {
      "sentence": "One the other hand, both SIMO and SISO TapNets can considerably outperform TinyCNN (purple dashed) starting from 3K training samples, and outperform SVM (blue dashed) starting from 6K.",
      "label": "Result",
      "prob": 0.3705880045890808
    },
    {
      "sentence": "This paper presents the design, training, implementation and application of TapNet for off-screen mobile input.",
      "label": "Objective",
      "prob": 0.6083097457885742
    },
    {
      "sentence": "In run time, it took 0.56 ms on the Phone B main CPU to finish one TapNet inference.",
      "label": "Result",
      "prob": 0.444295197725296
    },
    {
      "sentence": "To keep data collection natural, we avoid continuous and extensive tapping.",
      "label": "Method",
      "prob": 0.32880663871765137
    },
    {
      "sentence": "The key is to ensure the training data diversity.",
      "label": "Objective",
      "prob": 0.3622610569000244
    },
    {
      "sentence": "SecTap allowed users to move a cursor by tilting and select by back tapping [19].",
      "label": "Other",
      "prob": 0.5672191381454468
    },
    {
      "sentence": "This section evaluates the overall performance of TapNet, followed by the comparison between oneand multichannel CNN as well as ablation studies on the MIMO network design.",
      "label": "Result",
      "prob": 0.3829764425754547
    },
    {
      "sentence": "We focused on collecting the natural tapping actions to simulate tapping data distribution in real use, in particular, with the common finger (thumb and index), in the finger comfort range, and for four most common one-handed and two-handed gestures [11, 15] as shown in Figure 3.",
      "label": "Result",
      "prob": 0.3962249755859375
    },
    {
      "sentence": "This is more efficient than collecting additional multi-person data.",
      "label": "Result",
      "prob": 0.575975239276886
    },
    {
      "sentence": "In contrast, we propose to concatenate the six-channel data into a one-dimensional vector and apply onechannel convolutional layers in TapNet.",
      "label": "Objective",
      "prob": 0.32679957151412964
    },
    {
      "sentence": "tap-induced peak in the z-axis signal.",
      "label": "Result",
      "prob": 0.43366187810897827
    },
    {
      "sentence": "Training over an intersection of multiple tap tasks confines the learning in a restrained feature embedding space and thus allows it to converge to a solution for all related tasks [13].",
      "label": "Other",
      "prob": 0.5195320844650269
    },
    {
      "sentence": "The four grip gestures we studied are in a combination conditions of phone, grip gestures, and tapping actions as shown in Table 3.",
      "label": "Result",
      "prob": 0.5379201769828796
    },
    {
      "sentence": "Further, comparing the solid and dashed lines, large-capacity models generally outperforms small-capacity models with similar architecture and input format.",
      "label": "Result",
      "prob": 0.6137474179267883
    },
    {
      "sentence": "We used a 5.5\" Phone A and a 6.3\" Phone B throughout the collection.",
      "label": "Result",
      "prob": 0.36971762776374817
    },
    {
      "sentence": "All tap feature vectors are temporally aligned.",
      "label": "Result",
      "prob": 0.3541901111602783
    },
    {
      "sentence": "Since different tap properties have a confound impact on IMU responses, we jointly learn the mappings from IMU signals onto these interrelated tap properties using a multi-layer CNN.",
      "label": "Method",
      "prob": 0.4459787905216217
    },
    {
      "sentence": "The x-axis shows the number of training samples, and the y-axis the weighted average of F1 score.",
      "label": "Result",
      "prob": 0.49364370107650757
    },
    {
      "sentence": "5.2.2 Cross-device training utilizes data efficiently.",
      "label": "Result",
      "prob": 0.4238913357257843
    },
    {
      "sentence": "Specifically, we first perform a simple, linear complexity peak detection on the gating signal at the per-frame level (Figure 2 the pink region).",
      "label": "Method",
      "prob": 0.4323507249355316
    },
    {
      "sentence": "The feature window is identified and aligned across tap samples by the",
      "label": "Result",
      "prob": 0.44646260142326355
    },
    {
      "sentence": "Each session aims to collect tap in a specific condition described by a set of characteristics of the phone, grip gestures, and the tapping itself (see Table 2).",
      "label": "Objective",
      "prob": 0.39846715331077576
    },
    {
      "sentence": "(A+B) can approach the performance upper bound earlier (with 1.5K samples per device) than the rest of the models.",
      "label": "Result",
      "prob": 0.613130509853363
    },
    {
      "sentence": "To test this hypothesis, we collected a one-person dataset for training and a separate multiperson dataset for testing (and optionally model adaptation).",
      "label": "Method",
      "prob": 0.36227110028266907
    },
    {
      "sentence": "As such, we use the z-axis signal of accelerometer as a gating signal to the CNN in order to minimize the amount of computation (hence power consumption) on the mobile device.",
      "label": "Method",
      "prob": 0.4533850848674774
    },
    {
      "sentence": "The three parallel lines along the diagonal with a five-cell offset in the confusion matrix indicates TapNet either predicts correctly or to nearby regions (see Figure 4(c)).",
      "label": "Result",
      "prob": 0.5966347455978394
    },
    {
      "sentence": "5.2.1 Multi-task learning helps training with limited data.",
      "label": "Result",
      "prob": 0.4209079444408417
    },
    {
      "sentence": "Please refer to our supplemental video for these applications in action.",
      "label": "Other",
      "prob": 0.35202205181121826
    },
    {
      "sentence": "The numbers are the higher the better for F1 and r 2 scores, while lower the better for MAE.",
      "label": "Result",
      "prob": 0.6017846465110779
    },
    {
      "sentence": "We exploit convolutional layers to extract shape features from IMU signals, because the convolutional filter offers temporal",
      "label": "Result",
      "prob": 0.37077048420906067
    },
    {
      "sentence": "In total, the one-person training dataset contains 109,200 tapping actions, including 45,500 front taps, 48,450 back taps, 4,020 left taps, 4,020 right taps, 3,610 top taps, 3,600 bottom taps.",
      "label": "Other",
      "prob": 0.297719269990921
    },
    {
      "sentence": "For instance, it is possible to improve continuous and passive authentication [2, 35, 46] by using tap properties that contain biometric information, i.e. with a clear gap between the first two plateaus (orange area) in Figure 8.",
      "label": "Result",
      "prob": 0.5540840029716492
    },
    {
      "sentence": "Our technical investigation and evaluation shed lights on two important aspects for machine learning (ML) in HCI development: methods and data.",
      "label": "Result",
      "prob": 0.44578617811203003
    },
    {
      "sentence": "We verified the hypothesis that training on the one-person data can still generalize well across users if the diversity of the training data can be ensured.",
      "label": "Result",
      "prob": 0.5655655860900879
    },
    {
      "sentence": "Due to space limitation, we have put some of the implementation evaluations into the supplemental file.",
      "label": "Result",
      "prob": 0.5393325686454773
    },
    {
      "sentence": "The SISO TapNet variant also outperforms related works by a marked margin.",
      "label": "Result",
      "prob": 0.609367311000824
    },
    {
      "sentence": "This corroborates the hypothesis that training on the diverse data even from a single person can achieve viable user generalizability for tasks, such as event (F1:.92), finger part (F1:.93), and direction classification (F1:.85).",
      "label": "Result",
      "prob": 0.46698319911956787
    },
    {
      "sentence": "Specifically, TapNet yields a mean distance error around 10% of the screen diagonal, similar to the between-icon distance on mobile phone home page.",
      "label": "Result",
      "prob": 0.6179556846618652
    },
    {
      "sentence": "Stephenson et al. pointed out that conditioning on auxiliary information can achieve higher robustness than that of appending auxiliary information directly to the main features [28].",
      "label": "Other",
      "prob": 0.6078729033470154
    },
    {
      "sentence": "This section evaluates TapNets improvement over prior art and user generalizability when training on one-person data.",
      "label": "Result",
      "prob": 0.5504788160324097
    },
    {
      "sentence": "Its range is [0, 1.414], and a baseline (always predicting the center) is 0.707.",
      "label": "Other",
      "prob": 0.5723768472671509
    },
    {
      "sentence": "Visual indicator was presented on the screen to guide the experimenter.",
      "label": "Result",
      "prob": 0.40164706110954285
    },
    {
      "sentence": "However, the performance difference on simple tasks (event and finger part classification) among different methods is marginal.",
      "label": "Result",
      "prob": 0.7074629068374634
    },
    {
      "sentence": "When we need to improve the model, it is relatively easy to enlarge the one-person training set, evaluate on the test set, and repeat this process in an iterative fashion.",
      "label": "Method",
      "prob": 0.46366044878959656
    },
    {
      "sentence": "We demonstrated that many new interaction use cases could be enabled by TapNet.",
      "label": "Result",
      "prob": 0.6556228995323181
    },
    {
      "sentence": "5.1.2 Achieving person generalizability with one-person data.",
      "label": "Result",
      "prob": 0.4062177538871765
    },
    {
      "sentence": "We compared against the single-output counterpart (SISO; a truncated TapNet variant)",
      "label": "Result",
      "prob": 0.5064972043037415
    },
    {
      "sentence": "The advantages of this strategy are three-fold:",
      "label": "Result",
      "prob": 0.49223291873931885
    },
    {
      "sentence": "CHI 21, May 813, 2021, Yokohama, Japan",
      "label": "Other",
      "prob": 0.7494847178459167
    },
    {
      "sentence": "To train and optimize this and other alternative ML models, we developed a one-person dataset for training and a multi-person dataset for testing.",
      "label": "Method",
      "prob": 0.4196595847606659
    },
    {
      "sentence": "We measured classification performance by F1 score and regression by mean absolute error (MAE) and r 2 score.",
      "label": "Result",
      "prob": 0.5316985249519348
    },
    {
      "sentence": "and recent related works, including a SVM [19, 39] and a tiny CNN model [17].",
      "label": "Other",
      "prob": 0.6979166269302368
    },
    {
      "sentence": "We implemented and trained four ML algorithms, including TapNet, to compare their relative performance.",
      "label": "Method",
      "prob": 0.4361583888530731
    },
    {
      "sentence": "Note that we have built one model per task for the single-output models.",
      "label": "Result",
      "prob": 0.506218433380127
    },
    {
      "sentence": "We recruited 31 participants (13 female, age: 18-54).",
      "label": "Result",
      "prob": 0.38018718361854553
    },
    {
      "sentence": "This is in good agreement with the regression results (MAE:.14;  10% of the screen diagonal).",
      "label": "Result",
      "prob": 0.7069000601768494
    },
    {
      "sentence": "Taken together, we conclude that the one-channel CNN can address across-channel signal alignment more efficiently than its multichannel counterpart for tap property recognition.",
      "label": "Result",
      "prob": 0.7365294694900513
    },
    {
      "sentence": "The key objective is to achieve the five recognition tasks (i.e. the five network outputs) with one network (TapNet) as shown in Table 1.",
      "label": "Objective",
      "prob": 0.34966444969177246
    },
    {
      "sentence": "Therefore, we only perform CNN recognition when we observe a tap-like signal from the gating signal.",
      "label": "Result",
      "prob": 0.6342989802360535
    },
    {
      "sentence": "In addition to a tap event (presence of a tap) alone, potentially useful tap properties include tap direction [20, 34] (i.e. whether the tap is on the front, back, or side of the phone), tap location [17, 21] (i.e. which region the tap falls on the devices), and tap finger part [9] (i.e. tapping with finger pad vs fingernail).",
      "label": "Other",
      "prob": 0.45883244276046753
    },
    {
      "sentence": "Liang et al. applied a two-layer CNN model to estimate tap location from zaxis signal of accelerometer [17].",
      "label": "Other",
      "prob": 0.6254608631134033
    },
    {
      "sentence": "The resulting method, TapNet, enables joint learning on cross-device data and joint prediction of multiple tap properties.",
      "label": "Method",
      "prob": 0.5986767411231995
    },
    {
      "sentence": "Taken together, the TapNet project made significant progress towards practically enabling and enlarging the off-screen interaction design space by deep learning from on-device IMU signals, establishing new benchmarks with reproducible results, datasets and codebase.",
      "label": "Result",
      "prob": 0.6956971287727356
    },
    {
      "sentence": "Figure 4(a) shows the normalized confusion matrix of tap location classification.",
      "label": "Result",
      "prob": 0.646445631980896
    },
    {
      "sentence": "Please refer to the supplemental file for a detailed description.",
      "label": "Other",
      "prob": 0.5481974482536316
    },
    {
      "sentence": "Tap data were collected through multiple sessions on Phone A and Phone B 2 .",
      "label": "Result",
      "prob": 0.5948887467384338
    },
    {
      "sentence": "Addingamirrorcanmakecameratodetectfin-gerlocationontheback[33]oraroundthedevice[38].",
      "label": "Other",
      "prob": 0.7848984599113464
    },
    {
      "sentence": "The results show that the one-person model could achieve a comparable level of user generalizability as a model tuned on multi-person data.",
      "label": "Result",
      "prob": 0.7413058876991272
    },
    {
      "sentence": "Taken together, a multi-output TapNet is favorable over the state of art [17, 19, 39].",
      "label": "Other",
      "prob": 0.7254909873008728
    },
    {
      "sentence": "We applied ReLU and batch normalization after each convolutional layer and used Adam optimizer with a learning rate of 1e-4 and a momentum decay (1e-6).",
      "label": "Method",
      "prob": 0.4846574366092682
    },
    {
      "sentence": "As we aim to detect tap event and identify tap properties in an orientation-invariant manner, we leverage the raw accelerometer and gyroscope data and compute their first-order derivative.",
      "label": "Method",
      "prob": 0.6411733031272888
    },
    {
      "sentence": "Regarding the options between one-channel vs multi-channel network, we see that the one-channel network can be more efficient as it allows for filter reuse across IMU channels.",
      "label": "Result",
      "prob": 0.695239245891571
    },
    {
      "sentence": "As baselines, we also evaluated training on the 7.5K device-specific samples alone for each device.",
      "label": "Result",
      "prob": 0.6229820847511292
    },
    {
      "sentence": "This experiment was conducted on the Phone A data using the one-to-n evaluation paradigm.",
      "label": "Result",
      "prob": 0.5156509280204773
    },
    {
      "sentence": "In addition, data collection was informed by research conducted on the most common hand grips and finger placements [11, 15].",
      "label": "Other",
      "prob": 0.6805233359336853
    },
    {
      "sentence": "ExplorativeTap is a two-handed interaction method that exploits signals from both the front (touch) and back of the phone tap (see Figure 9b).",
      "label": "Method",
      "prob": 0.6233465671539307
    },
    {
      "sentence": "All the methods were trained on the one-person dataset and tested on the multi-person dataset.",
      "label": "Result",
      "prob": 0.4302244782447815
    },
    {
      "sentence": "Our contribution is four-fold.",
      "label": "Result",
      "prob": 0.5624966025352478
    },
    {
      "sentence": "By comparing the one-to-n-participant with the leave-one-out evaluation (see Table 5), we see that training on a one-person data can still be effective.",
      "label": "Result",
      "prob": 0.7489121556282043
    },
    {
      "sentence": "We mitigate the risks by evaluating on a separate multi-person dataset.",
      "label": "Result",
      "prob": 0.6640351414680481
    },
    {
      "sentence": "Granell and Leiva conducted feature engineering for tap detection [8].",
      "label": "Other",
      "prob": 0.7387425899505615
    },
    {
      "sentence": "Second, we discuss an efficient data strategy for developing a ML based HCI application.",
      "label": "Result",
      "prob": 0.3839919865131378
    },
    {
      "sentence": "We then discuss the gating component and signal filtering for recognition.",
      "label": "Result",
      "prob": 0.5380605459213257
    },
    {
      "sentence": "Among these tapping actions, 94,764 were collected from a Phone A and 14,440 from a Phone B, and 85.7% of them are tapping with finger pad and the rest are with",
      "label": "Result",
      "prob": 0.6180770993232727
    },
    {
      "sentence": "We repeated data collection under the same condition to mitigate bias.",
      "label": "Result",
      "prob": 0.6120522022247314
    },
    {
      "sentence": "Limited by the tap samples on Phone B (  15K) in the training dataset, we evaluated model performance averaged over two devices with incremental training samples from 1K to 15K.",
      "label": "Result",
      "prob": 0.6245091557502747
    },
    {
      "sentence": "2) developed two datasets and conducted extensive evaluations that advanced the state of the art;",
      "label": "Result",
      "prob": 0.6828520894050598
    },
    {
      "sentence": "Compared with the best performance among SVM and TinyCNN, TapNet achieved considerable improvements on tap direction (by 51.0%) and location (classification: 161.5% and regression: 30%).",
      "label": "Result",
      "prob": 0.7861592173576355
    },
    {
      "sentence": "Moving beyond the prior work in this space, this project aims at developing IMU-based input methods that meet the requirement of practical applications, by means of deep neural network design and training.",
      "label": "Objective",
      "prob": 0.7940064072608948
    },
    {
      "sentence": "This paper aims to address the needs in practice, by predicting comprehensive tap properties for diverse application purposes and advancing the state of the art of off-screen interaction towards a practical level of performance.",
      "label": "Objective",
      "prob": 0.8240378499031067
    },
    {
      "sentence": "TapNet achieved a marked improvement over the prior art [17, 19, 39] on tap direction (by 51.0%) and location (161.5%) classifications as well as tap location regression (30%).",
      "label": "Result",
      "prob": 0.7350457906723022
    },
    {
      "sentence": "As expected, fine tuning on the n-1 participants further improved the performance, but some of the improvements are relatively moderate, for example, by 1% for tap event and 3.2% for finger part classification.",
      "label": "Result",
      "prob": 0.8109105229377747
    },
    {
      "sentence": "A close examination of the 35-class tap location classification reveals that TapNet can be usable despite its seemingly limited F1 score (0.34).",
      "label": "Result",
      "prob": 0.6783645749092102
    },
    {
      "sentence": "Overall,MIMOTapNetsignificantlyoutperformsthepriorart[17, 19, 39].",
      "label": "Other",
      "prob": 0.8041942119598389
    },
    {
      "sentence": "F1 score is an weighted average metric of precision and recall, ranging from [0, 1].",
      "label": "Other",
      "prob": 0.7325621247291565
    },
    {
      "sentence": "The MAE of tap location, i.e. [(      )/  ] 2 + [(      )/  ] 2 , is",
      "label": "Other",
      "prob": 0.8063932061195374
    },
    {
      "sentence": "Their experience matched with the leave-one-participant-out test results reported here.",
      "label": "Result",
      "prob": 0.7426984906196594
    },
    {
      "sentence": "Bezel-Tap detected tap on the edge of the devices [27].",
      "label": "Other",
      "prob": 0.797634482383728
    },
    {
      "sentence": "We used a single researcher training strategy.",
      "label": "Result",
      "prob": 0.41545796394348145
    },
    {
      "sentence": "We have set up the infrastructure and we plan to further investigate along this line by adding new devices and also opensource our implementation.",
      "label": "Result",
      "prob": 0.5279577970504761
    },
    {
      "sentence": "Figure 7 shows the performance comparison of one-channel CNN against its multi-channel counterparts.",
      "label": "Result",
      "prob": 0.7592445611953735
    },
    {
      "sentence": "We also collected non-tap motions (26,060 in total) in a number of scenarios: grasping (4,700) the phone, rubbing the phone case (6,000), releasing a tap (6,160), knocking on the phone placing surface (4,400), shaking and moving with the phone in pocket and in bag (4,800).",
      "label": "Result",
      "prob": 0.5185827612876892
    },
    {
      "sentence": "As TapNet estimates",
      "label": "Other",
      "prob": 0.6464456915855408
    },
    {
      "sentence": "2021 Copyright held by the owner/author(s).",
      "label": "Other",
      "prob": 0.8625428676605225
    },
    {
      "sentence": "The solid lines denote the performance of large-capacity models with 163K (one-channel) and 144K (six-channel) trainable parameters, while the dashed lines those of small-capacity models with 11K (one-channel) and 9K (six-channel) trainable parameters.",
      "label": "Result",
      "prob": 0.6804870367050171
    },
    {
      "sentence": "Although evaluation results demonstrated that TapNet benefited from cross-device training, we do not expect the current TapNet trained on these two devices would directly apply to unseen devices without further training, i.e. a cross-device model.",
      "label": "Result",
      "prob": 0.7487069964408875
    },
    {
      "sentence": "Table 4: Weighted average F1 score of four classification tasks (no color shading) as well as MAE and r 2 score of the tap location regression task (purple shading).",
      "label": "Result",
      "prob": 0.7180525660514832
    },
    {
      "sentence": "3) the data quality is manageable and assessable.",
      "label": "Result",
      "prob": 0.7415972948074341
    },
    {
      "sentence": "Nevertheless, with sufficient training samples (over 3K) performance of SIMO and SISO TapNets flats out with a comparable F1 score (SIMO:.81, SISO:.80).",
      "label": "Other",
      "prob": 0.5291223526000977
    },
    {
      "sentence": "SVM and TinyCNN are our re-implementation of related works [17, 19, 39].",
      "label": "Other",
      "prob": 0.7745305299758911
    },
    {
      "sentence": "5.1.1 Improving the state of the art.",
      "label": "Other",
      "prob": 0.6079908013343811
    },
    {
      "sentence": "To verify this, we performed evaluation in two paradigms:",
      "label": "Result",
      "prob": 0.6700306534767151
    },
    {
      "sentence": "To investigate cross-device model training, we evaluated model performance with incremental training samples from 1K to 15K, as previous experiments suggest that TapNet converges with around 15K training samples.",
      "label": "Result",
      "prob": 0.804594099521637
    },
    {
      "sentence": "Zhang et al. investigated the benefit of using auxiliary information in training and found that it can improve performance in testing even without using the auxiliary information as input [42].",
      "label": "Result",
      "prob": 0.5116459131240845
    },
    {
      "sentence": "Liao et al. showed that integrating simple but essential auxiliary information can increase prediction accuracy [18].",
      "label": "Other",
      "prob": 0.6939179301261902
    },
    {
      "sentence": "Interesting findings include:",
      "label": "Result",
      "prob": 0.5960375070571899
    },
    {
      "sentence": "To evaluate TapNet performance, we collected a multi-person (n=31) dataset.",
      "label": "Result",
      "prob": 0.7517483234405518
    },
    {
      "sentence": "We first present the evaluation on multi-task learning.",
      "label": "Result",
      "prob": 0.7143934369087219
    },
    {
      "sentence": "We evaluated on tap direction classification as a representative task.",
      "label": "Result",
      "prob": 0.7811802625656128
    },
    {
      "sentence": "PINlogger classified tapping on ten buttons using a single layer neutral network [21].",
      "label": "Other",
      "prob": 0.8414703011512756
    },
    {
      "sentence": "(see the supplemental video figure).",
      "label": "Other",
      "prob": 0.6727854013442993
    },
    {
      "sentence": "Overall, the multi-person dataset contains 38,545 taps, including 20,615 taps from front, 10,505 back, 1,705 left, 1,705 right, 1,975 top, and 2,040 bottom, among which 58.3% was collected on phones with rubber cases, and the rest without.",
      "label": "Result",
      "prob": 0.8235623240470886
    },
    {
      "sentence": "Each model was trained with sufficient number of epochs until the validation (5% data) loss converges, and training was done using Tensorflow [1] on a 4G memory GPU.",
      "label": "Result",
      "prob": 0.5426647067070007
    },
    {
      "sentence": "A+B represents TapNet jointly trained on cross-device data; B->A and A->B denote tuning the pre-trained model from one device on the other; and A and B indicate models trained on device-specific data.",
      "label": "Result",
      "prob": 0.7603551745414734
    },
    {
      "sentence": "We first describe the pipeline overview, followed by the core of the method (a MIMO network).",
      "label": "Method",
      "prob": 0.7741057872772217
    },
    {
      "sentence": "This section describes two datasets: the one-person dataset (135,260 samples) was used for TapNet training only (not testing) and the multi-person dataset (38,545 samples) was for performance testing and user generalizability tuning.",
      "label": "Result",
      "prob": 0.7691326141357422
    },
    {
      "sentence": "Similar to standard deviation, r 2 measures how well the regression line fits the data with a range of [0, 1].",
      "label": "Other",
      "prob": 0.8204429149627686
    },
    {
      "sentence": "We also evaluated this in an experiment.",
      "label": "Result",
      "prob": 0.7732211351394653
    },
    {
      "sentence": "As input data dimension affects the number of trainable parameters (i.e. model capacity) of a specific network architecture, we evaluated similar architectures with commensurate number of trainable parameters, so as to compare models with comparable capacity.",
      "label": "Result",
      "prob": 0.7469967603683472
    },
    {
      "sentence": "TinyCNN is a replication of Liang et al.",
      "label": "Other",
      "prob": 0.899171769618988
    },
    {
      "sentence": "finger nail.",
      "label": "Other",
      "prob": 0.8124452233314514
    },
    {
      "sentence": "Figure 6 gives the performance comparison.",
      "label": "Result",
      "prob": 0.8097728490829468
    },
    {
      "sentence": "We define a tap-like signal as the one has an impulse that contains at least one peak, and an impulse as a group of peaks between each pair the interval is less than the threshold,   , which is empirically set to 80 ms. We also apply a magnitude threshold on the peak and valley to control the sensitivity of the gating component.",
      "label": "Method",
      "prob": 0.6453696489334106
    },
    {
      "sentence": "After experimenting with multiple methods and architectures for tap detection, we found that a multi-input, multi-output (MIMO) convolutional neural network (CNN) gave the best results.",
      "label": "Result",
      "prob": 0.8886306881904602
    },
    {
      "sentence": "TapNet is the proposed MIMO method.",
      "label": "Method",
      "prob": 0.5263786315917969
    },
    {
      "sentence": "The evaluation results show that",
      "label": "Result",
      "prob": 0.867849588394165
    },
    {
      "sentence": "https://doi.org/10.1145/3411764.3445626",
      "label": "Other",
      "prob": 0.9405646920204163
    },
    {
      "sentence": "4.2.2 Apparatus.",
      "label": "Other",
      "prob": 0.8556671142578125
    },
    {
      "sentence": "Figure 5 shows the comparison results.",
      "label": "Result",
      "prob": 0.865141749382019
    },
    {
      "sentence": "manner [45, 47].",
      "label": "Other",
      "prob": 0.9344018697738647
    },
    {
      "sentence": "s two-layer CNN [17].",
      "label": "Other",
      "prob": 0.9181391596794128
    },
    {
      "sentence": "ACM Reference Format:",
      "label": "Other",
      "prob": 0.9455322623252869
    },
    {
      "sentence": "1 TapNet Dataset",
      "label": "Other",
      "prob": 0.8385469913482666
    },
    {
      "sentence": "4.2.1 Data collection design.",
      "label": "Other",
      "prob": 0.8258645534515381
    },
    {
      "sentence": "REFERENCES",
      "label": "Other",
      "prob": 0.9412382245063782
    },
    {
      "sentence": "4.2.3 Participants.",
      "label": "Other",
      "prob": 0.9014063477516174
    }
  ]
}