{
  "uist-1": [
    {
      "sentence": "These systems have tended to be fairly brittle, and have generally only targeted reading text and not actually using the interface.",
      "label": "Background",
      "prob": 0.9581547975540161
    },
    {
      "sentence": "Many physical interfaces in the real world are inaccessible to blind people, which has led to substantial prior work on sys tems for making them accessible.",
      "label": "Background",
      "prob": 0.9506863355636597
    },
    {
      "sentence": "Unfortunately, that information is often either lost or inaccessible once the user interface makes it into a running system.",
      "label": "Background",
      "prob": 0.9505465030670166
    },
    {
      "sentence": "For instance, StateLens has limited capability in noticing and dif ferentiating minor interface changes such as toggle buttons or color indicators.",
      "label": "Background",
      "prob": 0.9455459713935852
    },
    {
      "sentence": "Even if videos only capture a subset of possible tasks, these would likely be frequently used paths of action, thus still providing reasonable functionality in many cases.",
      "label": "Background",
      "prob": 0.9446762800216675
    },
    {
      "sentence": "For unfamiliar dynamic touchscreen devices, the amount of time and cognitive effort needed for blind people to explore, understand, and activate functions became quite heavy.",
      "label": "Background",
      "prob": 0.9439407587051392
    },
    {
      "sentence": "In the real world, users cannot control the touchscreens they encounter, and many are not accessible.",
      "label": "Background",
      "prob": 0.9419119954109192
    },
    {
      "sentence": "For example, medical devices can be hard to congure, and devices that are in foreign languages are hard to operate.",
      "label": "Background",
      "prob": 0.9416578412055969
    },
    {
      "sentence": "Inaccessible touchscreen interfaces in the world represent a long-standing and frustrating problem for people who are",
      "label": "Background",
      "prob": 0.9346781969070435
    },
    {
      "sentence": "Such frustrating accessibility problems are commonplace and pervasive.",
      "label": "Background",
      "prob": 0.932069718837738
    },
    {
      "sentence": "These systems could more easily assist blind users with using an interface, but assisting in this way is likely to be cumbersome and slow.",
      "label": "Background",
      "prob": 0.9296683073043823
    },
    {
      "sentence": "Duplicate states require more manual effort to clean up, but have less impact on user experience compared to missing states.",
      "label": "Background",
      "prob": 0.9271455407142639
    },
    {
      "sentence": "Solving all of the challenges represented by the combination of difcult issues for public touchscreen devices has remained elusive:",
      "label": "Background",
      "prob": 0.9257537126541138
    },
    {
      "sentence": "For example, the location of the ring on the nger may vary for different users and different sessions during use, thus changing the actual position of touch.",
      "label": "Background",
      "prob": 0.912358283996582
    },
    {
      "sentence": "In a perfect world, posthoc xes like StateLens would not be needed (because all technologies would be inherently accessible), but in practice access technology like StateLens plays a vital role.",
      "label": "Background",
      "prob": 0.9093602299690247
    },
    {
      "sentence": "In this case, some users may accidentally press again at the same location triggering an incorrect selection on the next screen state.",
      "label": "Background",
      "prob": 0.9091219305992126
    },
    {
      "sentence": "For ve of the tasks, partic ipants accidentally selected the wrong option and had to go back or start over.",
      "label": "Background",
      "prob": 0.9085038900375366
    },
    {
      "sentence": "Prior work on reverse engineering of user interfaces has mainly used sceenshots or screencast videos.",
      "label": "Background",
      "prob": 0.9074728488922119
    },
    {
      "sentence": "However, this approach could be benecial to sighted people and people with cognitive disabilities in many ways as well.",
      "label": "Background",
      "prob": 0.9031034111976624
    },
    {
      "sentence": "This is worsened when they are asked to only use one nger to interact with the interfaces, in order to prevent accidental touches.",
      "label": "Background",
      "prob": 0.9019364714622498
    },
    {
      "sentence": "Making touchscreen interfaces accessible has been a longstanding challenge in accessibility [14, 17, 30], and some current platforms are quite accessible ( e.g. , iOS).",
      "label": "Background",
      "prob": 0.898794949054718
    },
    {
      "sentence": "When attempting to use existing inaccessible touchscreen de vices, participants found holding their ngers in mid-air while trying to explore and locate the buttons to be very awkward and unusable, which also often resulted in accidental touches.",
      "label": "Background",
      "prob": 0.8921234011650085
    },
    {
      "sentence": "StateLens represents an important step for solv ing this long-standing accessibility problem, and its technical approach may nd applications broadly for augmenting how people interact with the touchscreens they encounter.",
      "label": "Background",
      "prob": 0.8880354166030884
    },
    {
      "sentence": "A known challenge for touchscreen interfaces is that they can not easily be explored non-visually without the risk of acciden tally triggering functions on the screen.",
      "label": "Background",
      "prob": 0.886408269405365
    },
    {
      "sentence": "However, because of changing display states and screen layouts, explor ing and activating UI components across multiple screens is difcult (analogous to nding ones way in a new city).",
      "label": "Background",
      "prob": 0.8858731985092163
    },
    {
      "sentence": "We observed that participants sometimes held the accessories in awkward postures, likely due to unfamiliarity.",
      "label": "Background",
      "prob": 0.880869448184967
    },
    {
      "sentence": "For example, a vending ma chine could be labeled with Braille, but the checkout credit card machine is not accessible.",
      "label": "Background",
      "prob": 0.8808544874191284
    },
    {
      "sentence": "This issue may be alleviated by providing more immediate feed back such as a tentative audio conrmation that a button press has been successful.",
      "label": "Background",
      "prob": 0.8782533407211304
    },
    {
      "sentence": "Even with the existing laws, there are still many cases where reasonable accommodation is not enough.",
      "label": "Background",
      "prob": 0.8781554698944092
    },
    {
      "sentence": "Note that recognizing nger touchpoint locations in naturalistic us age videos is not always possible or accurate, such as under extreme lighting conditions, or when users are wearing gloves.",
      "label": "Background",
      "prob": 0.8772677779197693
    },
    {
      "sentence": "Our 3D-printed accessories elegantly add risk-free explo ration to existing capacitive touchscreen devices without modifying the underlying hardware or software, which has been a major hurdle for past efforts.",
      "label": "Background",
      "prob": 0.8716844320297241
    },
    {
      "sentence": "Without the 3D-printed ac cessories introduced in this paper, VizLens would not work for touchscreens.",
      "label": "Background",
      "prob": 0.8679107427597046
    },
    {
      "sentence": "Many specialized computer vision systems have been built to help blind people read the",
      "label": "Background",
      "prob": 0.8599709272384644
    },
    {
      "sentence": "If the screen is cluttered, it could still be quite difcult to operate.",
      "label": "Background",
      "prob": 0.8598886132240295
    },
    {
      "sentence": "A core feature of StateLens is its ability to reverse engineer user interfaces in-the-wild based on videos of their use.",
      "label": "Background",
      "prob": 0.8561291694641113
    },
    {
      "sentence": "Participants shared their concerns and fears of accidentally triggering functions on inaccessible touchscreens.",
      "label": "Background",
      "prob": 0.8503215909004211
    },
    {
      "sentence": "Furthermore, similar but slightly different models of a device may reuse another state diagram and enable transfer learning.",
      "label": "Background",
      "prob": 0.8494947552680969
    },
    {
      "sentence": "As users start to use a device, it can be geo-located, automatically recognized, or added into the system.",
      "label": "Background",
      "prob": 0.8469304442405701
    },
    {
      "sentence": "In contrast to prior work, StateLens is a solution for reverse engineering existing physical inter faces through much noisier point-of-view videos rather than screenshots or prototyped GUIs.",
      "label": "Background",
      "prob": 0.8469144701957703
    },
    {
      "sentence": "Participants often resorted to sighted help when accessing pub lic touchscreen appliances, and raised serious privacy concerns when asking others (often strangers) to help with entering sen sitive information, e.g. , using credit card machines to complete nancial transactions, or using sign-in kiosks at pharmacies and doctors ofces.",
      "label": "Background",
      "prob": 0.8431149125099182
    },
    {
      "sentence": "StateLens is intended to work on touchscreens already installed in the world that are not possible to be modied.",
      "label": "Background",
      "prob": 0.8370369076728821
    },
    {
      "sentence": "StateLens is a stopgap measure to make access possible (as are many access technologies), and introduces ideas that might nd purchase in other access and accessible technologies.",
      "label": "Background",
      "prob": 0.8369836211204529
    },
    {
      "sentence": "Furthermore, when pressing the nger and nger ring on the touchscreen, it was uncomfortable for the participants for certain angles and postures.",
      "label": "Background",
      "prob": 0.8355237245559692
    },
    {
      "sentence": "Most prior work on making touchscreens accessible has as sumed access to change or add to the touchscreen hardware or software.",
      "label": "Background",
      "prob": 0.8340906500816345
    },
    {
      "sentence": "Crowd-powered systems robustly make visual information accessible to blind people.",
      "label": "Background",
      "prob": 0.8335371613502502
    },
    {
      "sentence": "When a transition happens on the dynamic interface, the new state might not have been seen before.",
      "label": "Background",
      "prob": 0.8321363925933838
    },
    {
      "sentence": "For exam ple, a participant mentioned that once in a few weeks she would accidentally hit the settings button on her fridges touch screen panel, then she needed to call someone to come and check on it, which has been a huge burden.",
      "label": "Background",
      "prob": 0.8283483982086182
    },
    {
      "sentence": "VizLens users would also need to take pictures when the screen changes, which is difcult.",
      "label": "Background",
      "prob": 0.8274850249290466
    },
    {
      "sentence": "StateLens is intended to solve a longstanding and hard problem at the intersection of these spaces.",
      "label": "Background",
      "prob": 0.8265438079833984
    },
    {
      "sentence": "We do so because the rst few candidates often include transition residuals from the previous state, such as animations.",
      "label": "Background",
      "prob": 0.8262221813201904
    },
    {
      "sentence": "The nger cap prevents ac cidental touches by shielding undesirable areas of the nger from touching the touchscreen.",
      "label": "Background",
      "prob": 0.8202124238014221
    },
    {
      "sentence": "For example, a search on YouTube for coca cola freestyle machine demo produces many usage videos.",
      "label": "Background",
      "prob": 0.8132691979408264
    },
    {
      "sentence": "Other approaches include generalizing based on the existing states or other machines, and relying more on OCR.",
      "label": "Background",
      "prob": 0.8080779314041138
    },
    {
      "sentence": "StateLens is the rst system to enable access to dynamic touchscreens in-the-wild, that addresses the very hard case in which blind users encounter a touchscreen that is inaccessible and unfamiliar, which they cannot modify the hardware or software, and whose screen updates dynamically to show new information and interface components.",
      "label": "Background",
      "prob": 0.8068566918373108
    },
    {
      "sentence": "Copyrights for components of this work owned by others than ACM must be honored.",
      "label": "Background",
      "prob": 0.8063931465148926
    },
    {
      "sentence": "This can help users understand the relative positions of elements, but they still have the challenge of physically locating the elements in space on the real interface in order to use it.",
      "label": "Background",
      "prob": 0.8058412671089172
    },
    {
      "sentence": "VizLens::State Detection is able to do limited adaptation to dynamic interfaces by matching against every possible state and providing feedback based on the best match.",
      "label": "Background",
      "prob": 0.7997468113899231
    },
    {
      "sentence": "He would nd it useful if, for example, a button for a coffee selection labeled Rainbows End could further be described as a coffee blend containing tasting notes of nuts and citrus even though the display does not provide that information.",
      "label": "Background",
      "prob": 0.7986535429954529
    },
    {
      "sentence": "As with most systems, StateLens currently has some limita tions, which we believe could be explored in future work.",
      "label": "Background",
      "prob": 0.7964475154876709
    },
    {
      "sentence": "These accessories add risk-free exploration to ex isting touchscreen devices without modifying the underlying hardware or software.",
      "label": "Background",
      "prob": 0.7935880422592163
    },
    {
      "sentence": "the notion of risk-free exploration to counter this problem [24], but their solution (requiring multiple taps instead of just one) requires being able to modify how the touchscreen oper ates.",
      "label": "Background",
      "prob": 0.7929877042770386
    },
    {
      "sentence": "On the other hand, if continuous unmatched states in the pool do not reach the window size to qualify as a new state, they are considered noise and the candidate pool will be cleared.",
      "label": "Background",
      "prob": 0.7908400893211365
    },
    {
      "sentence": "For example, RetroFab [31] is a design and fabrication environment that allows non-experts to retrot physical interfaces, in order to increase usability and accessibility.",
      "label": "Background",
      "prob": 0.7897550463676453
    },
    {
      "sentence": "However, in the future, these processes can be sped up and the produced bounding boxes can be tracked across frames to offer better performance.",
      "label": "Background",
      "prob": 0.7849318385124207
    },
    {
      "sentence": "Participants remarked that interfaces are becoming much less accessible as at touch pads and touchscreens replace physical buttons.",
      "label": "Background",
      "prob": 0.784089207649231
    },
    {
      "sentence": "We also focused on capacitive touchscreens rather than resistive touch screens, since resistive screens usually require some pressure to activate so the issue of accidental activation is not as severe compared to capacitive touchscreens.",
      "label": "Background",
      "prob": 0.7827746272087097
    },
    {
      "sentence": "(i) touchscreens are inherently visual so a blind person cannot read what they say or identify user interface components,",
      "label": "Background",
      "prob": 0.7818282246589661
    },
    {
      "sentence": "StateLens heuristically generates training samples for the intents and prompts to the required entities from the descriptive texts along different paths aforementioned.",
      "label": "Background",
      "prob": 0.774950385093689
    },
    {
      "sentence": "StateLens is intended to make user interfaces accessible that are on public touchscreen devices, to which access is purposefully restricted.",
      "label": "Background",
      "prob": 0.7732535004615784
    },
    {
      "sentence": "A set of 3D-printed accessories enable capacitive touchscreens to be used non-visually by preventing accidental touches on the interface.",
      "label": "Background",
      "prob": 0.7706076502799988
    },
    {
      "sentence": "Past research has introduced fabrication techniques for retrotting and improving the acces sibility of physical interfaces.",
      "label": "Background",
      "prob": 0.7691443562507629
    },
    {
      "sentence": "Almost all of this subset of participants (7) had a strong familiarity with using VoiceOver on an iPhone or iPad, suggesting their habitual use of this tech nology may inuence their interactions using the accessories.",
      "label": "Background",
      "prob": 0.7677822113037109
    },
    {
      "sentence": "If an input image is not a match with the existing states, StateLens adds it to a can didate pool.",
      "label": "Background",
      "prob": 0.7673579454421997
    },
    {
      "sentence": "A low vision user (P12) mentioned that even though he might not always need assistance, if the interfaces contrast or bright ness is poor, a system like StateLens would be greatly helpful as a conrmation.",
      "label": "Background",
      "prob": 0.7662174701690674
    },
    {
      "sentence": "Sikuli [38] uses computer vision to identify GUI components in screen captures for search and automation in the interfaces.",
      "label": "Background",
      "prob": 0.7661553621292114
    },
    {
      "sentence": "This is likely because the conductive material is less sensitive compared to ngers.",
      "label": "Background",
      "prob": 0.7642581462860107
    },
    {
      "sentence": "StateLens takes point-of-view usage videos of dynamic inter faces from various sources as input to build up state diagrams about interface structures.",
      "label": "Background",
      "prob": 0.7637521028518677
    },
    {
      "sentence": "To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specic permission and/or a fee.",
      "label": "Background",
      "prob": 0.7615485191345215
    },
    {
      "sentence": "More generally, StateLens demonstrates the value in a hybrid, reciprocal relationship between humans and AI to col laboratively solve real-world, real-time accessibility problems.",
      "label": "Background",
      "prob": 0.7584142088890076
    },
    {
      "sentence": "This is because the screen detection and OCR processes have longer delays (~1 second).",
      "label": "Background",
      "prob": 0.7576297521591187
    },
    {
      "sentence": "Although the Thingiverse designs are closely re lated to assistive usage for touchscreens, none of them satisfy our need to enable blind users risk-free access to an existing touchscreen device.",
      "label": "Background",
      "prob": 0.7561931610107422
    },
    {
      "sentence": "Risk-free exploration allows blind users to freely explore with out accidentally triggering functions on the screen, all without modifying the underlying hardware or software of the device.",
      "label": "Background",
      "prob": 0.7553838491439819
    },
    {
      "sentence": "For instance, FrameWire [29] automatically extracts interaction ows from video recordings of paper prototype user tests.",
      "label": "Background",
      "prob": 0.7497680187225342
    },
    {
      "sentence": "StateLens detects whether a screen is present and its bound ing box in the cameras eld of view to lter out irrelevant video frames and random background content.",
      "label": "Background",
      "prob": 0.7495826482772827
    },
    {
      "sentence": "Partic ipants noted that if it were for a one-time use, it would not be worthwhile to invest the time and effort to learn the interface, which is much easier for sighted people.",
      "label": "Background",
      "prob": 0.7472052574157715
    },
    {
      "sentence": "Waken [2] recognizes UI components and activities from screencast videos, without any prior knowledge of that application.",
      "label": "Background",
      "prob": 0.7423661947250366
    },
    {
      "sentence": "Fourth, StateLens applies a similar approach to the candidate pool for smoothing, and only when a new state has been seen continuously across multiple frames, it is condent enough to determine a state transition.",
      "label": "Background",
      "prob": 0.7410298585891724
    },
    {
      "sentence": "StateLens allows users to interact with a natural language con versational agent to prespecify the task they want to achieve.",
      "label": "Background",
      "prob": 0.7361500263214111
    },
    {
      "sentence": "StateLens uses the description text from state S as the welcome prompt and adds conrmation prompts at the end of intents.",
      "label": "Background",
      "prob": 0.7358408570289612
    },
    {
      "sentence": "Because Dialogow only requires a small number of user ut terance samples for training, StateLens uses a random sample of entity values and concatenates with phrases such as Select ... to create training sentences.",
      "label": "Background",
      "prob": 0.7340444922447205
    },
    {
      "sentence": "Sub stantial prior work exists in reverse engineering user interfaces using computer vision from pixels.",
      "label": "Background",
      "prob": 0.729979932308197
    },
    {
      "sentence": "This approach has been recognized as one of the most universally applicable meth ods for understanding a user interfaces components, which is somewhat surprising given that at some level most user inter faces have been created with libraries that in some way had knowledge of their semantics.",
      "label": "Background",
      "prob": 0.7280747890472412
    },
    {
      "sentence": "Touchscreen appliances mentioned by participants were very diverse, and their interfaces differed in size, type of functions and number of buttons.",
      "label": "Background",
      "prob": 0.727393388748169
    },
    {
      "sentence": "Participants also mentioned sighted peo ple giving incorrect or incomplete information because of a lack of patience or experience helping blind people.",
      "label": "Background",
      "prob": 0.7258966565132141
    },
    {
      "sentence": "Note that for performance reasons, only SURF features are used when detecting states to provide real-time feedback for blind users.",
      "label": "Background",
      "prob": 0.7194849848747253
    },
    {
      "sentence": "StateLens is quite lenient in this step to prevent accidentally removing relevant frames, in order to maintain a high recall.",
      "label": "Background",
      "prob": 0.715703010559082
    },
    {
      "sentence": "Blind users could brush a phone case on the external touchscreen, then the built-in camera would capture, recognize, and instruct actuators contacting the external screen to trigger functions at the right place and time.",
      "label": "Background",
      "prob": 0.7107619643211365
    },
    {
      "sentence": "Special thanks to Patrick Carrington, Meredith Ringel Morris, Zheng Yao, and Xu Wang for their help and support.",
      "label": "Background",
      "prob": 0.7052258253097534
    },
    {
      "sentence": "For blind users accessing the interface with a 3D-printed accessory, a color marker on the accessory can be used to identify the touchpoint location.",
      "label": "Background",
      "prob": 0.7051008939743042
    },
    {
      "sentence": "Through these state diagrams, StateLens pro vides interactive feedback and guidance to help blind users prespecify task and access the touchscreen interfaces.",
      "label": "Background",
      "prob": 0.7018553614616394
    },
    {
      "sentence": "Rather than requiring crowd workers to draw bounding boxes around all buttons and provide text annota tions, the OCR-assisted crowd interface allows them to simply conrm or reject OCR-generated labels, and revise any er rors.",
      "label": "Background",
      "prob": 0.7011985778808594
    },
    {
      "sentence": "VizLens [17] is a screen reader to help blind people use inac cessible static interfaces in the real world ( e.g. , the buttons on a microwave).",
      "label": "Background",
      "prob": 0.697765588760376
    },
    {
      "sentence": "StateLens uses the state diagram and the associated aggrega tion of interaction traces to automatically generate a natural language summary of the devices popular use cases.",
      "label": "Background",
      "prob": 0.6921409368515015
    },
    {
      "sentence": "Another interesting observation was that 8 of 13 participants who completed the tasks for the printed accessories would occasionally perform a double-click, or two taps in quick succession to activate the screen.",
      "label": "Background",
      "prob": 0.6921092867851257
    },
    {
      "sentence": "Our formative study identied challenges and re quirements, which informed the design and architecture of StateLens.",
      "label": "Background",
      "prob": 0.6889358758926392
    },
    {
      "sentence": "[22] combine a number of useful computer vision techniques with mouse information to auto matically identify clickable targets in the interface.",
      "label": "Background",
      "prob": 0.6855409145355225
    },
    {
      "sentence": "Note that the task completion time is likely to reduce in prac tice, since the agents speaking rate is dependent on the users screen reader setting, and after repeated usage, the users will get familiar with the functions.",
      "label": "Background",
      "prob": 0.6788572669029236
    },
    {
      "sentence": "StateLens identies the current state of the dynamic interface, and recognizes the users touchpoint location to provide realtime feedback and guidance for blind users through the iOS application.",
      "label": "Background",
      "prob": 0.6743676066398621
    },
    {
      "sentence": "StateLens also provides feedback to users when the interface is partially out of frame by detecting whether the corners of the interface are inside the camera frame.",
      "label": "Background",
      "prob": 0.671587347984314
    },
    {
      "sentence": "Static physical interfaces can be augmented with tactile over lays to make them accessible.",
      "label": "Background",
      "prob": 0.6710560917854309
    },
    {
      "sentence": "(iii) a blind person does not have the option to choose a different touchscreen platform that would be more accessible and cannot get access to the software or hardware to make it work better.",
      "label": "Background",
      "prob": 0.6691910028457642
    },
    {
      "sentence": "Each screen iteration would take several minutes, making it cumbersome to use for dynamic interfaces.",
      "label": "Background",
      "prob": 0.6674434542655945
    },
    {
      "sentence": "This approach can work for many static interfaces, but struggles when the interface changes dynamically (as most touchscreens do), and cannot solve the problem of how a blind user could interact with a touchscreen without accidentally triggering touches.",
      "label": "Background",
      "prob": 0.6652664542198181
    },
    {
      "sentence": "If not, it provides feedback such as move phone to right.",
      "label": "Background",
      "prob": 0.6647422909736633
    },
    {
      "sentence": "Furthermore, StateLens cannot currently handle major updates and layout changes of the interface, as well as list menus, slide bars or other gestures ( e.g. , scroll, swipe, pinch).",
      "label": "Background",
      "prob": 0.654350221157074
    },
    {
      "sentence": "Changes to the devices can be automatically detected over time to update the interface state diagram.",
      "label": "Background",
      "prob": 0.6542081832885742
    },
    {
      "sentence": "Similarly, it provides feedback when it does not detect the interface or does not see a nger (using words or earcons [7] for no object or no nger).",
      "label": "Background",
      "prob": 0.6536481380462646
    },
    {
      "sentence": "Furthermore, StateLens aggregates these interaction traces to provide ranked usage suggestions to assist novice users.",
      "label": "Background",
      "prob": 0.652934730052948
    },
    {
      "sentence": "RegionSpeak [40] and Touch Cursor [19] enable spatial exploration of the layout of objects in a photograph using a touchscreen.",
      "label": "Background",
      "prob": 0.6528863906860352
    },
    {
      "sentence": "For example, Chorus:View [27] pairs a user with a group of crowd workers using a managed dialogue and a shared video stream.",
      "label": "Background",
      "prob": 0.6518035531044006
    },
    {
      "sentence": "Because our smoothing approach requires a new state to be seen continuously across multiple frames in order to determine a state transition, there may be a delay in determining if a button press was successful.",
      "label": "Background",
      "prob": 0.6513044834136963
    },
    {
      "sentence": "Prefab [12] identies GUI elements using GUI-specic visual features, which en ables overlaying advanced interaction techniques on top of existing interfaces.",
      "label": "Background",
      "prob": 0.651084840297699
    },
    {
      "sentence": "(ii) a blind person cannot touch the touchscreen to explore with out the risk of accidentally triggering something they did not intend, and,",
      "label": "Background",
      "prob": 0.6481060981750488
    },
    {
      "sentence": "It provides a physical affordance to prevent accidental touches, by delineating the conductive and non conductive regions with a rectangular bumper located on the side of the stylus.",
      "label": "Background",
      "prob": 0.645328938961029
    },
    {
      "sentence": "StateLens employs several techniques to enable efcient searching of states to reduce latency and prevent errors.",
      "label": "Background",
      "prob": 0.6450510621070862
    },
    {
      "sentence": "Compared to the ring design, the nger caps enlarged shielding area and top cover prevent accidental touches more effectively and ensure consistency across sessions.",
      "label": "Background",
      "prob": 0.6450298428535461
    },
    {
      "sentence": "The fea ture vectors are then matched using brute-force matcher with normalization type of L2 norms, which is the preferable choice",
      "label": "Background",
      "prob": 0.6441028118133545
    },
    {
      "sentence": "For existing physical devices whose underlying hard ware or software cannot be modied, point-of-view videos are more prevalent and easier to acquire compared to screencast videos, which makes our approach generalizable to a large variety of devices and scenarios.",
      "label": "Background",
      "prob": 0.6431854367256165
    },
    {
      "sentence": "With VizLens, at each step, a good picture must be taken, labeled, and only afterwards can users explore the buttons on the single screen.",
      "label": "Background",
      "prob": 0.6426083445549011
    },
    {
      "sentence": "Slide Rule developed multi-touch gestures that could control touchscreens non-visually [24], which have informed the popular VoiceOver screen reader on the iPhone.",
      "label": "Background",
      "prob": 0.6401413679122925
    },
    {
      "sentence": "We thank the participants who contributed to our studies for their time, and the reviewers for their valuable feed back and suggestions.",
      "label": "Background",
      "prob": 0.6381210088729858
    },
    {
      "sentence": "If so, the full video frame is retained and used for further processing.",
      "label": "Background",
      "prob": 0.6335023641586304
    },
    {
      "sentence": "Furthermore, he would like to get more information beyond the text labels on the buttons by using StateLens as a cognitive assistant.",
      "label": "Background",
      "prob": 0.6308277249336243
    },
    {
      "sentence": "On the other hand, if both the matched inlier ratio and the OCR similarity score are below a certain threshold, StateLens determines it as not a match.",
      "label": "Background",
      "prob": 0.6283240914344788
    },
    {
      "sentence": "accessories make exploration possible by bringing risk-free exploration to touchscreens.",
      "label": "Background",
      "prob": 0.6270104050636292
    },
    {
      "sentence": "After StateLens generated the states, researchers manually coded them as correct, missing, or redundant in order to calculate precision and recall.",
      "label": "Background",
      "prob": 0.6254530549049377
    },
    {
      "sentence": "While we strove to make this paper self-contained, it builds on our long his tory of work involving thousands of blind people as students, researchers, participants, and users.",
      "label": "Background",
      "prob": 0.6251184344291687
    },
    {
      "sentence": "The completeness of the state diagram is limited by the cov erage of the videos collected for the device.",
      "label": "Background",
      "prob": 0.6241194009780884
    },
    {
      "sentence": "Crowd workers are then instructed to provide labels to the individual interaction components ( e.g. , buttons) assisted with OCR output.",
      "label": "Background",
      "prob": 0.619426965713501
    },
    {
      "sentence": "To help blind users access the dynamic interfaces, StateLens takes advantage of the state diagram to efciently identify states, integrates natural language agents, and interactively provides feedback and guidance (Figure 1).",
      "label": "Background",
      "prob": 0.6159884929656982
    },
    {
      "sentence": "We collected a total of 28 videos from a diverse set of eight dy namic touchscreen interfaces, in different lighting conditions, and with both stationary and hand-held cameras, resulting in a total of 40,140 video frames.",
      "label": "Background",
      "prob": 0.6149524450302124
    },
    {
      "sentence": "Some of the prior work has gone beyond the task of identifying individual GUI components from static photos, and looked instead to extract interaction ows from screencast videos and screen metadata provided by the system API.",
      "label": "Background",
      "prob": 0.6116052865982056
    },
    {
      "sentence": "Our solution should support more uid interactions to reduce blind users cognitive effort in exploring the interface layout and accessing functions on complex and unfamiliar touchscreen devices.",
      "label": "Background",
      "prob": 0.6074941754341125
    },
    {
      "sentence": "Better affordances could further improve learnability as one participant (P14) noted that a conductive stylus design which incorporates a physical button to trigger, instead of a conduc tive region, would be benecial.",
      "label": "Background",
      "prob": 0.6070412993431091
    },
    {
      "sentence": "The conversational agent and the iOS application were installed on an iPhone 6, running iOS 12.2 with VoiceOver enabled.",
      "label": "Background",
      "prob": 0.6019614934921265
    },
    {
      "sentence": "People who are blind were involved throughout the research, including several people with visual impairments on our ex tended research team, and multiple sessions of design and study with a total of 30 outside participants.",
      "label": "Background",
      "prob": 0.601229727268219
    },
    {
      "sentence": "from a general category ( e.g. , coffee drinks), but can freely choose the other properties ( e.g. , coffee type, strength, size).",
      "label": "Background",
      "prob": 0.5935880541801453
    },
    {
      "sentence": "By generating and using state diagrams, StateLens enables a cru cial interaction of previewing and prespecifying tasks through a conversational agent (analogous to using map applications to plan trips and follow turn-by-turn directions).",
      "label": "Background",
      "prob": 0.5920445919036865
    },
    {
      "sentence": "We extracted key insights that re ected participants challenges and strategies, which we used in the design of StateLens.",
      "label": "Background",
      "prob": 0.5909348130226135
    },
    {
      "sentence": "Regarding the different video sources, stationary videos generally performed better com pared to hand-held ones for the same interface, because state matching is more robust with less camera blur, changing back ground noise and other uncertainty from camera motion.",
      "label": "Background",
      "prob": 0.5904679894447327
    },
    {
      "sentence": "Next, participants were asked to talk to the conversational agent to prespecify drinks they want to order from the coffee machine for three times.",
      "label": "Background",
      "prob": 0.5902207493782043
    },
    {
      "sentence": "In response, recent work has con sidered making existing interfaces accessible using computer vision and crowdsourcing to interpret the interfaces on-the-y and provide immediate feedback to users [17].",
      "label": "Background",
      "prob": 0.5899749994277954
    },
    {
      "sentence": "P12 had low vision, and was able to hover his nger above the target and then activate by him self.",
      "label": "Background",
      "prob": 0.5849897265434265
    },
    {
      "sentence": "If not, the frame is determined irrelevant and discarded.",
      "label": "Background",
      "prob": 0.5839190483093262
    },
    {
      "sentence": "This paper is about enabling blind people to use the touchscreens they encounter in-the-wild , despite the fact that nothing about how these systems are designed is intended for their use.",
      "label": "Background",
      "prob": 0.5774009823799133
    },
    {
      "sentence": "Facade [18] is a crowdsourced fabrication pipeline to help blind people independently make physical interfaces accessible by adding a 3D-printed augmentation of tactile buttons overlaying the original panel.",
      "label": "Background",
      "prob": 0.5771309733390808
    },
    {
      "sentence": "Furthermore, using the coffee machine with all 14 states, StateLens can still maintain suf cient speed for audio-guided interaction (~5fps), while the baseline approach dropped to ~2fps and became unusable.",
      "label": "Background",
      "prob": 0.5767195820808411
    },
    {
      "sentence": "tence ( e.g. , I want a large coffee 50-50, shown in Figure 5).",
      "label": "Background",
      "prob": 0.5742879509925842
    },
    {
      "sentence": "The advantages were mostly observed in the precision differences and especially for web videos, as irrelevant frames and noisy background were ltered out.",
      "label": "Background",
      "prob": 0.571684718132019
    },
    {
      "sentence": "Identifying States Efciently and Robustly",
      "label": "Background",
      "prob": 0.5663365721702576
    },
    {
      "sentence": "poor, StateLens gradually expands the search space to other states of the interface according to the distance, calculated as the shortest path in the state diagram.",
      "label": "Background",
      "prob": 0.5649160742759705
    },
    {
      "sentence": "In the current work, we demon strate StateLens with videos captured from stationary cameras, hand-held mobile phones and web video repositories.",
      "label": "Background",
      "prob": 0.5642651915550232
    },
    {
      "sentence": "The screen detection technique did not work well for the Coca-Cola machine, as the object detection model would not classify it as electronics",
      "label": "Background",
      "prob": 0.562581479549408
    },
    {
      "sentence": "Following a brief introduction of the study and demographic questions, participants rst completed tasks using the 3D printed accessories.",
      "label": "Background",
      "prob": 0.558815598487854
    },
    {
      "sentence": "Using this candidate pool approach, only when the same im age is seen continuously across multiple frames, StateLens is condent enough to register it as a new state.",
      "label": "Background",
      "prob": 0.5551061630249023
    },
    {
      "sentence": "These videos can be collected in many ways, including through existing IoT and surveillance cameras, through motivating sighted volunteers to contribute videos using mobile and wearable cameras, by encouraging manufacturers to share videos as a low-cost way to make their systems accessible to more people, and by mining existing demo and tutorial videos in online repositories.",
      "label": "Background",
      "prob": 0.553856611251831
    },
    {
      "sentence": "We conducted semi-structured interviews with 16 blind people about their ex periences and challenges with public touchscreen appliances, and their strategies for overcoming these challenges.",
      "label": "Background",
      "prob": 0.5533602833747864
    },
    {
      "sentence": "We varied the total number of states involved from one to all 14, and plotted the amount of processing time required for identifying the current state.",
      "label": "Background",
      "prob": 0.5526681542396545
    },
    {
      "sentence": "Using the state diagrams, StateLens automatically generates conversational agents that guide blind users to prespecify tasks (Figure 5).",
      "label": "Background",
      "prob": 0.5483028888702393
    },
    {
      "sentence": "In this step, crowd workers also work in parallel, and the worker interface shows labeled elements to other workers as they are completed.",
      "label": "Background",
      "prob": 0.5452451705932617
    },
    {
      "sentence": "The StateLens iOS application then provides interactive guid ance and feedback to help blind users access the interfaces (Figure 1).",
      "label": "Background",
      "prob": 0.5417992472648621
    },
    {
      "sentence": "Therefore, our solution should support risk-free exploration to enable blind users freely explore without accidentally trig gering functions on the screen.",
      "label": "Background",
      "prob": 0.5344775915145874
    },
    {
      "sentence": "We also manually selected web videos of four touchscreen interfaces, resulting in a total of 32,610 video frames.",
      "label": "Background",
      "prob": 0.5275297164916992
    },
    {
      "sentence": "This natural lan guage summary is also integrated in the conversational agent (Figure 5), and users can simply ask, e.g. , tell me a summary.",
      "label": "Background",
      "prob": 0.5269346237182617
    },
    {
      "sentence": "Then, for the next images which are also added into this pool, they are matched against the existing candidates.",
      "label": "Background",
      "prob": 0.5246433615684509
    },
    {
      "sentence": "The advan tages were mostly observed in the recall differences, and specically for interfaces that had many similar screens in graphical layout with only text changes, e.g. , coffee machine (graphical), coffee machine (text-only), projector control, and room reservation interfaces.",
      "label": "Background",
      "prob": 0.5189589858055115
    },
    {
      "sentence": "The stylus uses a conductive trace to trig ger touches at the tip of the stylus when touched by a nger (Figure 3GHI).",
      "label": "Background",
      "prob": 0.5161092877388
    },
    {
      "sentence": "[9] propose an accessibility and pixel-based framework, which also allow for detecting text and arbitrary word blobs in user interfaces.",
      "label": "Background",
      "prob": 0.5014029145240784
    },
    {
      "sentence": "Note that here b m represents the button identier in the metadata of from state that caused the state transition into to state.",
      "label": "Background",
      "prob": 0.5008835792541504
    },
    {
      "sentence": "To address this problem, special-purpose models for detecting screens could be built.",
      "label": "Background",
      "prob": 0.49528181552886963
    },
    {
      "sentence": "Furthermore, the generated state diagrams effectively reduced latency and prevented errors in the state detection process.",
      "label": "Background",
      "prob": 0.4943312108516693
    },
    {
      "sentence": "Using a hybrid crowd-computer vision pipeline, StateLens generates state diagrams about interface structures from point-of-view usage videos.",
      "label": "Background",
      "prob": 0.4932621717453003
    },
    {
      "sentence": "Once all required entities are fullled, the StateLens iOS application will proceed to guiding the users to activate each button on the predened interaction trace.",
      "label": "Background",
      "prob": 0.48959606885910034
    },
    {
      "sentence": "Users often ask questions about interfaces [8], but it can be difcult to map the answers received, e.g. , the stop button is in the middle of the bottom row of buttons, to actually using the interface because doing so requires locating the referenced object in space ( e.g. , place a nger on the button).",
      "label": "Background",
      "prob": 0.47601625323295593
    },
    {
      "sentence": "Our work goes beyond VizLens by enabling access to dynamic touchscreens.",
      "label": "Background",
      "prob": 0.4727482795715332
    },
    {
      "sentence": "This nger-worn design also incorporates a slit so that when 3D printed with a exible material ( e.g. , thermoplastic polyurethane  TPU), it can t around ngers of different sizes.",
      "label": "Background",
      "prob": 0.4693436026573181
    },
    {
      "sentence": "The architecture of StateLens to generate state diagrams (Fig ure 2) involves capturing point-of-view usage videos from a variety of sources, representing state diagrams, detecting screen regions, identifying existing and new states, soliciting labels from the crowd, as well as recognizing user interactions.",
      "label": "Background",
      "prob": 0.4687071740627289
    },
    {
      "sentence": "Other systems provide more continuous support.",
      "label": "Background",
      "prob": 0.4655837118625641
    },
    {
      "sentence": "Once a new state is registered, StateLens then sends it to the crowdsourced labeling pipeline to acquire more infor mation such as the interface region, interaction components, and description (Figure 2).",
      "label": "Background",
      "prob": 0.46408769488334656
    },
    {
      "sentence": "Our solution should enable blind people to independently access touchscreen devices without needing sighted assistance.",
      "label": "Background",
      "prob": 0.4639335870742798
    },
    {
      "sentence": "Conductive traces can be applied using conductive paint or printed with conductive PLA on a dual",
      "label": "Background",
      "prob": 0.4638976752758026
    },
    {
      "sentence": "StateLens then looks up the coordinates of the touchpoint in the current states labeled interaction components, and an nounces feedback and guidance to the blind user, e.g. , state: coffee drinks, select strength; target: regular, move up, move left slowly and at regular, press it.",
      "label": "Background",
      "prob": 0.4628450274467468
    },
    {
      "sentence": "In the next section of Accessing the State Diagram, using the user interaction information, StateLens predicts the state that the interface could be transitioning to, and reduces the process ing latency and errors by narrowing down the search space.",
      "label": "Background",
      "prob": 0.4538479745388031
    },
    {
      "sentence": "Using the Google Dialogow API [15], StateLens automatically creates an agent for each device using these mappings.",
      "label": "Background",
      "prob": 0.45196086168289185
    },
    {
      "sentence": "A high precision indicates that most of the extracted states are unique screens of the actual interface (few duplicates).",
      "label": "Background",
      "prob": 0.4503277838230133
    },
    {
      "sentence": "We conducted a multi-part technical evaluation in order to understand how each key component of StateLens performs across a wide range of interfaces and usage scenarios.",
      "label": "Background",
      "prob": 0.4496062695980072
    },
    {
      "sentence": "In a formative study, we rst identied key challenges and design considerations for a system to provide access to dy namic touchscreen interfaces in the real world.",
      "label": "Background",
      "prob": 0.4475148320198059
    },
    {
      "sentence": "We have presented StateLens , a reverse engineering solution that makes existing dynamic touchscreens accessible.",
      "label": "Background",
      "prob": 0.44542446732521057
    },
    {
      "sentence": "the user through each required parameter needed to complete an interaction trace.",
      "label": "Background",
      "prob": 0.44313135743141174
    },
    {
      "sentence": "Additional states can be added to the existing diagram as users interact with the device.",
      "label": "Background",
      "prob": 0.44048118591308594
    },
    {
      "sentence": "StateLens builds on this rich literature, and applies a hybrid crowd-computer vision pipeline to automatically extract state diagrams about the underlying interface structures from point of-view usage videos.",
      "label": "Background",
      "prob": 0.4385441839694977
    },
    {
      "sentence": "Similarity is dened as the ratio of longest common sequence (LCS) edit distance to the length of the OCR output results, and if above a threshold, the candidate matched state is nalized as the matched state.",
      "label": "Background",
      "prob": 0.4383592903614044
    },
    {
      "sentence": "VizWiz lets blind people take a picture, speak a question, and get answers back from the crowd within approximately 30 seconds [6].",
      "label": "Other",
      "prob": 0.4628341495990753
    },
    {
      "sentence": "StateLens is not the ideal solution.",
      "label": "Background",
      "prob": 0.4323115050792694
    },
    {
      "sentence": "In this section, we discuss how the approaches used in StateLens might generalize to extract information from existing online videos to, for instance, assist sighted users and con struct a queryable map of devices.",
      "label": "Background",
      "prob": 0.43099597096443176
    },
    {
      "sentence": "StateLens works by reverse engineering state diagrams of existing interfaces from point-of-view usage videos using a hybrid crowd-computer vision pipeline (Figure 2).",
      "label": "Background",
      "prob": 0.42876380681991577
    },
    {
      "sentence": "First, when available, StateLens utilizes users ngertip location to infer from the state diagram about the state that the interface has transitioned to, e.g. , using the button that the nger was on.",
      "label": "Background",
      "prob": 0.428460955619812
    },
    {
      "sentence": "Our design variations consist of a nger cap (Figure 3D) and a conductive stylus (Figure 3G).",
      "label": "Background",
      "prob": 0.4282025098800659
    },
    {
      "sentence": "If a blind user needs to access an unseen state, StateLens could add it to the state diagram onthe-y, asking the user to wait for that screen to be labeled and then added to the full state diagram.",
      "label": "Background",
      "prob": 0.42500898241996765
    },
    {
      "sentence": "Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for prot or commercial advantage and that copies bear this notice and the full citation on the rst page.",
      "label": "Other",
      "prob": 0.48021334409713745
    },
    {
      "sentence": "Using StateLens, we envision building a queryable map of state diagrams for many of the devices in the world using existing point-of-view videos that have been shared online.",
      "label": "Background",
      "prob": 0.4169052541255951
    },
    {
      "sentence": "The iPad Pro simulating the inaccessible coffee machine was placed tilted at chest level, and the iPhone 6 running the iOS application was mounted on a head strap to simulate a head-mounted camera.",
      "label": "Background",
      "prob": 0.4137381911277771
    },
    {
      "sentence": "In this paper, we developed a hybrid crowd-computer vision system to enable access to dynamic touchscreens in-the-wild.",
      "label": "Background",
      "prob": 0.4126690626144409
    },
    {
      "sentence": "Our next step is to harden our implementation to scale to many users, and deploy it to understand how it performs in the ev eryday lives of blind people.",
      "label": "Background",
      "prob": 0.40682148933410645
    },
    {
      "sentence": "If not, StateLens checks whether the output labels with high condence scores (above 55%) appears in the above categories.",
      "label": "Background",
      "prob": 0.40441492199897766
    },
    {
      "sentence": "Through understanding of the state diagrams of devices with readily available or user-taken point-of-view videos, our approach can provide additional information to the user as they interact with the devices ( e.g. , augmented reality applications for translation services, interactive tutorials).",
      "label": "Background",
      "prob": 0.404091477394104
    },
    {
      "sentence": "As future work, we have started to design hardware proxies that can locate and actuate external touchscreens automatically.",
      "label": "Objective",
      "prob": 0.4627816081047058
    },
    {
      "sentence": "For example, physical buttons were added to the",
      "label": "Background",
      "prob": 0.39740389585494995
    },
    {
      "sentence": "For all Likert scale questions, par ticipants rated along a scale of 1 to 7, where 1 was extremely negative and 7 was extremely positive.",
      "label": "Background",
      "prob": 0.3972585201263428
    },
    {
      "sentence": "To do this, StateLens ranks the aggregated interaction traces, then generates prompts for each trace based on the involved state and transition metadata as well as the corresponding interac tion components.",
      "label": "Method",
      "prob": 0.4089290499687195
    },
    {
      "sentence": "[25] apply a crowdsourcing workow to extract step-by-step structure from existing online tutorial videos.",
      "label": "Method",
      "prob": 0.42148590087890625
    },
    {
      "sentence": "The number of accidental triggers during exploration, and the number of attempts during activation were recorded.",
      "label": "Background",
      "prob": 0.38963329792022705
    },
    {
      "sentence": "Using An droids accessibility API, Sugilite [28] and Interaction Proxies [39] extract the screen structures, in order to create automa tion and improve mobile application accessibility.",
      "label": "Background",
      "prob": 0.3851802349090576
    },
    {
      "sentence": "While the 3D-printed nger ring enabled our participants to explore without accidental triggers, participants also identied issues related with the design and suggested other solutions.",
      "label": "Background",
      "prob": 0.3800649344921112
    },
    {
      "sentence": "We also discuss limitations of our work, which represent opportunities for future research.",
      "label": "Background",
      "prob": 0.3796827793121338
    },
    {
      "sentence": "Using the Amazon Rekognition Object Detection API [1], StateLens rst detects bounding boxes of object cate gories related to electronics and machines.",
      "label": "Method",
      "prob": 0.4073125123977661
    },
    {
      "sentence": "Others preferred the nger cap since it provided better control over the stylus.",
      "label": "Result",
      "prob": 0.44073402881622314
    },
    {
      "sentence": "We had success with both techniques, though conductive PLA was more durable, while conductive paint can come off after repeated use.",
      "label": "Result",
      "prob": 0.4523179829120636
    },
    {
      "sentence": "For each trial, participants were rst instructed to explore by placing the accessory on the touchscreen and move according to the researchers verbal instructions without activating touches.",
      "label": "Method",
      "prob": 0.41155076026916504
    },
    {
      "sentence": "Informed by the participants feedback to our initial prototype, we designed variations of 3D-printed accessories (Figure 3DG) that focus on improving stability and comfort during use.",
      "label": "Background",
      "prob": 0.37401100993156433
    },
    {
      "sentence": "Imagine sitting down for a 12-hour ight only to realize that the entertainment center on the seatback in front of you can only be controlled by its inaccessible touchscreen; imagine checking out at the grocery store and being required to tell the cashier your pin number out loud because the checkout kiosk is an inaccessible touchscreen; and, imagine not being able to independently make yourself a coffee at your workplace because the fancy new coffee machine is controlled only by an inaccessible touchscreen.",
      "label": "Background",
      "prob": 0.3704853653907776
    },
    {
      "sentence": "We varied the total number of states involved from one to all 14, and plotted the percentage of errors in identifying the current state.",
      "label": "Result",
      "prob": 0.37740880250930786
    },
    {
      "sentence": "The cap has an opening on the nger pad that allows the user to tilt their nger to ac tivate a touch (Figure 3DEF).",
      "label": "Background",
      "prob": 0.3639128804206848
    },
    {
      "sentence": "These realis tic tasks involved a series of button pushes across many states, e.g. , select gourmet drinks, cafe latte, strong strength, then conrm, auto-select default coffee bean, and end on the drink preparation screen.",
      "label": "Background",
      "prob": 0.3633081912994385
    },
    {
      "sentence": "Soliciting Labels from the Crowd",
      "label": "Background",
      "prob": 0.3548926115036011
    },
    {
      "sentence": "The nger cap and the conductive stylus in Figure 3 were fabricated and used.",
      "label": "Background",
      "prob": 0.35477542877197266
    },
    {
      "sentence": "Next, according to the three interaction traces prespecied through the conversational agent, participants were asked to use the 3D-printed accessories to perform the tasks following the guidance and feedback of the iOS application.",
      "label": "Method",
      "prob": 0.3767695426940918
    },
    {
      "sentence": "StateLens represents the interface structure with a state diagram, as shown in Figure 2 and the instantiation of the coffee machine shown in Figure 4.",
      "label": "Result",
      "prob": 0.4081430435180664
    },
    {
      "sentence": "(ii) improving the accessibility of existing physical interfaces.",
      "label": "Background",
      "prob": 0.3346896767616272
    },
    {
      "sentence": "This paper introduces StateLens , a reverse engineering solution for making existing dynamic touchscreens accessible.",
      "label": "Objective",
      "prob": 0.5459657907485962
    },
    {
      "sentence": "We motivated our approach as a benet to improve accessibil ity for blind users.",
      "label": "Objective",
      "prob": 0.33965516090393066
    },
    {
      "sentence": "We tested this design in a pilot study with two blind partic ipants (one female, age 48; one male, age 57).",
      "label": "Result",
      "prob": 0.36617761850357056
    },
    {
      "sentence": "In our user study, we discovered issues around holding the accessories in certain angles, and the last meter problem to accurately activate the exact button once.",
      "label": "Result",
      "prob": 0.43469762802124023
    },
    {
      "sentence": "Essentially, StateLens uses the last image of the previous state V i before the state transition, transforms the input image to the reference image frame through warping, and detects the touchpoint lo cation using skin color thresholding and other standard image processing techniques [36].",
      "label": "Method",
      "prob": 0.4455307424068451
    },
    {
      "sentence": "StateLens uses a hybrid crowd-computer vision pipeline to dynamically generate state diagrams about interface structures from point-of-view usage videos, and to provide interactive feedback and guidance to help blind users access the interfaces through these diagrams.",
      "label": "Method",
      "prob": 0.5534073710441589
    },
    {
      "sentence": "We recruited 14 visually impaired users (9 female, 5 male, age 34-85).",
      "label": "Result",
      "prob": 0.40993258357048035
    },
    {
      "sentence": "Among the can didates identied as the same state, StateLens automatically selects the last one added to the pool as the reference image for this new state.",
      "label": "Result",
      "prob": 0.39820075035095215
    },
    {
      "sentence": "Participants mentioned that the head mount can be made more comfortable using a lighter setup, e.g. , glasses.",
      "label": "Background",
      "prob": 0.3120273947715759
    },
    {
      "sentence": "We conducted a formative study to identify the key challenges and design considerations for a system to provide access to dy namic touchscreen interfaces in the real world.",
      "label": "Objective",
      "prob": 0.31042736768722534
    },
    {
      "sentence": "Finally, the reference images can be pre-computed once in advance to improve processing speed.",
      "label": "Result",
      "prob": 0.3590453863143921
    },
    {
      "sentence": "StateLens rst uses SURF feature detectors to compute key points and feature vectors in both the existing state reference images (Figure 4) and the input image.",
      "label": "Method",
      "prob": 0.5030547976493835
    },
    {
      "sentence": "To do this, we introduce a set of simple 3D-printed accessories that allow users to explore without touching the screen with their nger, and perform a gesture to activate touch at a desired position.",
      "label": "Method",
      "prob": 0.40199631452560425
    },
    {
      "sentence": "These search terms resulted in a total of 103 existing designs.",
      "label": "Result",
      "prob": 0.5508491396903992
    },
    {
      "sentence": "Human-centered computing  Interactive systems and tools; Accessibility technologies;",
      "label": "Other",
      "prob": 0.6020939946174622
    },
    {
      "sentence": "Finally, we ended the study with a semi-structured interview asking for the participants comments and suggestions on the StateLens system.",
      "label": "Method",
      "prob": 0.31554561853408813
    },
    {
      "sentence": "Following our running example, the transition from the initial state S = V 0 = ( { b , b , b } , other metadata )",
      "label": "Other",
      "prob": 0.4950503408908844
    },
    {
      "sentence": "Parameters can be chosen to further maximize recall (sacri cing some precision), as post-hoc crowd validation can be applied in the future to further lter out duplicates.",
      "label": "Result",
      "prob": 0.3698083460330963
    },
    {
      "sentence": "It then uses the reference state with the distinctly highest ratio as the can didate matched state.",
      "label": "Result",
      "prob": 0.36298689246177673
    },
    {
      "sentence": "UIST '19, October 2023, 2019, New Orleans, LA, USA",
      "label": "Other",
      "prob": 0.684782087802887
    },
    {
      "sentence": "Our technical evaluation showed that StateLens can accurately reconstruct interface structures from stationary, hand-held, and web usage videos.",
      "label": "Result",
      "prob": 0.5948758721351624
    },
    {
      "sentence": "This is designed to assist novice users get familiar with the device.",
      "label": "Method",
      "prob": 0.3207182288169861
    },
    {
      "sentence": "Using an approach akin to afnity diagramming [5, 10, 21], we classied these items into ve main categories of devices: styluses, prosthetic accessories, nger caps, buttons and joy sticks.",
      "label": "Method",
      "prob": 0.4757940173149109
    },
    {
      "sentence": "One solution may be to detect and factor in UI widgets that are expected to change using approaches like those in PreFab [12] and TapShoe [32].",
      "label": "Other",
      "prob": 0.47087711095809937
    },
    {
      "sentence": "Next in user evaluation, we further demonstrate how the generated state diagrams power interactive applications to assist blind users access existing dynamic touchscreen devices.",
      "label": "Result",
      "prob": 0.37746530771255493
    },
    {
      "sentence": "The study took about two hours and participants were each compensated for $50.",
      "label": "Result",
      "prob": 0.337478369474411
    },
    {
      "sentence": "We evaluated StateLens across a number of touchscreen inter faces and with blind users in the lab, but we did not deeply study how StateLens works in the real world, which is often much more complicated and messier than in-lab studies.",
      "label": "Result",
      "prob": 0.6148879528045654
    },
    {
      "sentence": "All participants except P12 completed tasks using the 3D printed accessories.",
      "label": "Result",
      "prob": 0.593415379524231
    },
    {
      "sentence": "StateLens extracts two kinds of features and intelligently com bines them (Figure 2): SURF (Speeded-Up Robust Features) [3] and OCR.",
      "label": "Result",
      "prob": 0.3872804045677185
    },
    {
      "sentence": "(i) reverse engineering user interfaces, and",
      "label": "Other",
      "prob": 0.5551604628562927
    },
    {
      "sentence": "Since there is no existing models for detecting touchscreen interfaces, we re-purpose state-of-the-art object detection models output for this task.",
      "label": "Result",
      "prob": 0.466082364320755
    },
    {
      "sentence": "StateLens uses simple heuristic templatebased generation methods that concatenate words like I want ... with most frequently selected button options, i.e. entities, as well as the descriptive text of the intent.",
      "label": "Method",
      "prob": 0.5024548172950745
    },
    {
      "sentence": "The order of accessories was counterbalanced for all participants.",
      "label": "Result",
      "prob": 0.5149202942848206
    },
    {
      "sentence": "Second, StateLens searches the neighbors of previously iden tied state for the best match, in case when the inferred state from the ngertip location matches poorly with input image.",
      "label": "Result",
      "prob": 0.6637222170829773
    },
    {
      "sentence": "We rst evaluated the effectiveness of StateLens in reconstruct ing interface structures from stationary, hand-held, and web usage videos.",
      "label": "Result",
      "prob": 0.452251672744751
    },
    {
      "sentence": "(iii) SURF and OCR features, and",
      "label": "Other",
      "prob": 0.5024972558021545
    },
    {
      "sentence": "We rst conducted an exploratory search on Thingiverse to understand what openly available solutions exist for people to interact with touchscreens and see if they can enable risk-free exploration for blind people.",
      "label": "Result",
      "prob": 0.30226555466651917
    },
    {
      "sentence": "These approaches have looked to automatically extract GUI components from screenshot images in order to decouple GUI element representation from predened image templates [2, 9, 12, 22, 38], to augment existing interfaces through understanding of GUI components [2, 12], and to extract interaction ows from screencast videos and screen metadata [25, 28, 29, 39].",
      "label": "Result",
      "prob": 0.2722269594669342
    },
    {
      "sentence": "A sample user-agent interaction is shown in Figure 5.",
      "label": "Result",
      "prob": 0.5398874282836914
    },
    {
      "sentence": "Participants were then asked to activate a touch.",
      "label": "Method",
      "prob": 0.4469131529331207
    },
    {
      "sentence": "Our evaluations demonstrated the feasibility of StateLens in accurately reconstructing the state diagram, iden tifying interface states, and giving effective feedback and guid ance.",
      "label": "Result",
      "prob": 0.6236369013786316
    },
    {
      "sentence": "We created a list of 11 search terms including: touchscreen accessibility; touchscreen stylus; screen stylus; capacitive screen input; resistive screen; input assistive; assistive nger cap; nger cap; 3D printed acces sibility; conductive PLA accessibility; and prosthetic nger.",
      "label": "Result",
      "prob": 0.40407219529151917
    },
    {
      "sentence": "To do this, StateLens transforms all the possible paths (interaction traces) from S to T in the generated state diagram into different intents ( e.g. , to make coffee drinks, to make gourmet drinks), and the in teractive element values in the edges E i along the path into required entities for the intent and their attributes/values ( e.g. , size: large/medium/small).",
      "label": "Method",
      "prob": 0.45064833760261536
    },
    {
      "sentence": "Be My Eyes matches users to a single volunteer over a video stream [4].",
      "label": "Other",
      "prob": 0.747869610786438
    },
    {
      "sentence": "Then us ing a Wizard-of-Oz approach, we asked two participants to try using a touchscreen coffee machine with verbal instructions given by the researchers.",
      "label": "Method",
      "prob": 0.49616512656211853
    },
    {
      "sentence": "This work has been supported by the National Science Foun dation (#IIS-1816012), Google, and the National Institute on Disability, Independent Living, and Rehabilitation Research (NIDILRR).",
      "label": "Other",
      "prob": 0.6594824194908142
    },
    {
      "sentence": "We used these categories to inspire design ideas for prototypes that take on familiar forms used in the Thingiverse accessibility community but also support risk-free exploration (Figure 3).",
      "label": "Result",
      "prob": 0.5793328285217285
    },
    {
      "sentence": "Each edge (transition) from state V i to state V j is E i j  E that can be represented as E i j = ( { b 1 , b 2 , ..., b m } , V i , V j ) .",
      "label": "Other",
      "prob": 0.5626232624053955
    },
    {
      "sentence": "The re sults are shown in Table 2.",
      "label": "Result",
      "prob": 0.5724852681159973
    },
    {
      "sentence": "We represent a state diagram as a directed graph G = ( V , E , S , T ) where S is the start state and T = { T 1 , T 2 , ..., T n } con tains the end states where tasks are accomplished.",
      "label": "Method",
      "prob": 0.44192901253700256
    },
    {
      "sentence": "The designs aim to reduce the change of touchpoint when the user moves from exploration to interaction ( i.e. , touch acti vation), and maintain consistency across sessions.",
      "label": "Objective",
      "prob": 0.6999070048332214
    },
    {
      "sentence": "The 3D-printed",
      "label": "Other",
      "prob": 0.3818760812282562
    },
    {
      "sentence": "A high recall indicates that most of the screens of the interface are captured in the extracted states (good coverage).",
      "label": "Result",
      "prob": 0.7143300175666809
    },
    {
      "sentence": "(iv) Screen Detection, SURF, and OCR features.",
      "label": "Result",
      "prob": 0.4337490499019623
    },
    {
      "sentence": "( { b 1 , b 2 , ..., b n } , descriptions, coordinates, other metadata ) , where b n is one of the interactive elements ( e.g. , but tons) in state V i .",
      "label": "Other",
      "prob": 0.6764538884162903
    },
    {
      "sentence": "After each step of the study, we collected Likert scale ratings and subjective feedback from the participants.",
      "label": "Result",
      "prob": 0.38912656903266907
    },
    {
      "sentence": "One unique contribution of this work is that we demonstrated the possibility of extracting state diagrams from existing point of-view videos instead of screenshots or screencast videos [2, 26, 37].",
      "label": "Other",
      "prob": 0.3678086996078491
    },
    {
      "sentence": "side of the screen to provide a tactile way to provide input [34, 35].",
      "label": "Other",
      "prob": 0.6615217924118042
    },
    {
      "sentence": "For each interface and video source, we computed the preci sion, recall, and F1 scores for the extracted states using four congurations of features:",
      "label": "Result",
      "prob": 0.4326903820037842
    },
    {
      "sentence": "or machines.",
      "label": "Other",
      "prob": 0.6777825355529785
    },
    {
      "sentence": "We use a time window of 1 second for this process.",
      "label": "Result",
      "prob": 0.44513511657714844
    },
    {
      "sentence": "By ltering matches and nding the perspective transformation [11] between the reference-input image pairs using RANSAC (Random Sample Consensus) [13], StateLens is able to compute the ratios of inliers to the number of good matches for each existing state.",
      "label": "Method",
      "prob": 0.4322412610054016
    },
    {
      "sentence": "number of states increases, StateLens achieved a relatively stable processing time compared to the linear increase in the baseline approach (Figure 7).",
      "label": "Result",
      "prob": 0.7711287140846252
    },
    {
      "sentence": "On the other hand, participants preferred the n ger cap much more than the stylus (65% vs. 35%) in the 45 and 0 screen placements, since the nger cap became more comfortable to use in these positions ( M = 6 . 3 , SD = 0 . 8 ) .",
      "label": "Result",
      "prob": 0.6623193621635437
    },
    {
      "sentence": "(ii) Screen Detection and SURF features,",
      "label": "Result",
      "prob": 0.3213730454444885
    },
    {
      "sentence": "We show each of these categories with example items in Table 1.",
      "label": "Result",
      "prob": 0.6212817430496216
    },
    {
      "sentence": "Each node (state) V i  V can be represented as V i =",
      "label": "Other",
      "prob": 0.5878912806510925
    },
    {
      "sentence": "We next evaluated the effectiveness of using state diagrams to reduce latency and prevent errors in the state detection process.",
      "label": "Result",
      "prob": 0.44525274634361267
    },
    {
      "sentence": "We then ltered results that were not related to accessibility or assistive technology ( e.g. , raspberry pi and/or touchscreen cases), leading to a total of 39 relevant items.",
      "label": "Result",
      "prob": 0.7684636116027832
    },
    {
      "sentence": "Then through a user study with 14 blind participants, we showed that the conversational agent, the iOS application, and the 3D-printed accessories collectively helped blind users access otherwise inaccessible dynamic touchscreen devices effectively.",
      "label": "Result",
      "prob": 0.6266377568244934
    },
    {
      "sentence": "We now detail our user study results and summarize user feedback and preferences.",
      "label": "Result",
      "prob": 0.5884600877761841
    },
    {
      "sentence": "Overall, the combination of Screen Detection+SURF+OCR features achieved high performances across a wide range of interfaces, and were often the best in the four feature congurations.",
      "label": "Result",
      "prob": 0.7907593250274658
    },
    {
      "sentence": "The list of interfaces is shown in Figure 6, and summarized in Table 2.",
      "label": "Result",
      "prob": 0.6996684670448303
    },
    {
      "sentence": "Inspired by our formative study, the goal of the conversational agent is to reduce the time and effort of the blind users to explore, understand, and activate functions on inaccessible and unfamiliar touchscreen interfaces.",
      "label": "Objective",
      "prob": 0.7896773815155029
    },
    {
      "sentence": "Regarding OCR features, a combination of Screen Detec tion+SURF+OCR features generally had better performance compared to Screen Detection+SURF features.",
      "label": "Result",
      "prob": 0.7721295952796936
    },
    {
      "sentence": "Participants were instructed to order",
      "label": "Other",
      "prob": 0.48021501302719116
    },
    {
      "sentence": "Enabling Risk-Free Exploration",
      "label": "Other",
      "prob": 0.5437238812446594
    },
    {
      "sentence": "The goal of our user study was to evaluate how the components of StateLens (the 3D-printed accessories, the conversational agent, and the iOS application) perform in enabling blind people to accomplish realistic tasks that involve otherwise inaccessible dynamic touchscreen interfaces.",
      "label": "Objective",
      "prob": 0.6890941262245178
    },
    {
      "sentence": "All of these videos for our evaluation were collected by sighted people.",
      "label": "Result",
      "prob": 0.6681458950042725
    },
    {
      "sentence": "The results show that as the number of states increases, StateLens achieved a relatively stable error rate of ~5% compared to the",
      "label": "Result",
      "prob": 0.7372595071792603
    },
    {
      "sentence": "For each of the three screen placements (in the order of 90 vertical at chest-level, 45 tilted at chest-level, and 0 at on the table), participants completed ve trials using both the nger cap and the conductive stylus.",
      "label": "Method",
      "prob": 0.4480595290660858
    },
    {
      "sentence": "Task completion rate and time were recorded.",
      "label": "Result",
      "prob": 0.483568012714386
    },
    {
      "sentence": "Task completion rate and time were recorded.",
      "label": "Result",
      "prob": 0.4835681617259979
    },
    {
      "sentence": "Participants slightly preferred us ing the stylus to explore and activate touchscreens in the 90 screen placement (54% vs. 46%), since holding the hand in the upright position using the nger cap was not as comfortable ( M = 5 . 3 , SD = 1 . 4 ) , and the stylus felt more natural.",
      "label": "Result",
      "prob": 0.7329378724098206
    },
    {
      "sentence": "Identifying Existing States",
      "label": "Other",
      "prob": 0.5202870965003967
    },
    {
      "sentence": "We use the coffee machine in Figure 4 as a running example.",
      "label": "Result",
      "prob": 0.4892696142196655
    },
    {
      "sentence": "Slide Rule developed",
      "label": "Result",
      "prob": 0.31179091334342957
    },
    {
      "sentence": "For example, matching V 1 against V 5 results in low condence with SURF, then with additional information provided by OCR, StateLens is able to differentiate them.",
      "label": "Result",
      "prob": 0.7684469223022461
    },
    {
      "sentence": "Our work is related to prior work on",
      "label": "Result",
      "prob": 0.5094925761222839
    },
    {
      "sentence": "However, there were differences across the various screen placements.",
      "label": "Result",
      "prob": 0.7663044929504395
    },
    {
      "sentence": "increasing trend in the baseline approach (Figure 8).",
      "label": "Other",
      "prob": 0.44510746002197266
    },
    {
      "sentence": "In those cases, StateLens will fallback to only using the state transition without the detailed interaction component as the triggering event, e.g. , E i j = V i  V j = ( 0/ , V i , V j ) .",
      "label": "Other",
      "prob": 0.6955872178077698
    },
    {
      "sentence": "The demographics of our participants are shown in Table 3.",
      "label": "Result",
      "prob": 0.6074386239051819
    },
    {
      "sentence": "Abstracting with credit is permitted.",
      "label": "Other",
      "prob": 0.8195109367370605
    },
    {
      "sentence": "They felt the audio feedback provided by the app was in real-time and accurate ( M = 6 . 1 , SD = 0 . 9 ) .",
      "label": "Other",
      "prob": 0.4960971474647522
    },
    {
      "sentence": "We evaluated the efciency of our techniques in identifying states compared to the naive approach in VizLens::State De tection [17] which compares against every possible reference image.",
      "label": "Result",
      "prob": 0.5639825463294983
    },
    {
      "sentence": "Reducing Cognitive Effort",
      "label": "Result",
      "prob": 0.46089601516723633
    },
    {
      "sentence": "Finally, StateLens captures the interaction component that triggered a state transition, e.g. , a button b n that contributes to the transition E i j = V i  V j = ( { b n } , V i , V j ) .",
      "label": "Other",
      "prob": 0.45100611448287964
    },
    {
      "sentence": "In general, participants found both accessories to be com fortable to use ( M = 5 . 9 , SD = 1 . 1 ) and highly useful ( M = 6 . 4 , SD = 0 . 8 ) .",
      "label": "Result",
      "prob": 0.5682114362716675
    },
    {
      "sentence": "Crowd workers are rst asked to rate the image quality, segment the interface region (with the generated screen bounding box as a start when available), indicate the approximate number of interaction components, and additionally provide a description of the interface state.",
      "label": "Result",
      "prob": 0.5488572716712952
    },
    {
      "sentence": "Similarly, the transition to go back to the initial state can be represented as: E 10 = V 1  V 0 = ( { b back } , V 1 , V 0 ) .",
      "label": "Other",
      "prob": 0.5727406144142151
    },
    {
      "sentence": "Overall, participants were very excited about the potential of StateLens, and felt that it could help them access other inaccessible interface in the future ( M = 6 . 6 , SD = 0 . 9 ) :",
      "label": "Other",
      "prob": 0.7059844732284546
    },
    {
      "sentence": "for SURF descriptors.",
      "label": "Result",
      "prob": 0.4097450375556946
    },
    {
      "sentence": "The created agent then guides",
      "label": "Result",
      "prob": 0.348479688167572
    },
    {
      "sentence": "More than 10,000 users have asked more than 100,000 questions using VizWiz [20].",
      "label": "Other",
      "prob": 0.7985945343971252
    },
    {
      "sentence": "These tech niques effectively reduces the search space, speeds up the state detection process, and improves the robustness of state detection, which we will validate in technical evaluation.",
      "label": "Result",
      "prob": 0.578676164150238
    },
    {
      "sentence": "Several participants tried specifying multiple parameters in one sen-",
      "label": "Other",
      "prob": 0.6544032692909241
    },
    {
      "sentence": "StateLens builds upon the crowdsourcing workow in VizLens [17], and uses a two-step workow to label the area of the image that contains the interface assisted with screen detection results, and then label the individual interaction components assisted with OCR output (Figure 2).",
      "label": "Method",
      "prob": 0.5262104272842407
    },
    {
      "sentence": "Inspired by the nger cap designs from Thingiverse, we rst created a 3D-printed ring that allows users to explore without touching the screen, and tilt their nger forward to perform a touch at a desired position (Figure 3A-C).",
      "label": "Method",
      "prob": 0.5145944356918335
    },
    {
      "sentence": "Third, in case the matching results with neighbor states are",
      "label": "Result",
      "prob": 0.7406466007232666
    },
    {
      "sentence": "Participants spent an average of 122.3 seconds ( SD = 41 . 9 ) completing the rst task, 110.4 seconds ( SD = 36 . 9 ) for the second, the 97.6 seconds ( SD = 30 . 7 ) for the third, as they got familiar with the audio feedback and guidance.",
      "label": "Result",
      "prob": 0.718571662902832
    },
    {
      "sentence": "The whole study was video and audio recorded for further analysis.",
      "label": "Result",
      "prob": 0.690628170967102
    },
    {
      "sentence": "We then evaluated the robustness of our techniques in identify ing states compared to the baseline approach.",
      "label": "Result",
      "prob": 0.6710779070854187
    },
    {
      "sentence": "This can be improved with practice, as participants generally found the accessories to be very easy to learn ( M = 6 . 2 , SD = 0 . 9 ) .",
      "label": "Result",
      "prob": 0.6313470602035522
    },
    {
      "sentence": "Detecting the Screen",
      "label": "Result",
      "prob": 0.4046679437160492
    },
    {
      "sentence": "Itll be a thing, I will actually use it.  P1",
      "label": "Other",
      "prob": 0.8267855048179626
    },
    {
      "sentence": "In subjective ratings, participants found the StateLens iOS ap plication to be easy to learn ( M = 5 . 5 , SD = 0 . 9 ) , comfortable to use ( M = 5 . 6 , SD = 1 . 2 ) , and very useful ( M = 6 . 1 , SD = 1 . 1 ) .",
      "label": "Result",
      "prob": 0.6770530939102173
    },
    {
      "sentence": "extrusion 3D printer.",
      "label": "Other",
      "prob": 0.7039751410484314
    },
    {
      "sentence": "If such bounding boxes exist and their sizes are above 10% of the image size (aiming to lter out objects that are not the one of interest), StateLens crops the image using the bounding box to remove background noises for further processing.",
      "label": "Method",
      "prob": 0.6297030448913574
    },
    {
      "sentence": "In order to enable repeated testing without wasting coffee, we built a simulated interactive prototype of the coffee machine in Figure 4 with InVision [23], which we displayed on an iPad tablet of similar size as the coffee machines interface (iPad Pro 3rd generation, 11-inch, running iOS 12.2 without VoiceOver enabled).",
      "label": "Method",
      "prob": 0.5746822953224182
    },
    {
      "sentence": "Generalizability",
      "label": "Other",
      "prob": 0.6839868426322937
    },
    {
      "sentence": "Regarding the effect of our screen detection approach, a com bination of Screen Detection+SURF+OCR features generally yielded higher performance compared to SURF+OCR fea tures.",
      "label": "Result",
      "prob": 0.891990602016449
    },
    {
      "sentence": "LCD panels on appliances [14, 30, 33].",
      "label": "Other",
      "prob": 0.8598601222038269
    },
    {
      "sentence": "(i) SURF features only,",
      "label": "Other",
      "prob": 0.8019717335700989
    },
    {
      "sentence": "2019 Association of Computing Machinery.",
      "label": "Other",
      "prob": 0.8914349675178528
    },
    {
      "sentence": "Using the conductive stylus to explore touchscreens generally re sulted in fewer accidental triggers ( M = 0 . 03 , SD = 0 . 16 ) compared to using the nger cap ( M = 0 . 07 , SD = 0 . 27 ) .",
      "label": "Result",
      "prob": 0.7554724812507629
    },
    {
      "sentence": "The overall task completion rate was 94.7%.",
      "label": "Result",
      "prob": 0.7371533513069153
    },
    {
      "sentence": "The results show that as the",
      "label": "Result",
      "prob": 0.8043178915977478
    },
    {
      "sentence": "The aggregated results are shown in Table 4.",
      "label": "Result",
      "prob": 0.8236029744148254
    },
    {
      "sentence": "I would welcome more opportunities to use interfaces with [StateLens], like operating the cable company box. It would be great if interfaces could also show up on my phone screen and read it to me or let me explore it there.  P12",
      "label": "Other",
      "prob": 0.7503363490104675
    },
    {
      "sentence": "Request permissions from Permissions@acm.org.",
      "label": "Other",
      "prob": 0.9176303744316101
    },
    {
      "sentence": "To make sure the touchpoint does not change from exploration to activation ( i.e. , the problems Slide Rule [24] addressed with split tap, and VizLens [17] addressed with shifting the interaction point), we measured the ground truth touchpoint location and placed the color marker on the accessory accordingly.",
      "label": "Method",
      "prob": 0.46096840500831604
    },
    {
      "sentence": "Results are combined using majority vote.",
      "label": "Result",
      "prob": 0.7935641407966614
    },
    {
      "sentence": "coffee_drinks gourmet_drinks hot_beverages to the coffee drink type state V 1 can be represented as: E 01 = V 0  V 1 = ( { b coffee_drinks } , V 0 , V 1 ) , stating that by interacting with button Coffee Drinks in the initial state, we could get to the desired state for coffee drinks type selection.",
      "label": "Result",
      "prob": 0.6388972401618958
    },
    {
      "sentence": "On the other hand, the average attempts of using the stylus ( M = 2 . 48 , SD = 1 . 07 ) was more than that from using the nger cap ( M = 1 . 90 , SD = 1 . 01 ) .",
      "label": "Result",
      "prob": 0.6865201592445374
    },
    {
      "sentence": "Participants spent an average of 53.7 seconds ( SD = 11 . 6 ) to prespecify tasks with the conversational agent, with an overall task completion rate of 100%, and found it to be ex tremely easy to learn ( M = 6 . 6 , SD = 0 . 6 ) , comfortable to use ( M = 6 . 8 , SD = 0 . 4 ) , and useful ( M = 6 . 7 , SD = 0 . 6 ) .",
      "label": "Result",
      "prob": 0.5923879742622375
    },
    {
      "sentence": "Hurst et al.",
      "label": "Other",
      "prob": 0.9282839894294739
    },
    {
      "sentence": "[StateLens] gives much more exibility, so that if the machine itself doesnt have speech, this can cover the instances where you have to interact with a touchscreen. There are more tools to access them. This combination opens up more accessibility. ... I cant wait to see this in action!  P6",
      "label": "Other",
      "prob": 0.8307225704193115
    },
    {
      "sentence": "CCS Concepts",
      "label": "Other",
      "prob": 0.9145587086677551
    },
    {
      "sentence": "If the highest matched ratio across existing reference images is not high enough, meaning the match using only SURF features is not so condent, StateLens then uses the Google Cloud Vision API [16] to compute OCR results for the input image and compares to the pre-computed OCR results of the state reference image.",
      "label": "Result",
      "prob": 0.7797395586967468
    },
    {
      "sentence": "ACKNOWLEDGMENTS",
      "label": "Other",
      "prob": 0.8630120158195496
    },
    {
      "sentence": "Kim et al.",
      "label": "Other",
      "prob": 0.9259616732597351
    },
    {
      "sentence": "Chang et al.",
      "label": "Other",
      "prob": 0.9266535043716431
    },
    {
      "sentence": "Author Keywords",
      "label": "Other",
      "prob": 0.9486260414123535
    }
  ]
}