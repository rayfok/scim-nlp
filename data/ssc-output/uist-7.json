{
  "uist-7": [
    {
      "sentence": "Recent advances in computer vision have shown that hand pose can be accurately estimated using commodity depth, RGB or monochrome cameras.",
      "label": "Background",
      "prob": 0.9520501494407654
    },
    {
      "sentence": "Automatic speech recognition is more accessible, but may not be socially acceptable for certain environments or for private communication.",
      "label": "Background",
      "prob": 0.9492419958114624
    },
    {
      "sentence": "However, existing hand-tracking-based text entry solutions for AR/VR are relatively low throughput.",
      "label": "Background",
      "prob": 0.9367558360099792
    },
    {
      "sentence": "Commercial AR/VR devices such as the Oculus Quest and the Microsoft Hololens have started using hand-tracking for text entry.",
      "label": "Background",
      "prob": 0.9360081553459167
    },
    {
      "sentence": "Without the feel of physical keys and without using sight to nd the keys, ngers will drift during typing.",
      "label": "Background",
      "prob": 0.9353940486907959
    },
    {
      "sentence": "Hand-tracking provides potentially richer sensing information (including nger identities and trajectories) than the contact modality.",
      "label": "Background",
      "prob": 0.9128216505050659
    },
    {
      "sentence": "Text entry is an important task for communication and productivity in augmented reality and virtual reality (AR/VR).",
      "label": "Background",
      "prob": 0.9113802313804626
    },
    {
      "sentence": "While conventional physical keyboards and touch screens can be incorporated into AR/VR input systems, added peripherals detract from mobile use cases and accessibility.",
      "label": "Background",
      "prob": 0.9065499901771545
    },
    {
      "sentence": "This mapping is inherently ambiguous, for example, when a nger strikes the boundary between two keys, and is exacerbated by drift of the users ngers due to the lack of haptic feedback of physical keys.",
      "label": "Background",
      "prob": 0.9016958475112915
    },
    {
      "sentence": "Consumer hand-tracking systems on current generation HMDs are optimized for virtual manipulation tasks rather than text input.",
      "label": "Background",
      "prob": 0.9006808400154114
    },
    {
      "sentence": "Most importantly, there already exists a wide audience of effective typists.",
      "label": "Background",
      "prob": 0.8992589116096497
    },
    {
      "sentence": "Our decoding is also continuous (at 60Hz) rather than constrained to producing characters at discrete contact events.",
      "label": "Background",
      "prob": 0.883708119392395
    },
    {
      "sentence": "PalmType leverages passive haptics by using the opposite hand as a tapping / typing surface, although this approach comes at the cost of limiting typing to a single hand.",
      "label": "Background",
      "prob": 0.8834518194198608
    },
    {
      "sentence": "While this serves as a proof of concept for interactive utility, our system still lacks many fundamental features required of any practical text input system, such as backspace or punctuation.",
      "label": "Background",
      "prob": 0.8803421854972839
    },
    {
      "sentence": "Typing on any at surface without the need to bring a physical keyboard would provide a valuable addition to AR/VR interaction.",
      "label": "Background",
      "prob": 0.8789544701576233
    },
    {
      "sentence": "Hand-tracking is typically achieved through onheadset sensors, without extra peripherals, making it suitable",
      "label": "Background",
      "prob": 0.8778999447822571
    },
    {
      "sentence": "An advantage of using a TCN is efciency during training, since TCNs can process entire sequences in parallel rather than sequentially as with recurrent neural networks.",
      "label": "Background",
      "prob": 0.8730723261833191
    },
    {
      "sentence": "Statistical decoding of typing is analogous to text decoding in automatic speech recognition.",
      "label": "Background",
      "prob": 0.8625378012657166
    },
    {
      "sentence": "There is no mechanism to detect an accidental touch or to guess when a touch event should have happened but was missed.",
      "label": "Background",
      "prob": 0.8599453568458557
    },
    {
      "sentence": "hand-tracking input signal from mobile headsets, or alternatively improve the state-of-the-art of egocentric hand-tracking today.",
      "label": "Background",
      "prob": 0.8573462963104248
    },
    {
      "sentence": "Flat surface typing is a paradigm that exists today in tablet computers.",
      "label": "Background",
      "prob": 0.8539684414863586
    },
    {
      "sentence": "The isFree system [30] is an example of a gesture keyboard that learns keyboard location from gesture input over time.",
      "label": "Background",
      "prob": 0.8537421822547913
    },
    {
      "sentence": "Note that while more sophisticated contact-based decoders such as the one described in Velocitap [25] can add or remove characters during decoding, they would not have access to nger trajectory information.",
      "label": "Background",
      "prob": 0.8507324457168579
    },
    {
      "sentence": "Many challenges remain to making this system practical for general text input.",
      "label": "Background",
      "prob": 0.8455443978309631
    },
    {
      "sentence": "This model lacks the continuous text decoding capabilities of our motion model, but rather has to decode text only at discrete contact events.",
      "label": "Background",
      "prob": 0.8397207856178284
    },
    {
      "sentence": "Typing on a virtual keyboard is more discreet than speaking.",
      "label": "Background",
      "prob": 0.822597324848175
    },
    {
      "sentence": "[10] improve on key-targets with dynamic resizing and respecting minimal key regions or anchors.",
      "label": "Background",
      "prob": 0.8142523765563965
    },
    {
      "sentence": "We observed that many mistakes made by contactbased decoding were due to its discrete nature: Characters are generated if and only if there is a corresponding contact event, which means that spurious or omitted contacts necessarily result in decoding errors.",
      "label": "Background",
      "prob": 0.8076065182685852
    },
    {
      "sentence": "Touch typing, by which we mean eyes-free input, on a at surface has been studied in the context of gesture keyboards.",
      "label": "Background",
      "prob": 0.8063085675239563
    },
    {
      "sentence": "Because contact-based decoding occurs only at discrete touch events, for an accidental touch, the system must assign a key to the event, and for a missing touch, the system cannot insert an extra key-press.",
      "label": "Background",
      "prob": 0.8045998215675354
    },
    {
      "sentence": "The input features to the network are frame-to-frame deltas of wrist position and rotation along with 3D ngertip positions.",
      "label": "Background",
      "prob": 0.7988808155059814
    },
    {
      "sentence": "VISAR also integrates a more sophisticated decoding strategy [25] to achieve superior mid-air typing on Hololens.",
      "label": "Background",
      "prob": 0.7964043021202087
    },
    {
      "sentence": "Copyrights for third-party components of this work must be honored.",
      "label": "Background",
      "prob": 0.7854674458503723
    },
    {
      "sentence": "Any remaining errors from the contact-based methods can only be due to the richness of the input signal.",
      "label": "Background",
      "prob": 0.7849287986755371
    },
    {
      "sentence": "To transcribe the probabilities V into typed text, this output must be decoded into a sequence of keys W .",
      "label": "Background",
      "prob": 0.780563235282898
    },
    {
      "sentence": "People type faster on a physical keyboard [3] than a soft keyboard and also faster on a surface [4] than in the air.",
      "label": "Background",
      "prob": 0.7767452597618103
    },
    {
      "sentence": "Our system currently does not support typing of nondictionary words effectively.",
      "label": "Background",
      "prob": 0.7457740306854248
    },
    {
      "sentence": "The ATK system [28] uses skeletal hand-tracking (via a Leap Motion device) to drive text entry, although through midair typing.",
      "label": "Background",
      "prob": 0.7419953942298889
    },
    {
      "sentence": "After typing each phrase, participants would use one of two foot pedals to mark that they felt they correctly typed the phrase, or that they typed the phrase but felt they made mistakes.",
      "label": "Background",
      "prob": 0.7413907051086426
    },
    {
      "sentence": "[29], who enforced touch-typing on a smartphone surface by asking users to tap on an invisible keyboard.",
      "label": "Background",
      "prob": 0.7270257472991943
    },
    {
      "sentence": "This prevented any visible retroactive changes and maintained a controlled latency, while allowing corrections of the most recent 1-2 characters for most typists.",
      "label": "Background",
      "prob": 0.7169758677482605
    },
    {
      "sentence": "All positions are represented in the coordinate frame of the keyboard (the touchpad, or a virtual keyboard in the runtime).",
      "label": "Background",
      "prob": 0.7094846963882446
    },
    {
      "sentence": "For temporal modeling, we opt to use a temporal convolutional network (TCN) rather than a recurrent model because a xed window of hand motion data is typically sufcient to make predictions about key presses.",
      "label": "Background",
      "prob": 0.7078102827072144
    },
    {
      "sentence": "Participants were given prompts with 3-6 word phrases containing only lowercase alphabetical characters and spaces.",
      "label": "Background",
      "prob": 0.7077456116676331
    },
    {
      "sentence": "Our current experiments provide no visual feedback during typing, and more exploration of what visual feedback to offer, e.g., along the lines of Velocitap [25] is needed.",
      "label": "Background",
      "prob": 0.7000945806503296
    },
    {
      "sentence": "In our study we compromise between accessibility and speed by requiring users to type against a surface but eschewing the use of a physical keyboard or a touchpad.",
      "label": "Background",
      "prob": 0.6950453519821167
    },
    {
      "sentence": "Aside from the prompted phrase, no visual feedback was afforded in any of the blocks.",
      "label": "Background",
      "prob": 0.683614194393158
    },
    {
      "sentence": "3) a sequence of length T of skeletal hand poses while those keys were typed, recorded at 60Hz.",
      "label": "Background",
      "prob": 0.6724218130111694
    },
    {
      "sentence": "At rst, we assumed that the discrete nature of contacts was an advantage for contact decoding.",
      "label": "Background",
      "prob": 0.6711768507957458
    },
    {
      "sentence": "The VISAR system [5] also uses hand-tracking (via a Hololens device) to enable typing, although with just the index ngers.",
      "label": "Background",
      "prob": 0.6704065203666687
    },
    {
      "sentence": "Since then, hand-tracking technology has advanced signicantly.",
      "label": "Background",
      "prob": 0.6607657074928284
    },
    {
      "sentence": "2) a sequence of length N of 2D contact events from the touchpad, and",
      "label": "Background",
      "prob": 0.6551459431648254
    },
    {
      "sentence": "Some of the error discrepancies could be explained by augmenting with nger identity information.",
      "label": "Background",
      "prob": 0.645683228969574
    },
    {
      "sentence": "The model should assign more likelihood to a key when the user is hitting a key, and otherwise assign likelihood to the blank label.",
      "label": "Background",
      "prob": 0.6452140212059021
    },
    {
      "sentence": "We will need to handle other keys, including backspace, numbers and symbols to support general interactive text editing.",
      "label": "Background",
      "prob": 0.6325116157531738
    },
    {
      "sentence": "As has been shown in the speech recognition community [9], beam search decoding is also well-suited to the CTC loss with which we train the network.",
      "label": "Background",
      "prob": 0.6279776096343994
    },
    {
      "sentence": "Finally, others were due to the fundamentally discrete nature of contact decoding.",
      "label": "Background",
      "prob": 0.6277680397033691
    },
    {
      "sentence": "richer input features of hand-tracking, e.g., which nger is hitting a key or which path the nger took to reach a key.",
      "label": "Background",
      "prob": 0.6220942139625549
    },
    {
      "sentence": "However, when using a touchpad, we assume no ambiguity in whether a contact event occurred, only 2D spatial ambiguity about which key was pressed.",
      "label": "Background",
      "prob": 0.6195654273033142
    },
    {
      "sentence": "[2] which consists of causal dilated convolutions and weight normalization arranged in residual blocks.",
      "label": "Background",
      "prob": 0.616402804851532
    },
    {
      "sentence": "This architecture allows for 46 past frames of hand features (around 0.75 seconds of motion at 60Hz) to be referenced to generate the current probability distribution over the set of keys.",
      "label": "Background",
      "prob": 0.593869149684906
    },
    {
      "sentence": "We only rendered text in the common prex of all beams, effectively imposing a xed 0.1s delay.",
      "label": "Background",
      "prob": 0.5735911726951599
    },
    {
      "sentence": "We attempt to ablate away the continuous nature of hand motion decoding by creating a ltered test dataset containing only samples with matched contacts and keys.",
      "label": "Background",
      "prob": 0.571382999420166
    },
    {
      "sentence": "Participants typed a median of 362 training phrases (approximately 6650 characters), and a median of 131 testing phrases (approximately 3400 characters).",
      "label": "Background",
      "prob": 0.5701418519020081
    },
    {
      "sentence": "We also use complete hand pose of all the ngers on both hands rather than the pose of a single nger.",
      "label": "Background",
      "prob": 0.5636839270591736
    },
    {
      "sentence": "We ltered out captures where the number of touchpad contact events did not agree with the number of characters in the prompted phrase.",
      "label": "Background",
      "prob": 0.5621791481971741
    },
    {
      "sentence": "Others could be attributed to the addition of nger trajectory information.",
      "label": "Background",
      "prob": 0.5559331178665161
    },
    {
      "sentence": "We are inspired by the work of Dudley and colleagues [4] that shows the high potential of human typing efciency and error rate given a text decoding oracle with knowledge of the text being typed.",
      "label": "Background",
      "prob": 0.553835928440094
    },
    {
      "sentence": "In this questionnaire all participants self identied as expert typists who type for more than 30 minutes per day and who use at least 3 distinct ngers to type the word ghost on a QWERTY keyboard.",
      "label": "Background",
      "prob": 0.5520972609519958
    },
    {
      "sentence": "Explicit contact information is a strong signal for a key-press, whereas our motion model has to learn to detect the signature trajectory of a nger as it presses a key.",
      "label": "Background",
      "prob": 0.5498049259185791
    },
    {
      "sentence": "We wish to quantify our ability to produce the text people intended to type, which should include all of the samples where participants felt they typed the phrase correctly.",
      "label": "Background",
      "prob": 0.5485844016075134
    },
    {
      "sentence": "Our investigation caters particularly to the fastest typists touch typists , which we mean as those who type without the sense of sight to nd the keys.",
      "label": "Background",
      "prob": 0.5407103300094604
    },
    {
      "sentence": "The rst evaluation is a direct comparison against physical keyboards, and the second evaluation consists of two experiments aimed at",
      "label": "Background",
      "prob": 0.534240186214447
    },
    {
      "sentence": "Since our goal is to produce the text people intended to type, we ltered samples where the user believed they made a mistake since we dont know what text the user expects to be produced in those cases.",
      "label": "Background",
      "prob": 0.533362090587616
    },
    {
      "sentence": "A prex beam search decoder approximately maximizes p ( W ; V ) by incrementally constructing W by tracking a set of B best candidates (beams) at any given step.",
      "label": "Background",
      "prob": 0.5291223526000977
    },
    {
      "sentence": "Many other text entry systems have been proposed for AR/VR applications, and for brevity, we concentrate on those that use a QWERTY keyboard layout.",
      "label": "Background",
      "prob": 0.5256357192993164
    },
    {
      "sentence": "The motion model captures the mapping from nger trajectories to intended key presses.",
      "label": "Background",
      "prob": 0.5099201798439026
    },
    {
      "sentence": "To collect a dataset of skeletal hand-tracking data, we make use of a high quality marker-based hand-tracking system [12] which is not subject to the current tracking limitations of consumer head mounted hand-trackers.",
      "label": "Background",
      "prob": 0.5091137290000916
    },
    {
      "sentence": "Thus our motion model was able to be trained on the original training dataset, only ltering samples where users felt they made a mistake.",
      "label": "Background",
      "prob": 0.5079600811004639
    },
    {
      "sentence": "2. A language model which can give the likelihood of an additional token given a prex of tokens.",
      "label": "Background",
      "prob": 0.5017107725143433
    },
    {
      "sentence": "We chose these features because they are somewhat invariant to differences in hand scale across people.",
      "label": "Background",
      "prob": 0.498334139585495
    },
    {
      "sentence": "We also explore why decoding continuous hand motion data could be advantageous to decoding a discrete set of contacts on a touch surface by isolating the value nger trajectory information, nger identity information and continuous decoding.",
      "label": "Background",
      "prob": 0.49388808012008667
    },
    {
      "sentence": "The testing dataset used for all decoders is the same, except that we only lter samples where the user felt they made a mistake, which means that the number of characters typed might not equal the number of contact events.",
      "label": "Background",
      "prob": 0.4922064244747162
    },
    {
      "sentence": "After decoding, we compute the uncorrected error rate UER ( W , W  ) as the Levenstein edit distance between the decoded and prompted strings divided by the number of characters of the longer of the two strings.",
      "label": "Background",
      "prob": 0.4877384603023529
    },
    {
      "sentence": "The target for each sample is the sequence of keys W  = { w  j } Nj = 1 that were prompted to the participant.",
      "label": "Background",
      "prob": 0.48625901341438293
    },
    {
      "sentence": "This suggests that continuous hand motion decoding is better able to cope with the mistakes in the unltered dataset.",
      "label": "Background",
      "prob": 0.4862571060657501
    },
    {
      "sentence": "Recent studies show that touch typists and faster typists tend to have lower entropy in their nger to key mapping [6].",
      "label": "Background",
      "prob": 0.4850698709487915
    },
    {
      "sentence": "This allows the language model to steer decoding when the motion model is uncertain (See Figure 2).",
      "label": "Background",
      "prob": 0.47873613238334656
    },
    {
      "sentence": "Additionally, surface typing has been shown to be more comfortable than mid air typing [4] and confers haptic feedback, which enhances presence in VR [16].",
      "label": "Background",
      "prob": 0.4782876670360565
    },
    {
      "sentence": "To do so we create two contact-based baselines for comparison, one that uses only anonymous, discrete contact events, and another that adds nger-identity information.",
      "label": "Background",
      "prob": 0.47636011242866516
    },
    {
      "sentence": "The combination of connectionist temporal classication (CTC) loss and beam search is a cornerstone of modern end-to-end speech recognition systems [1].",
      "label": "Background",
      "prob": 0.46475183963775635
    },
    {
      "sentence": "In this paper we take a major step towards realizing the viability of such a system by demonstrating decoding of text from hand motion captured with a high quality hand-tracking system.",
      "label": "Background",
      "prob": 0.4643828570842743
    },
    {
      "sentence": "The network is trained using the CTC loss function[8], which allows for sequence level labels without needing known alignment of labels to individual frames of input data.",
      "label": "Background",
      "prob": 0.4508286416530609
    },
    {
      "sentence": "[17] model a trajectory of contacts as well as words in a language model geometrically and decode stylus gestures via a geometric matching method.",
      "label": "Background",
      "prob": 0.4432995915412903
    },
    {
      "sentence": "[27] improve rst touch accuracy for a gesture keyboard by centering the keyboard around rst touch.",
      "label": "Background",
      "prob": 0.43815651535987854
    },
    {
      "sentence": "We use a higher capacity neural motion model to decode a richer input signal (i.e., with nger identity and trajectory information) into text.",
      "label": "Background",
      "prob": 0.43668439984321594
    },
    {
      "sentence": "Similarly, RotoSwype [11] uses a ring to capture the motion of a single nger tracing a path through a QWERTY keyboard in the air, achieving speeds of at least 14WPM with a 1% error rate by the end of a ve-day study.",
      "label": "Background",
      "prob": 0.4352234899997711
    },
    {
      "sentence": "1. A motion model, analogous to an acoustic model, which takes a sequence of hand poses and for each frame outputs a likelihood over an alphabet of tokens, i.e., keys plus a blank token corresponding to no key.",
      "label": "Background",
      "prob": 0.431042343378067
    },
    {
      "sentence": "1 +  p total = ( p ( W ; V ) p lm ( W )  ) where  is a hyperparameter to control the balance between the two likelihoods.",
      "label": "Background",
      "prob": 0.42509952187538147
    },
    {
      "sentence": "Because contact-based text decoders are sensitive to accidental or missed touches, we took care to clean the contact-based training data from the touchpad captures.",
      "label": "Background",
      "prob": 0.42453733086586
    },
    {
      "sentence": "Our motion model network is compact, containing just 180KB of weights, enabling efcient evaluation on a GPU.",
      "label": "Result",
      "prob": 0.4666503369808197
    },
    {
      "sentence": "We recruited 20 participants who passed a pre-screening questionnaire designed to select for experienced typists.",
      "label": "Background",
      "prob": 0.4167628586292267
    },
    {
      "sentence": "For this work, we trained per-user neural motion models over an hours worth of typing samples and will need a more user-friendly version of user calibration.",
      "label": "Background",
      "prob": 0.41421568393707275
    },
    {
      "sentence": "In this paper, we investigate the use of hand-tracking to enable typing on any at surface at speeds comparable to typing on a physical keyboard.",
      "label": "Background",
      "prob": 0.4119809567928314
    },
    {
      "sentence": "Participants of our user study type at different speeds, so we compare the relative speed of typing on a at surface versus a physical keyboard.",
      "label": "Background",
      "prob": 0.4072510600090027
    },
    {
      "sentence": "The network is trained with a batch size of 32, where each individual sample consists of input features { u i } Ti = 1 , where T depends on how long it took the participant to type the phrase.",
      "label": "Background",
      "prob": 0.4016987681388855
    },
    {
      "sentence": "1) a sequence of length N of keys that were typed,",
      "label": "Background",
      "prob": 0.40168488025665283
    },
    {
      "sentence": "We then lter samples where multiple keys in the sample were struck by a nger which hits that key in less than 1% of cases overall.",
      "label": "Result",
      "prob": 0.4795694649219513
    },
    {
      "sentence": "For our motion model we trained person-specic models that captured each users typing style from the training set portion of the data.",
      "label": "Background",
      "prob": 0.4009583592414856
    },
    {
      "sentence": "Our system differs from prior work in several ways.",
      "label": "Result",
      "prob": 0.4265313446521759
    },
    {
      "sentence": "This model takes as input a sequence of frames of hand-tracking features and for each frame outputs a probability distribution over the set of possible keys, plus one additional label for blank / no-key.",
      "label": "Background",
      "prob": 0.38802918791770935
    },
    {
      "sentence": "[7] rst applied statistical decoding to improve the accuracy of a soft keyboard by modeling key-targets as bi-variate Gaussians and representing a language model as an n-gram distribution.",
      "label": "Background",
      "prob": 0.3850562870502472
    },
    {
      "sentence": "2. 60 minutes (in 5 minute blocks) of training set phrases on a touchpad",
      "label": "Background",
      "prob": 0.3826916813850403
    },
    {
      "sentence": "We compare these baselines to each other and to our hand motion based decoding to isolate the impact of nger identity information.",
      "label": "Background",
      "prob": 0.3784903585910797
    },
    {
      "sentence": "Next, we design a system for decoding the skeletal hand-tracking data into the text the typists intended to type.",
      "label": "Background",
      "prob": 0.3783358037471771
    },
    {
      "sentence": "For each key k we t a bivariate Gaussian g k ( x ) = N ( x ;  k ,  k ) from the collection of 2D contacts.",
      "label": "Background",
      "prob": 0.3732287287712097
    },
    {
      "sentence": "This transform enabled all 2D contact points to be lifted into the 3D coordinate space in which the skeletal hand poses were represented.",
      "label": "Background",
      "prob": 0.369733065366745
    },
    {
      "sentence": "Test phrases were randomly sampled from a corpus of 500 phrases giving a possibility of overlap between the physical",
      "label": "Result",
      "prob": 0.4480341076850891
    },
    {
      "sentence": "3. A decoder which can optimize an objective function combining the likelihoods from both the motion and the language models.",
      "label": "Background",
      "prob": 0.36286190152168274
    },
    {
      "sentence": "As shown in Figure 6, we found our expert typist participants tended to have consistent key-nger correspondences.",
      "label": "Result",
      "prob": 0.5119118094444275
    },
    {
      "sentence": "The output of the network V = { v i } Ti = 1 is a corresponding sequence of T frames, each containing a probability distribution v i ( k ) over the set of the K + 1 possible keys (with one extra for the blank label).",
      "label": "Method",
      "prob": 0.3713565766811371
    },
    {
      "sentence": "These labels { ` t } tT = 1 are compacted into a transcription W by rst combining adjacent frames with the same label into one of that label, and then by removing all blank labels.",
      "label": "Method",
      "prob": 0.4987178146839142
    },
    {
      "sentence": "We are able to run both models, in addition to decoding, at interactive rates (i.e. 120 Hz) on a PC with an Nvidia RTX 2080Ti graphics card.",
      "label": "Result",
      "prob": 0.3804801106452942
    },
    {
      "sentence": "Because our participants were tasked with typing test-set phrases on both a physical keyboard and on a touchpad, we can make this comparison directly.",
      "label": "Result",
      "prob": 0.36251258850097656
    },
    {
      "sentence": "While using a marker-based tracking system may introduce a gap in tracking quality compared to what is achievable on an AR/VR headset, we can study the potential of hand-tracking applied to this problem.",
      "label": "Background",
      "prob": 0.34774625301361084
    },
    {
      "sentence": "We apply this same general framework, substituting recurrent neural networks with a TCN-based motion model, to decode text entry via typing.",
      "label": "Method",
      "prob": 0.4456369876861572
    },
    {
      "sentence": "We show that these users can transfer their existing skills typing on a keyboard to typing on a at surface.",
      "label": "Result",
      "prob": 0.448879212141037
    },
    {
      "sentence": "The ARKB system [18] showed a very similar concept of typing on a QWERTY virtual keyboard on a surface using hand-tracking through color-based segmentation and markers.",
      "label": "Result",
      "prob": 0.5572448372840881
    },
    {
      "sentence": "Longer term context is useful for prediction in the context of language, but since our system design separates motion modeling from language modeling, a TCN works well for the former.",
      "label": "Result",
      "prob": 0.5658263564109802
    },
    {
      "sentence": "Hand-tracking information was recorded while participants typed during all three blocks.",
      "label": "Result",
      "prob": 0.39907699823379517
    },
    {
      "sentence": "Figure 1(b) shows an example where our motion model is able to learn to detect the signature trajectory of reaching for a particular key.",
      "label": "Result",
      "prob": 0.41657817363739014
    },
    {
      "sentence": "For decoding hand motion into text, we make no such concessions and investigate the accuracy we can achieve using practical language models and statistical decoding strategies presented in this work.",
      "label": "Result",
      "prob": 0.3506585359573364
    },
    {
      "sentence": "In our study we collected data by having participants complete a text transcription task for short phrases.",
      "label": "Result",
      "prob": 0.3475267291069031
    },
    {
      "sentence": "This output can be interpreted as a T  ( K + 1 ) heat map",
      "label": "Background",
      "prob": 0.3207329213619232
    },
    {
      "sentence": "of keys can be processed using the same beam search decoder and language model we described for hand motion decoding.",
      "label": "Method",
      "prob": 0.4187394380569458
    },
    {
      "sentence": "We will need to explore a more efcient user calibration process in future work.",
      "label": "Background",
      "prob": 0.3066823482513428
    },
    {
      "sentence": "Our method is designed for typing on a at surface rather than in the air or against the opposite hand.",
      "label": "Method",
      "prob": 0.503103494644165
    },
    {
      "sentence": "These models were not optimized for compute and can be further accelerated using modern distillation and quantization techniques for neural networks [22].",
      "label": "Other",
      "prob": 0.4259592592716217
    },
    {
      "sentence": "Since these sequences are in correspondence, we can bucket 2D contact points for each key on the keyboard.",
      "label": "Result",
      "prob": 0.48670563101768494
    },
    {
      "sentence": "In our second experiment we investigate the contribution of continuous motion decoding versus discrete contact-based decoding.",
      "label": "Result",
      "prob": 0.29598814249038696
    },
    {
      "sentence": "In our rst experiment we study the contribution of nger identity information.",
      "label": "Result",
      "prob": 0.35905739665031433
    },
    {
      "sentence": "We propose a motion model, represented as a temporal convolutional network (TCN), that can translate hand motion directly into (a probability distribution over the) typed text.",
      "label": "Method",
      "prob": 0.29518747329711914
    },
    {
      "sentence": "We attempt to tease apart the contributions of these differences with two experiments.",
      "label": "Result",
      "prob": 0.3796378970146179
    },
    {
      "sentence": "containing the prediction of which key was hit at which time (Figure 2).",
      "label": "Result",
      "prob": 0.3551461398601532
    },
    {
      "sentence": "Finally we measure typing speed and error rates of our system against typing on a physical keyboard and contact-based statistical decoding methods.",
      "label": "Method",
      "prob": 0.4903002679347992
    },
    {
      "sentence": "On the other hand, our motion model generates a probability distribution of which key was pressed (including no-key) at every frame of the tracking, which provides the decoder exibility to insert or remove key-presses to accommodate the language model prior (Figure 7).",
      "label": "Result",
      "prob": 0.38019001483917236
    },
    {
      "sentence": "Graves and Jaitly [9] rst applied CTC loss with a prex beam search decoder to speech recognition, and Hannun and colleagues [13] showed how to directly incorporate a language model.",
      "label": "Result",
      "prob": 0.5217179656028748
    },
    {
      "sentence": "Finally, we are only decoding the lower case letters of the alphabet on our keyboard.",
      "label": "Result",
      "prob": 0.4593487083911896
    },
    {
      "sentence": "We use three layers of residual blocks with 64, 64, and 32 hidden units respectively, a kernel size of 2 and a dilation factor of 3.",
      "label": "Method",
      "prob": 0.38961076736450195
    },
    {
      "sentence": "Notably, our model is the rst technique to our knowledge that converts skeletal hand motion directly into text.",
      "label": "Result",
      "prob": 0.504271924495697
    },
    {
      "sentence": "We show that by using hand pose rather than contact points and a richer motion model, we can achieve more accurate decoding.",
      "label": "Result",
      "prob": 0.4879584014415741
    },
    {
      "sentence": "1. 5 minutes of test set phrases on a physical keyboard",
      "label": "Other",
      "prob": 0.47078409790992737
    },
    {
      "sentence": "Vulture [21] uses a high-precision marker-based hand-tracking system to capture a pinch and the tracing of a path (of a word-gesture) through a QWERTY keyboard, which are then decoded into the best word proposals.",
      "label": "Method",
      "prob": 0.5902175903320312
    },
    {
      "sentence": "While the contact-based baselines can only be trained with known key/contact-point correspondences, our motion model is trained using CTC loss, which allows for sequence level labels and can deduce the frame-level alignment of the labels.",
      "label": "Method",
      "prob": 0.46997445821762085
    },
    {
      "sentence": "for on-the-go use cases.",
      "label": "Other",
      "prob": 0.5168817043304443
    },
    {
      "sentence": "This has several advantages to existing approaches.",
      "label": "Result",
      "prob": 0.5784299969673157
    },
    {
      "sentence": "This language model was trained on using a window of 500 characters on text sampled from 2 million articles in the CC-News dataset [20].",
      "label": "Other",
      "prob": 0.5466184020042419
    },
    {
      "sentence": "Session 9B: Interpreting and Adapting Hand Input",
      "label": "Other",
      "prob": 0.5663302540779114
    },
    {
      "sentence": "Session 9B: Interpreting and Adapting Hand Input",
      "label": "Other",
      "prob": 0.5663302540779114
    },
    {
      "sentence": "Session 9B: Interpreting and Adapting Hand Input",
      "label": "Other",
      "prob": 0.5663302540779114
    },
    {
      "sentence": "Session 9B: Interpreting and Adapting Hand Input",
      "label": "Other",
      "prob": 0.5663302540779114
    },
    {
      "sentence": "Session 9B: Interpreting and Adapting Hand Input",
      "label": "Other",
      "prob": 0.5663302540779114
    },
    {
      "sentence": "First, we nd the closest ngertip f for each contact using hand-tracking data and then bucket by both key k and nger f to t 2D Gaussians h k , f ( x ) to these subsets of contact points.",
      "label": "Method",
      "prob": 0.4462301731109619
    },
    {
      "sentence": "In this work, we take the rst steps to reducing this oracle to practice by building a neural model of text decoding that combines motion modeling of ngers and a state-of-theart language model.",
      "label": "Method",
      "prob": 0.4504130482673645
    },
    {
      "sentence": "While marker-based hand-tracking is still an optimistic approximation of the delity achievable from an AR/VR headset, our experiments shed light on the potential of hand-tracking-based text decoding.",
      "label": "Result",
      "prob": 0.48003631830215454
    },
    {
      "sentence": "In this interactive setting we constrained our beam search decoder to force convergence for any predictions older than 6 frames (0.1s) causing all beams to have a common prex.",
      "label": "Result",
      "prob": 0.5491276383399963
    },
    {
      "sentence": "However, the decrease is greater for the contact-",
      "label": "Result",
      "prob": 0.5814774632453918
    },
    {
      "sentence": "Motivated by this nding, we hypothesized that providing a richer input feature that includes which nger pressed a key can help a model disambiguate which key was pressed.",
      "label": "Result",
      "prob": 0.578900933265686
    },
    {
      "sentence": "Typing on a at surface is analogous to typing on a soft keyboard on a smartphone and inherits similar problems such as noisy input and systematic offsets [14] which can be addressed via statistical decoding methods [7, 10, 25] (see below).",
      "label": "Method",
      "prob": 0.5083039402961731
    },
    {
      "sentence": "To use nger identity information, we make two changes to our Gaussian contact decoding baseline.",
      "label": "Method",
      "prob": 0.4913274943828583
    },
    {
      "sentence": "The touchpad was calibrated by placing three retroreective hemispheres at corners of the touchpad and tting a transform to align those 2D touchpad coordinates with the corresponding 3D marker positions.",
      "label": "Method",
      "prob": 0.4884227514266968
    },
    {
      "sentence": "We show that we can combine our motion model with a language model, also represented as a neural network, using an efcient beam search decoding technique.",
      "label": "Method",
      "prob": 0.51229327917099
    },
    {
      "sentence": "The resulting touchpad training dataset consists of samples where we have",
      "label": "Result",
      "prob": 0.4302360415458679
    },
    {
      "sentence": "To evaluate the feasibility of using hand-tracking to enable touch typing on virtual keyboards, we rst collect a dataset of skeletal hand-tracking data from touch-typists transcribing short phrases while typing on a at surface.",
      "label": "Method",
      "prob": 0.3252009153366089
    },
    {
      "sentence": "For each participant, data was collected in three distinct blocks in the following order:",
      "label": "Result",
      "prob": 0.5401737689971924
    },
    {
      "sentence": "We will need to handle a lower quality",
      "label": "Result",
      "prob": 0.42941024899482727
    },
    {
      "sentence": "This result is consistent with previous ndings on the performance envelopes of human typing [4] which described the high potential of typing speeds given a limited text decoding oracle.",
      "label": "Result",
      "prob": 0.7385640144348145
    },
    {
      "sentence": "Still, the remaining discrepancy in descriptive statistics between hand motion decoding UER and both baselines suggests that nger trajectory information is helpful for further disambiguating typed text.",
      "label": "Result",
      "prob": 0.7259554266929626
    },
    {
      "sentence": "Our language model consists of 19MB of weights.",
      "label": "Result",
      "prob": 0.5123761892318726
    },
    {
      "sentence": "We decoded all test set samples using the Gaussian, Per Finger Gaussian, and our hand motion model with a greedy decoder with no language modeling.",
      "label": "Result",
      "prob": 0.46258872747421265
    },
    {
      "sentence": "better understanding which aspects of the motion model make it perform so well.",
      "label": "Result",
      "prob": 0.6713749170303345
    },
    {
      "sentence": "In each of the remaining samples we expect that the N th contact event corresponds to the N th character in the prompted phrase.",
      "label": "Result",
      "prob": 0.7121264934539795
    },
    {
      "sentence": "We show that tracking hands typing on a at surface combined with our statistical decoding method has the potential of achieving speeds comparable to typing on a physical keyboard while maintaining low-error rates.",
      "label": "Result",
      "prob": 0.40057066082954407
    },
    {
      "sentence": "The problem of generating text from hand motion has strong analogs to automatic speech recognition (ASR), and we use ASR as motivation to design a multi-component system with the following three pieces.",
      "label": "Method",
      "prob": 0.3195696771144867
    },
    {
      "sentence": "In both cases, we also captured their hand motion using a marker-based hand-tracking system [12].",
      "label": "Other",
      "prob": 0.3877536356449127
    },
    {
      "sentence": "To lter samples where both an extra and a missing contact event occurred (leading to an agreement on counts but an error in contact-key sequence alignment), we build up a distribution for each key of how many times each nger hit that key.",
      "label": "Method",
      "prob": 0.36983561515808105
    },
    {
      "sentence": "This model also lacks the",
      "label": "Result",
      "prob": 0.5004073977470398
    },
    {
      "sentence": "Participants typed phrases up to 40 characters long drawn from two corpora; samples used to t or train models were randomly sampled from Daily Dialog [19], while samples for testing and evaluation were randomly sampled from Mackenzie and Soukeroff [23].",
      "label": "Other",
      "prob": 0.6063323616981506
    },
    {
      "sentence": "With greedy decoding, the 2D contact-based methods appeared to have higher variance, though the median UER was comparable across the three strategies.",
      "label": "Result",
      "prob": 0.7571300268173218
    },
    {
      "sentence": "3. 5 minutes of test set phrases on a touchpad",
      "label": "Result",
      "prob": 0.41693708300590515
    },
    {
      "sentence": "UIST '20, October 2023, 2020, Virtual Event, USA",
      "label": "Other",
      "prob": 0.7855333685874939
    },
    {
      "sentence": "For our language model, we use a Transformer [24] model similar to the small-two model described in [15] with 4.76M parameters.",
      "label": "Result",
      "prob": 0.41479671001434326
    },
    {
      "sentence": "We created a toy text entry application with an Oculus Rift and the Unity game engine to demonstrate real-time touch typing on a at surface in VR using hand-tracking (Figure 9).",
      "label": "Method",
      "prob": 0.4040766954421997
    },
    {
      "sentence": "keyboard and surface test set phrases.",
      "label": "Other",
      "prob": 0.485970675945282
    },
    {
      "sentence": "Our rst evaluation is to determine if participants are able to transfer their existing skills typing on a physical keyboard to typing on a at surface (with the help of our proposed decoder).",
      "label": "Result",
      "prob": 0.41641318798065186
    },
    {
      "sentence": "Instead of requiring users to make precise contacts on a xed keyboard layout, we investigate using a motion model to recognize nger trajectories, and we further explore how statistical decoding techniques affect performance.",
      "label": "Method",
      "prob": 0.3620185852050781
    },
    {
      "sentence": "Using the cleaned training dataset, we obtain a sequence of keys pressed { w  i } and a sequence of 2D contact points from the touchpad { x  i } (See Figure 5).",
      "label": "Result",
      "prob": 0.5255790948867798
    },
    {
      "sentence": "We found that our expert typists generally typed efciently both on physical keyboards (median: 75 WPM, mean: 74 WPM) as well as on surfaces (median: 69 WPM, mean: 73 WPM).",
      "label": "Result",
      "prob": 0.6550422310829163
    },
    {
      "sentence": "We believe the on-surface domain, while slightly less accessible, better leverages existing typing skills, allowing our method to achieve speeds comparable to typing on a keyboard at a low error rate.",
      "label": "Method",
      "prob": 0.5083824396133423
    },
    {
      "sentence": "A naive greedy approach to decoding is to generate a label for each frame t  T by taking ` t = argmax k v t ( k ) .",
      "label": "Other",
      "prob": 0.4795151948928833
    },
    {
      "sentence": "To evaluate handtracking as an input modality compared to contact data from touchpads or to physical keyboards, we asked participants to type each phrase on either a physical keyboard or on a Sensel pressure sensitive touchpad with a printed 2D keyboard layout afxed (See Figure 3).",
      "label": "Method",
      "prob": 0.562211275100708
    },
    {
      "sentence": "This work is licensed under a Creative Commons Attribution International 4.0 License.",
      "label": "Other",
      "prob": 0.8118007183074951
    },
    {
      "sentence": "We apply a beam search decoder to resolve these ambiguities using the language model as a prior.",
      "label": "Method",
      "prob": 0.5718343257904053
    },
    {
      "sentence": "This distribution over the set",
      "label": "Other",
      "prob": 0.49759766459465027
    },
    {
      "sentence": "We note that this less ltered training dataset more closely mirrors the testing dataset.",
      "label": "Result",
      "prob": 0.75075364112854
    },
    {
      "sentence": "We also show that our hand-tracking-based decoder can produce signicantly lower error than two baselines using contact-based text decoding (with and without nger identity information).",
      "label": "Result",
      "prob": 0.8207222819328308
    },
    {
      "sentence": "[26] use Gaussian Process regression to model key targets.",
      "label": "Result",
      "prob": 0.6025448441505432
    },
    {
      "sentence": "A Wilcoxon signed-rank test also showed no statistically signicant difference (p = 0 . 859) with participants typing speed across the two modalities.",
      "label": "Result",
      "prob": 0.7650445699691772
    },
    {
      "sentence": "For our second baseline, Per Finger Gaussian contact decoding , we specically investigate if augmenting the spatial model input with nger identity information improves performance of the contact-based model.",
      "label": "Result",
      "prob": 0.6587716937065125
    },
    {
      "sentence": "During inference, the likelihood of a novel 2D contact point is measured according to each Gaussian, and the resulting distribution over all keys is then normalized p ( k ; x ) = g k ( x ) /  Kk 0 = 1 g k 0 ( x ) .",
      "label": "Result",
      "prob": 0.35858315229415894
    },
    {
      "sentence": "Specically, we make the following contributions:",
      "label": "Other",
      "prob": 0.6275926828384399
    },
    {
      "sentence": "Surveys of internet users show that even average typists can achieve speeds greater than 50 words per minute (WPM) with the fastest 90 th percentile achieving more than 78 WPM [3].",
      "label": "Other",
      "prob": 0.7985785007476807
    },
    {
      "sentence": "Instead of relying on surface contact information (e.g., from capacitive touch), we investigate using the output of a marker-based hand-tracking system [12].",
      "label": "Result",
      "prob": 0.39110293984413147
    },
    {
      "sentence": "We repeat our evaluation of the two baselines on this corresponded contacts dataset, isolating the value of trajectories from the value of continuous decoding and nger identity information.",
      "label": "Result",
      "prob": 0.7000564336776733
    },
    {
      "sentence": "We use a temporal neural network as a motion model.",
      "label": "Method",
      "prob": 0.49971312284469604
    },
    {
      "sentence": "(p = 0 . 011), indicating that factors beyond nger identity had a strong impact on performance.",
      "label": "Result",
      "prob": 0.8051679134368896
    },
    {
      "sentence": "Our work is most similar to that of Zhu et al.",
      "label": "Other",
      "prob": 0.7562485933303833
    },
    {
      "sentence": "We can do better than greedy decoding by using a prex beam search decoder [13].",
      "label": "Other",
      "prob": 0.5743146538734436
    },
    {
      "sentence": "We use a beam search implementation with beam compaction which maximizes the objective W = argmax W p total .",
      "label": "Result",
      "prob": 0.5296451449394226
    },
    {
      "sentence": "We have shown on a 20 person dataset that touchtypists can transfer their skills typing on a physical keyboard to typing on a at surface, reaching comparable typing speeds (73WPM) while retaining an uncorrected error rate of less than 2.4%.",
      "label": "Result",
      "prob": 0.860016942024231
    },
    {
      "sentence": "A Wilcoxon signed-rank test found the motion model performance to be signicantly better than both Gaussian (p = 0 . 0258) and Per Finger Gaussian decoding",
      "label": "Result",
      "prob": 0.7400556802749634
    },
    {
      "sentence": "While this is not an interactive result, it simulates the same condition of decoding additional text from the user after a model had been trained (although without providing visual feedback to the user).",
      "label": "Result",
      "prob": 0.8449791073799133
    },
    {
      "sentence": "The previous experiments show that our continuous hand motion decoding method is more accurate than decoding of discrete contacts with either a simple Gaussian spatial model or a richer model with nger identity information.",
      "label": "Result",
      "prob": 0.7023471593856812
    },
    {
      "sentence": "We then tested a beam search decoder with a language model on the same three conditions.",
      "label": "Result",
      "prob": 0.6347917914390564
    },
    {
      "sentence": "Using the foot pedals participants discarded a median 15.89% of surface phrases compared to 12.5% of physical keyboard phrases; a Wilcoxon signed rank test found no signicance ( p = 0 . 328).",
      "label": "Result",
      "prob": 0.7142394781112671
    },
    {
      "sentence": "In order to disentangle the benet of continuous motion decoding versus discrete contact decoding, we lter our test dataset similarly to our training set to contain only samples where we know the correspondences between contact events and ground truth character labels.In this ltered corresponded contacts dataset, there are no samples with missing or spurious contacts.",
      "label": "Result",
      "prob": 0.7038918137550354
    },
    {
      "sentence": "Our result reduces this oracle to practice by substituting it with our proposed neural text decoder.",
      "label": "Result",
      "prob": 0.6839298605918884
    },
    {
      "sentence": "While we are targeting a different sensing modality (hand-tracking instead of capacitive touchpads), we can use touchpads as a baseline for our work.",
      "label": "Result",
      "prob": 0.7451671957969666
    },
    {
      "sentence": "on the rst page.",
      "label": "Other",
      "prob": 0.7811543941497803
    },
    {
      "sentence": "Participants typed on physical keyboards with a mean UER of 1.72% (median: 1.19%) compared to a mean UER of 2.38% (median: 1.77%) when they typed on at surfaces with our decoder.",
      "label": "Result",
      "prob": 0.6873884201049805
    },
    {
      "sentence": "For all of our results, we use B = 100 beams.",
      "label": "Result",
      "prob": 0.7493295669555664
    },
    {
      "sentence": "Participants wore elastic mesh gloves with 19 retro-reective motion capture markers afxed, and the method from Han and colleagues [12] was used to generate skeletal hand tracking informationspecically, joint angles and wrist transforms necessary to drive a tted hand mesh.",
      "label": "Method",
      "prob": 0.8342400193214417
    },
    {
      "sentence": "Similar to our proposed method, Velocitap [25]",
      "label": "Result",
      "prob": 0.4788769483566284
    },
    {
      "sentence": "based methods, which makes the differences between hand motion decoding and the two baselines no longer statistically signicant ( p = 0 . 300 for Gaussian and p = 0 . 109 for Per Finger Gaussian) according to a Wilcoxon signed rank test.",
      "label": "Result",
      "prob": 0.7984917759895325
    },
    {
      "sentence": "Using our touchpad evaluation dataset we compared the two baselines with our motion model approach (Figure 8).",
      "label": "Result",
      "prob": 0.6991755962371826
    },
    {
      "sentence": "Second, at inference time, we use the known ngertip f to compute the distribution over the set of keys for a specic nger p ( k ; x , f ) = h k , f ( x ) /  K = 1 h k 0 , f ( x , f ) k 0 .",
      "label": "Other",
      "prob": 0.5714702010154724
    },
    {
      "sentence": "When we examined the results qualitatively, we noted several differences between the contact-based decoding approach and our handtracking-based approach, which we illustrate in Table 2.",
      "label": "Result",
      "prob": 0.8095165491104126
    },
    {
      "sentence": "We rst investigate touch typists ability to transfer their physical keyboard typing skills to typing on virtual keyboards imposed on at surfaces, and we then compare the performance of decoding text from skeletal hand-tracking data to decoding text from 2D surface contact points from a touchpad.",
      "label": "Method",
      "prob": 0.46114349365234375
    },
    {
      "sentence": "A Wilcoxon signed-rank test showed no statistically signicant difference (p = 0 . 131), however the descriptive statistics might suggest that users can still type more accurately on physical keyboards (Figure 4).",
      "label": "Result",
      "prob": 0.8571968674659729
    },
    {
      "sentence": "Matt Durasoff",
      "label": "Other",
      "prob": 0.883077085018158
    },
    {
      "sentence": "All of our results were computed over the test set portion of the data.",
      "label": "Result",
      "prob": 0.844043493270874
    },
    {
      "sentence": "Redmond, WA",
      "label": "Other",
      "prob": 0.8879026770591736
    },
    {
      "sentence": "Furthermore, we can incorporate a joint probability from both the likelihood of the beam according to the motion model p ( W ; V ) as well as the likelihood of the compacted text according to a language model p lm ( W ) , i.e.,",
      "label": "Other",
      "prob": 0.6618010997772217
    },
    {
      "sentence": "We follow the TCN architecture proposed by Bai et al.",
      "label": "Other",
      "prob": 0.7871047854423523
    },
    {
      "sentence": "Facebook Reality Labs",
      "label": "Other",
      "prob": 0.8546572327613831
    },
    {
      "sentence": "Facebook Reality Labs",
      "label": "Other",
      "prob": 0.8546572327613831
    },
    {
      "sentence": "Facebook Reality Labs",
      "label": "Other",
      "prob": 0.8546574115753174
    },
    {
      "sentence": "When we attempted to train a single between-users model on the combined training sets of all users, the performance did not match the user specic models (UER rose from 2.4% to 3.9%, which a Wilcoxon signed rank test found to be signicant, p = 0 . 001).",
      "label": "Result",
      "prob": 0.8370351195335388
    },
    {
      "sentence": "uses beam search with a language model to decode whole sentences at a time, although Velocitap uses contact as the input modality while our method uses hand-tracking.",
      "label": "Method",
      "prob": 0.8088526725769043
    },
    {
      "sentence": "Robert Wang",
      "label": "Other",
      "prob": 0.878190815448761
    },
    {
      "sentence": "Gunawardana et al.",
      "label": "Other",
      "prob": 0.9153225421905518
    },
    {
      "sentence": "We present two evaluations of our proposed text entry method using the data collected from our user study.",
      "label": "Result",
      "prob": 0.6739934682846069
    },
    {
      "sentence": "Repeating the evaluation of the previous two baselines on this ltered corresponded contacts dataset, we found a substantial drop in the mean UER for all methods (Table 1), suggesting that removing spurious or missing key-presses makes for an easier dataset.",
      "label": "Result",
      "prob": 0.8542827367782593
    },
    {
      "sentence": "We achieved this result through the introduction of a novel motion model mapping hand motion to text, represented as a temporal neural network, and the application of beam search decoding combined with a modern neural language model.",
      "label": "Result",
      "prob": 0.748664140701294
    },
    {
      "sentence": "For our rst baseline, Gaussian contact decoding , we evaluate performance using the spatial modeling approach described by Zhu et al.",
      "label": "Other",
      "prob": 0.7574648857116699
    },
    {
      "sentence": "Goodman et al.",
      "label": "Other",
      "prob": 0.9173194169998169
    },
    {
      "sentence": "echo@fb.com",
      "label": "Other",
      "prob": 0.9306744337081909
    },
    {
      "sentence": "When we added the beam search language model decoder, however, we found that both Gaussian and Per Finger Gaussian contact-based methods performed comparably with a mean UERs of 5.66% (median 2.70%) and 4.76% (median 2.64%) respectively, while our motion model approach outperformed both with a mean UER of 2.38% (median 1.77%).",
      "label": "Result",
      "prob": 0.8525882959365845
    },
    {
      "sentence": "Kristensson et al.",
      "label": "Other",
      "prob": 0.930647611618042
    },
    {
      "sentence": "Weir et el.",
      "label": "Other",
      "prob": 0.9297558665275574
    },
    {
      "sentence": "Yang et al.",
      "label": "Other",
      "prob": 0.9268543124198914
    },
    {
      "sentence": "Author Keywords",
      "label": "Other",
      "prob": 0.9486260414123535
    }
  ]
}