{"sections":[{"body":"CCS CONCEPTS • Human-centered computing → Empirical studies in HCI; Empirical studies in collaborative and social computing; Empirical studies in ubiquitous and mobile computing.\nKEYWORDS computer-mediated communication, biosignals, interpersonal communication, social connection, smartwatches, heart rate, couples ACM Reference Format: Fannie Liu, Chunjong Park, Yu Jiang Tham, Tsung-Yu Tsai, Laura Dabbish, Geof Kaufman, and Andrés Monroy-Hernández. 2021. Signifcant Otter: Understanding the Role of Biosignals in Communication. In CHI Conference on Human Factors in Computing Systems (CHI ’21), May 8–13, 2021, Yokohama, Japan. ACM, New York, NY, USA, 15 pages. https://doi.org/10.1145/3411764. 3445200 ∗Also with Carnegie Mellon University.\nPermission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for proft or commercial advantage and that copies bear this notice and the full citation on the frst page. Copyrights for third-party components of this work must be honored. For all other uses, contact the owner/author(s). CHI ’21, May 8–13, 2021, Yokohama, Japan © 2021 Copyright held by the owner/author(s). ACM ISBN 978-1-4503-8096-6/21/05. https://doi.org/10.1145/3411764.3445200"},{"header":"1 INTRODUCTION","body":"Today, we rely heavily on digital technology to connect with others. Furthermore, with the global COVID-19 pandemic diminishing in-person social contact, technology-mediated communication is more prominent than ever before [35]. However, digital communication is well-known to be challenging due to limited access to important nonverbal cues, such as our body movements and facial expressions [32, 60, 63].\nAn emerging area of research in HCI has explored a novel social cue for improving the way we interact over technology: our biosignals. Biosignals, such as heart rate and skin conductance, are well known to change according to our physical and emotional responses, and can be revealed in everyday interactions using wearable sensor technologies. For example, applications like Pulsoid or Onbeat1 explore this possibility through livestreams of heart rate during gameplay or exercise. Researchers have shown that expressive biosignals, or biosignals displayed as a social cue, have the potential to facilitate communication as a means to recognize and express our emotions and physical being [21, 23, 26, 40–43, 50, 55, 57]. However, researchers have not yet described the role that biosignals play in communication. Biosignals are personal and private data that require careful design and consideration [20, 22, 26, 41]. In particular, as cues that are sensed and recommended by systems, they present a new form of AI-mediated communication that could shape our interactions in unintended ways [25]. Thus, it is crucial that we understand the value and consequences of integrating them into our existing means of communicating.\nIn the present work, we expand on expressive biosignals literature by demonstrating the efects of shifting from communication without biosignals to communication with biosignals. We designed, developed, and deployed Signifcant Otter, an Apple Watch and iPhone app that enables romantic couples to send heart rate-driven otter animations as messages to each other. By setting adaptive thresholds for each person based on their past heart rate and motion data, Signifcant Otter intelligently suggests animations that match their current emotional and physical state. To explore the design of expressive biosignals as AI-mediated communication, we incorporate AI-recommended sets of shareable sensed states. In a one-month within-subjects feld study, we investigate how couples’ behaviors and perceptions are afected when shifting from a sensing OFF version of the app, with no biosignals sensed, to a sensing ON version, with biosignals sensed. We present qualitative results from interviews during the study and discuss opportunities and challenges for biosignals in communication.\nThe core contributions of this work are: (1) Signifcant Otter2, a novel smartwatch and phone app that promotes communication and connection between romantic partners through animated avatars recommended based on heart rate; (2) an empirical study with 20 couples who used Signifcant Otter with sensing OFF and ON that demonstrates the value of biosignals as a lightweight and authentic social cue; (3) design implications and future directions for expressive biosignals research, including suggestions for integration into social platforms as a form of AI-mediated communication.\n1https://pulsoid.net/ and http://onbeat.ft/ 2Signifcant Otter is publicly available on the App Store at the following link: https: //apps.apple.com/us/app/signifcant-otter-couples-app/id1450105275"},{"header":"2 BACKGROUND","body":""},{"header":"2.1 Research Context: Technology for Romantic Couples","body":"For the purposes of this study, we focus on communication between romantic couples. Given the intimate nature of physiological data [26], people feel most comfortable sharing them with close others [41], who may also be the most interested and equipped to understand them as limited contextual cues. For instance, couples can interpret work breaks or distance from home based how many steps their partner has made [14]. In lightweight communication, defned by quick exchanges [8] through minimal interaction or content generation, even minimal messages between close partners can convey meaning like “thinking of you” [7, 28]. Thus, we target the closest partners: signifcant others.\nA breadth of HCI research has explored technologies that can support signifcant others, including those that integrate biosignals. In their review on technology-mediated intimacy, Hassenzahl and colleagues described diferent strategies for supporting important aspects of intimacy [16]. For example, physicalness represents the physical aspect of intimacy, and has been simulated through mediated touch [15] and gestures [12, 52], as well as feeling someone else’s heartbeat [64]. Expressivity describes expressing feelings through a language unique to the couple, such as mutual afection through “on-of” signals [29] or couple-specifc symbols [36]. Awareness of one’s partner has been explored in systems that display a partner’s presence, activities, and mood through availability [6, 10] or sensed contextual information like location [2, 66], motion [3, 67], and heart rate [17], or a combination of these data [14].\nWith the integration of biosignals, Signifcant Otter similarly incorporates physicalness, expressivity, and awareness to support intimate communication. Signifcant Otter can simulate physicalness through shared heart rate representing the body’s physical state. It can support expressivity by providing an emotional language for couples through otter animations embedded with heart rate, which communication partners can use to create emotional meaning together [41]. Finally, the app’s heart rate animations can enable awareness by providing contextual cues that display presence, activities, and mood [17, 42]. We describe the full Signifcant Otter system in Section 3."},{"header":"2.2 AI-Mediated Communication","body":"Hancock and colleagues defne AI-mediated communication as “mediated communication between people in which a computational agent operates on behalf of a communicator by modifying, augmenting, or generating messages to accomplish communication or interpersonal goals.” They suggest that AI-mediated communication systems may have important efects on interpersonal dynamics, including self-presentation and disclosure, and subsequently, meaningful and intimate relationships [25]. As a relatively new area of research, much of the AI-mediated communication work has focused on text, such as AI-recommended wording in emails [4] and AI-generated profles on sites like AirBnB [25]. The present work expands on this research by exploring AI-mediated communication through expressive biosignals.\nExpressive biosignal systems recommend a user’s current state as part of interpersonal communication. The recommendation can be used to augment communication, such as by providing emotional context for text messages [17, 41] and joint activities in mixed reality [55], or to generate new messages in communication, such as emoji-like animations [42]. Like other forms of AI-mediated communication, AI-recommended states through biosignals could impact key aspects of communication. For example, in their deployment of Ripple, a shirt that displayed a wearer’s skin conductance, Howell and colleagues found that people granted the system high degrees of authority over their feelings and, therefore, the feelings they conveyed to others [22]. On the other hand, Liu and colleagues showed that some people may strongly disagree with an AI-recommended state, and subsequently fail to use the system to communicate meaningfully with others [42]. To address these issues, we explore the design of an expressive biosignal system with a lower level of autonomy, i.e., the degree of control it has over messages [25]. Specifcally, we explore communication in which people choose between shareable states suggested by the AI, rather than the AI providing only one possible state. To understand the efects of biosignals-based recommendations, we compare people’s perceptions of their communication when they can share from a set of random versus sensed states, described in more detail in Section 3."},{"header":"2.3 Efects of Biosignals on Communication and Connection","body":"Existing literature on expressive biosignals have primarily explored their potential for supporting how we communicate and connect with each other. Following the interaction model of communication [65], these works suggest that biosignals can support the key stages of communication: sending a message, receiving and understanding that message, and responding to it with feedback. By sharing their biosignals as a message, a sender can express both emotions and daily activities, such as texting one’s heart rate to convey feeling down or taking a walk [41]. Upon viewing the sender’s biosignals, a receiver can become aware of the sender’s state. Hassib and colleagues showed that when accessing someone’s heart rate on a mobile messaging app, people can recognize when that person is angry or on their way home [17]. A recent controlled study also showed that biosignals increase emotional perspectivetaking, or imagining someone else’s emotions, in the context of a narrative story [43]. Receivers may subsequently respond with feedback based on their understanding of the sender’s emotions. In prior studies where people shared their biosignals in conversation or sporadically during the day, receivers often acknowledged, provided support for, or discussed the meaning of the sender’s biosignals [21, 22, 42].\nExpressive biosignals may also impact social connection, or “a person’s subjective sense of having close and positively experienced relationships with others in the social world” [56]. According to Slovák and colleagues, expressive biosignals may promote connectedness between people in two ways. First, they suggest that expressive biosignals are a form of emotional self-disclosure, as they can represent our internal emotional reactions during personal experiences [57]. Self-disclosure is crucial for people to connect with each other, where it can improve the quality of interactions\nand closeness in relationships [1, 39]. Second, Slovák and colleagues suggest that biosignals indicate a person’s physical being as a representation of the daily physiological workings of our heart and other organs, thereby creating feelings of presence [57], which can lead to feelings of connectedness [24]. For instance, Howell and colleagues showed that listening to someone’s heartbeat on a bench can elicit a sense of being alive and connected to another living person [23]. Moreover, Liu and colleagues suggest that remote interactants can feel present with each other when sharing their biosignals over smartwatches [42].\nAlthough these prior works suggest the potential for biosignals to support communication and connection, they have not illustrated the value of expressive biosignals. In particular, their emotionally expressive ability may already be achieved verbally and nonverbally through emojis and stickers [44, 59]. Since expressive biosignals can elicit concerns around privacy [41, 57], cognitive load [40], and accuracy [22, 42, 47], it is crucial that we understand the value they add to existing modes of expression. Research suggests several possibilities for expressive biosignals to improve how we interact today, drawing from their potential to validate feelings as “objective” cues [22, 41, 55]. In the diferent stages of communication, biosignals sent as a message could be a more vivid way to express ourselves emotionally, understand those expressions directly from the body, and subsequently provide improved feedback. As vivid emotional expressions from our bodies, they may be perceived as more authentic and intimate disclosures of our internal experiences, leading to greater feelings of connection. We explore these possibilities by comparing communication with and without biosignals.\nTo our knowledge, only a few studies have compared the presence and absence of biosignals in social contexts [9, 26, 43, 46]. However, these works did not test in real-world dyadic communication, instead focusing on perceptions of a target other in controlled laboratory settings. We address this gap through a feld study with couples who used two versions of Signifcant Otter, an expressive biosignals app. Specifcally, we investigate communication and social connection between couples who shift from a sensing OFF version, with no biosignals, to sensing ON, with biosignals.\nRQ1: How does shifting from sensing OFF to sensing ON afect the stages of communication (sending, understanding, responding) between couples? RQ2: How does shifting from sensing OFF to sensing ON afect social connection between couples?\nWe designed Signifcant Otter based on prior expressive biosignals systems tested in everyday contexts [41, 42]. Like these works, we focus on heart rate due to its wide availability on consumergrade wearables compared to other biosignals, representing the data as an animated avatar. However, unlike prior systems, Signifcant Otter recommends a set of heart rate-driven avatars, rather than a single number or avatar, in order to further explore biosignals in AI-mediated communication. We detail our system in the following section."},{"header":"3 SIGNIFICANT OTTER SYSTEM","body":"Signifcant Otter is an Apple Watch and iPhone app that enables two people to send animated otter characters to each other based on their biosignals. Each person has an animated otter that refects\ntheir inner state, which they can send to their partner. We designed Signifcant Otter to provide a playful way for couples to communicate. The app has been publicly available since November 2019, and over 59 thousand people have installed it as of January 2021.\nTo investigate our research questions, we created two study versions3 of the Signifcant Otter app: sensing ON and sensing OFF, where biosignals are either sensed or not sensed, respectively. With sensing ON, people can send otter animations from a list of sensed states, suggested based on their biosignals. With sensing OFF, people can send otter animations from a list of random states, randomly selected by the system. For both versions, the app prompts people to name their otter and pair with the partner. Sensing ON requires people to accept HealthKit4 and Motion & Fitness5 permissions to access sensed heart rate and activity data from the watch. People can then view their otter on their watch or phone, and scroll through the list of animated states to send one to their partner. We developed Signifcant Otter as a watch-frst app, since smartwatches can be an unobtrusive and lightweight platform for communicating biosignals [42], but we included a phone version due to Apple’s watch app requirements at the time."},{"header":"3.1 Pilot Studies","body":"We ran two pilot studies as initial tests for Signifcant Otter. The frst pilot tested people’s understanding of the sensing ON version, to ensure that people would recognize that their heart rate is sensed and tied to the animations. The pilot included seven couples (employees of a technology company and their signifcant others) who used the app freely for one week and were asked about their usage and perceptions of the app. Based on their responses, we iterated on the app to improve its usability. For instance, we determined the fnal list of animations based on the pilot results, which suggested that we should include states that people typically relate to heart rate (e.g., exercise), as well as limit the number of available animations for usability. The second pilot tested transitioning from sensing OFF to sensing ON. We ran this pilot for three weeks with three couples (employees of the same technology company and their signifcant others). The results confrmed that people viewed sensing ON as a feature update that included biosignals, and provided initial insights that informed the development of the study materials. We also ran this pilot during the early stages of the COVID-19 stay-at-home orders for many states in the United States. Stay-at-home orders required that people stay in their residences except for essential trips, such as for daily food and supplies or if they were essential workers (e.g., life-sustaining occupations, including employees in healthcare, food retail, and public transportation). The pilot informed ways to address possible COVID-19 circumstances that would afect the study. The fnal versions of the study app and study design are described in the following sections.\n3Study versions of Signifcant Otter were not publicly available. Public users were not included in our study. 4HealthKit is Apple’s framework for health and ftness data, such as from recorded vital signs and workouts. 5This refers to Apple’s Core Motion framework for motion data, such as accelerometer and gyroscope data."},{"header":"3.2 Otter Animations","body":"People can send two types of animations to their partner: states and reacts. People can send states to initiate communication, and use reacts to respond to their partner’s states. The study versions of the app contain a subset of the animations available in the public version, in order to focus on states that could be interpreted from biosignals.\n3.2.1 State animations. Signifcant Otter presents an interpreted representation for biosignals: animated avatars that correspond to diferent emotional and physical states. That is, the system determines an interpretation for a user’s heart rate by mapping it to multiple possible states, as opposed to presenting raw biosignals data (e.g., a heart rate number) [17]. We made this decision based on prior work [41], which shows that raw data is less engaging and requires additional contextual clarifcation that may not be feasible on a lightweight smartwatch communication app.\nThere are four types of state animations: emotions, activities, greetings, and afection. We chose emotion and activity animations according to expressions through biosignals shown in prior work [41]. We included greeting and afection animations to represent minimal expressions of mutual afection [16], which prior work suggests are common use cases (“hello,” “thinking of you”) on similar apps [42]. To limit the number of available states according to our pilot results, we included only a few greeting and afection states such that we could cover a sufcient number of sensed states (emotions and activities) to address our research questions.\nEmotions. These include excited, angry, calm, sad, surprised, bored, and neutral otter animations. We chose these states to represent each quadrant of the valence-arousal model of emotion [53]. The sensing ON version senses these states using heart rate data extracted from HealthKit. Since valence cannot be determined from the heart rate data, the system suggests states according to arousal levels determined from the data [11]. For instance, excited and angry states are available when people are in high arousal, while the calm and sad states are available when they are in low arousal. Signifcant Otter determines diferent ranges of heart rate based on people’s historical data, including their min, max, walking, and resting heart rates from HealthKit, which Apple updates daily. The ranges are shown in Figure 2, and were determined through empirical testing within the research team.\nActivities. These animations represent daily activities, including eating, sleeping, walking, running, and exercising. Eating and sleeping are time-based activities, inferred from heart rate changes during specifc times. Eating is detected based on common meal times in the US (11AM-2PM and 5PM-8PM) [38] and neutral or high arousal [54], while sleeping is detected based on common bedtimes and hours slept in the US (10PM-8AM) [33] and low or neutral arousal [37]. Walking and running are motion-based activities, classifed by Apple’s Core Motion6. Exercising is detected solely from heart rate changes, and is presented during high or very high arousal.\nGreetings. This category simply contains waving. This is not sensed, as people may want to greet their partner at any moment. Instead, the app rotates availability with the afection animations such that one can always convey either “hi” or “thinking of you” to their partner.\nAfection. This category shows animations where the couple’s two otters are interacting, including hugging and holding hands. These are not sensed, as people may want to show afection at any moment. Instead, these animations randomly rotate with greetings, as described above.\n6Since Apple already provides activity detection for walking and running, we did not use heart rate data to sense those states. However, participants perceived the sensed states as tied to heart rate.\n3.2.2 React animations. We included 14 diferent reacts to cover a variety of responses people could have to their partner’s state. Signifcant Otter initially had 22 react animations, which were designed based on social support literature and existing react systems [61]. For the former, we focused on emotional support, or expressing caring and concern, as other types of support typically require more information [5, 27, 45], which would not be suitable for a lightweight platform. Reacts are not sensed in order to explore people’s decisions around responding to their partner’s states.\nBased on feedback from the frst pilot study, we reduced the number of reacts to increase usability. We ran a survey on Mechanical Turk to understand how people perceive the react animations in order to select the most relevant ones. 45 participants interpreted characteristics of each react (e.g., extent of emotional support it provides), gave an example text message that would prompt them to use it as a response, and wrote the response that they believed it conveyed in words (see supplemental materials). We selected the fnal set of reacts to cover diverse possible responses to the Signifcant Otter states. This included emotions (similar to states), acknowledging the sender’s state or receipt of their state (e.g., “I agree” or “OK”), showing caring and afection for the sender (e.g., “I’m here for you” or “I love you”), and indicating a desire for followup on a diferent platform (e.g., “Call me ASAP”). We removed reacts that elicited interpretations that did not suit the available states or were overly ambiguous."},{"header":"3.3 Sharing Otter States","body":"People can share their otter state through the main screen of Signifcant Otter on their watch or phone. People can enter the main screen through notifcation prompts to view their otter (explained in section 3.5 below), or by opening the app on their own. On the\nwatch, people can open the app through the app complication7 on their watch face, which will show an otter icon, similar to an emoji, of one of their currently available states. The icons are designed to act as short-form representations for the larger animations, such that people can glance to see their state otter without opening the app. After opening the app, people can simply tap on their otter to send it to their partner, and their partner can view the otter’s animated state on their own device (see Figure 1). People can scroll to view and send other possible states, using the Apple Watch crown or swiping up/down on the phone.\nWe show multiple shareable states due to limitations in detecting emotions from signals available on the watch (e.g., low granularity of heart rate, determining valence), as well as recommendations from prior work [42] to explore systems that collaborate with the user to determine their state. By providing a limited set of other possible states, people can refect on their subjective emotions alongside the app’s suggestions, and then select one of the recommended states. Therefore, the system has low autonomy [25], where the states that people send are partially automated and partially determined by the user. At least one afection or greeting state is always included in the sensed state list, as described above. With sensing OFF, the list is restricted to two to fve random states to match the possible sizes of the sensed state list. The states are randomized every 10 minutes to match the frequency of sensing states with sensing ON."},{"header":"3.4 Reacting to an Otter State","body":"When people receive their partner’s otter, they have the option to react within the app. After they view their partner’s state animation, the app will enter the react mode, where they can scroll through all 14 possible reacts (using the watch crown or swiping up/down on the phone) and tap on one to send it as a response to their partner. We include all possible reacts in order to understand people’s preferences and decisions in reacting with certain animations. People can also react through “quick reacts,” selecting from one of four possible reacts shown in the notifcation they receive to respond without opening the app. Quick reacts are only featured on the\nwatch and are primarily included for usability, as a lightweight way to respond without viewing the full animation. The four available quick reacts are fxed and selected based on the most frequently used reacts in the public version of the app (love, nodding, handholding, and hugging). Finally, people can choose not to react by selecting “Don’t react” in the app after viewing the animation, or dismissing the notifcation. Reacts are the same between both study versions of the app in order to explore potential diferences in how people react to their partner’s sensed or randomized state. People cannot react to a react animation. After a user views a react, the app will return to the main screen with the list of states."},{"header":"3.5 Notifcations","body":"3.5.1 Partner’s state oter visit. People are notifed when their partner sends them their state otter. The notifcation includes an otter icon representing their partner’s state otter as well as the four quick reacts (see Figure 6(a)). We used icons for the notifcations such that people can glance at the state they received and dismiss or quick react, if desired. Tapping on the icon opens the app to play their partner’s state animation, and then enter the in-app react mode.\n3.5.2 Partner’s react oter. People are notifed when their partner reacts to a state that they sent. The notifcation includes an icon representing their partner’s react otter. Tapping on the icon opens the app to play the animation of the react otter, alongside an icon representing the state to which their partner is reacting.\n3.5.3 User’s own state oter. People are notifed periodically during the day (at least 45 minutes apart, to minimize invasiveness) with a “Message from your otter” notifcation (see Figure 6(b)). Opening the notifcation shows an icon of an available state animation. We include these notifcations to encourage people to share their current state with their partner. Notifcations are time-based and thus appear regardless of whether the user’s state changed. This is due to limitations of the Apple Watch, which does not enable real-time heart rate sensing (outside of a ftness tracking session) necessary for recording in-the-moment state changes. This also helped to control diferences in the notifcations between the two versions of the app, as the app with sensing OFF cannot record state changes. Tapping on the icon allows the user to view the animation in the 7Complications are widgets for the Apple Watch watch face that display information about an app.\napp. People can also directly send from the notifcation using the “Share” button. With sensing ON, the available state is randomly selected from the list of sensed states (not including greetings or afection). Sensing ON also shows a heart icon to indicate that the state is selected from the sensed list. With sensing OFF, the available state is randomly selected from the list of random states."},{"header":"4 METHODS","body":"To test Signifcant Otter, we deployed the sensing OFF and ON versions of the app in a one-month feld study."},{"header":"4.1 Participants","body":"Recruitment took place from late March to early April 2020, during the COVID-19 stay-at-home orders for many US states. We recruited 21 romantic couples; however, one couple was removed at the start of the study due to failing to meet the minimum participation requirement (explained in the Procedure below). This left a total\nof 20 couples (N=40). Participants were recruited through Reddit posts on the SampleSize and AppleWatch subreddits, recruitment posts for about 30 US cities on Craigslist (including major cities in diferent areas of the US to account for diferences in state responses to COVID-19), and snowball sampling (social media posts).\nParticipants took a screening survey to ensure that they met the study requirements. This included being in an exclusive romantic relationship, living in the US, being able to participate in onboarding and interview sessions via video call, and owning an Apple Watch Series 3 or above that they used for at least two weeks, to ensure familiarity with the watch. Participants described using their Apple Watch for a variety of reasons, predominantly ftness tracking, but also music, news, weather, short texting, and checking notifcations. The screening survey also included several questions about participants’ circumstances concerning COVID-19, including their living situation with their partner. Results from the second pilot study suggested that people are less likely to engage with the app when collocated with their partner (e.g., if they were both\nworking from home); therefore, we recruited couples who were living apart or living together with one or both of them spending most of their time elsewhere.\nThe couples we recruited were diverse in several dimensions, including their backgrounds, careers, demographics, and length of relationship. About half of the couples were not living together, including one couple in a long-distance relationship. The rest of the couples were living together with at least one person working outside as an essential worker. Table 3 summarizes the demographic information per couple. Unfortunately, our sample was not diverse in sexual orientation, where most couples were heterosexual. 13 participants identifed as Hispanic, Latino or Spanish, 11 as White/Caucasian, 9 as Asian, 4 as Black/African-American, 1 as Native Hawaiian or other Pacifc Islander, 1 as Asian/Hispanic, and 1 as Biracial. Participants had various jobs, including students, healthcare professionals, personal trainers, technicians, restaurant workers, and analysts. Six were unemployed or furloughed due to COVID-19."},{"header":"4.2 Procedure","body":"We conducted a one-month study deploying Signifcant Otter in the wild with couples who were Apple Watch users. All participants used the app with sensing OFF for the frst two weeks and with sensing ON for the latter two weeks. We intentionally did not counterbalance the order of the versions, as our research questions focused on the shift from the status quo of communicating without biosignals to communicating with biosignals. Moreover, the removal of “sensing” as a feature in a counterbalanced study could disrupt participants’ mental model of the app, as opposed to a feature update when switching from sensing OFF to ON. The study consisted of the following sessions:\n4.2.1 Onboarding Session. Each couple completed a 30 minute onboarding session with one of the researchers over a video call. During this session, participants installed Signifcant Otter with sensing OFF on their iPhone and Apple Watch through Apple’s TestFlight8 and added the app as a complication on their watch. During the installation, participants completed a short questionnaire about their background and relationship with their partner. Then, we instructed them on using the app, and asked them to test it during the session to ensure that it was installed and working correctly.\n4.2.2 Daily Usage of Significant Oter. Participants could freely use Signifcant Otter as little or as much as they wanted during the study. In order to capture participants’ perceptions of the app and behaviors throughout the study, we asked participants via email to complete brief daily surveys about how they used the app that day (see supplemental materials). The frst daily survey included comprehension questions to ensure that participants understood how to use Signifcant Otter. Given the time and efort involved in flling out a survey every day, we required participants to fll out a minimum of three daily surveys per week.\n4.2.3 Mid-Study Session. Two weeks after their onboarding session, each participant individually completed a 30-60 minute midstudy session over video call. Before the session, participants completed a mid-study questionnaire similar to the onboarding questionnaire, with the addition of questions about COVID-19-related changes they experienced since the start of the study. During the call, we conducted a semi-structured interview about participants’ experiences with the sensing OFF version of the app (see supplemental materials). The interview included questions about participants’ overall thoughts and perceptions about the app and its diferent features (e.g., reactions to the notifcations), and how they used the 8TestFlight is an online service for deploying apps to testers.\napp with their partner (e.g., when and why they sent their own otter, what they thought of their partner’s otter and how they responded, if at all). To help participants recall their experiences, we showed GIFs of the top states and reacts that they sent and received. After completing the interview, participants installed and were given instructions on the sensing ON version of the app. We explained that with sensing ON, the app displays state animations based on heart rate using Health data from the Apple Watch9. After the session, participants were given a $75 Amazon gift card as mid-point compensation.\n4.2.4 Exit Session. Two weeks after their mid-study session, each participant individually completed a 30-60 minute exit session over video call. Before the session, participants completed a questionnaire identical to the mid-study questionnaire. During the call, we conducted a semi-structured interview about participants’ experiences with the sensing ON version of the app. The interview was similar to the mid-study interview, with the addition of questions about how they understood and perceived sensing in the app (see supplemental materials). At the end of the interview, we asked participants to uninstall Signifcant Otter. Since multiple participants expressed interest in continuing to use the app, we provided links to the public version, which participants could freely download. After the session, participants were compensated with another $75 Amazon gift card for completing the study.\n4.2.5 Adjustments and Issues During the Study. During the study, we made updates to the app and some study materials to address issues that emerged as participants used the app. Participants installed bug fxes by uninstalling and reinstalling the app through TestFlight. We also adjusted how we explained the sensing ON version and added related comprehension questions to the daily surveys, since some participants expressed confusion around how sensing worked (e.g., whether opening the app triggered sensing). Additionally, several participants had issues receiving the app notifcations, where they may not have received any during the frst or second half of the study. This is a limitation of the Apple Watch OS, which restricts when and how often apps can send push notifcations. Since we were unable to address this issue, participants received notifcations at diferent frequencies."},{"header":"4.3 Analysis","body":"We analyzed transcripts of the mid-study and exit interviews using a grounded theory approach [58], focused on how participants’ perceptions and behaviors shifted between the two versions of the app. First, we segmented the transcripts into high-level categories according to our interview protocol, which highlighted the different aspects of communication (e.g., content of what they sent, thoughts about their partners’ sent state, feedback provided, etc.). This enabled us to analyze similar concepts together. Categories were the same for the mid-study and exit interviews, with the addition of categories for the exit interview specifc to sensing (e.g., how sensing worked) and external factors that afected usage (e.g., novelty efects, COVID-19-related changes). Next, we developed\n9In the session, we stated: “Version 2 will try to sense your state using your heart rate and other contextual data. The state otters that you’ll be able to see and send to your partner will be based on this sensing.”\nopen codes for each category based on a subset of transcripts, labeling them according to similarities in participants’ responses. Three coders validated the subsequent codebook by independently coding another subset of transcripts, meeting frequently to discuss the codes and ensure high inter-rater reliability. They achieved fuzzy Fleiss’ kappas [34] above 0.7. After validating the codebook, the three coders divided and coded the rest of the segments. We then performed axial coding by grouping similar codes together and analyzing them to form cross-cutting themes. Finally, we refned these themes according to our research questions."},{"header":"5 RESULTS","body":"In this section, we describe how participants used Signifcant Otter during the study and provide detailed insights around the reasons behind their usage for both versions of the app. Overall, participants sent a total of 2,474 states and 987 reacts during the study. For both app versions, we observed novelty efects in the frst week after installation (weeks 1 and 3)10. Participants used the app daily even after novelty efects wore of, sending an average of 1.66 states and 0.71 reacts per day with sensing OFF (week 2) and an average of 1.54 states and 0.54 reacts with sensing ON (week 4). There was a slight non-signifcant drop in usage from sensing OFF to sensing ON, which participants attributed to COVID-19-related changes to their life circumstances (e.g., changes in their work schedule or ability to meet their partner). Despite using the sensing ON version less, 30 out of 40 participants preferred it over sensing OFF for enhancing their ability to communicate and connect with their partner. At the same time, participants experienced challenges in using the app to communicate what they wanted to their partner. We describe these opportunities and challenges for integrating biosignals into communication in more detail below."},{"header":"5.1 Opportunities for Biosignals: “Enhanced","body":"Emojis”\nOur results suggest that sharing sensed states can promote efcient and personal communication between couples, and help them feel connected with each other. This aligns with prior work [42], which similarly showed that people can easily keep in touch through sharing biosignals-driven animated shapes on their smartwatch. We build on this work through our comparison of participants’ usage of Signifcant Otter with sensing OFF and ON. Specifcally, we suggest that the app with sensing OFF functioned similar to emojis, stickers, and GIFs, while sensing ON introduced a new, enhanced form of communication."},{"header":"5.1.1 Efects on the Stages of Communication.","body":"Easier sharing. Participants felt that sharing from sensed state suggestions was easier than sharing from a randomized list of animations. With sensing OFF, participants scrolled through the list of state animations as if they were scrolling through a shorter emoji/sticker/GIF keyboard. They appreciated the readily available, unintrusive messages that helped them quickly communicate back and forth with their partner without having to use words. However, some participants were frustrated with access to only two to 10In week 3, participants described using the app more due to curiosity around the new sensing feature.\nfve random states, expecting a wider and more expressive variety, while others appreciated that they did not need to look through hundreds of options for a specifc one. After updating to sensing ON, participants perceived that the state list was personalized to them, where the sensed states were more accurate to how they were feeling or what they were doing than the randomized states. Thus, their otter became more representative of them and was easier to send to their partner.\n“The sensed state otters [with sensing ON] hit closer to home than [with sensing OFF], where they were just random otters. So it narrowed it down better.” - P3\nThis was reinforced by the smartwatch, which participants were more compelled to use in the latter half of the study in order for the sensing feature to work. P14 noted that the sensing feature gave him a reason to use his watch:\n“I’m not really super attached to this watch compared to my phone.... So I think having a reason to want to use the watch for this app and its sensing my vitals and things like that is...a good thing to include in this type of app.” - P14\nThe smartwatch prompted participants with notifcations that became personalized suggestions about how they were feeling with sensing ON, rather than dismissable nudges to use the app with sensing OFF. When participants viewed the notifcations without opening the app, participants simply made “yes or no” decisions to share their otter rather than scrolling through emoji-like options or even thinking to send their otter on their own.\n“Because it knows exactly how you’re feeling versus like me having to look through it and kinda of tick something. Because sometimes I don’t even know how I’m feeling...you don’t really think about how you’re feeling until you have to...sit and think about it.” - P9\nLess ambiguity. Sharing a sensed otter was also less ambiguous than sharing a randomized otter. With sensing OFF, participants assigned various meanings to the otter animations, including those that they were not originally designed for, such as suggestions and needs. Participants would even send animations with no intended meaning, just to send one to their partner. This fexibility in the otter animations aligns with the fexibility of emojis, where an emoji can be used to convey numerous possible messages [49, 68], and are thus known to be expressive yet ambiguous even when used in textual contexts [48]. With sensing OFF, some participants described following-up over verbal conversation to clarify the animations they sent, or struggling to interpret and respond to the animations they received, subsequently resorting to “safe” otter reacts.\n“Like that walking otter...she might [react with a] thumbs up, but that doesn’t necessarily mean that...she’s understanding that the walking otter means that I would like to go for a walk...the thumbs up could be, ‘yes, I want to go for a walk too.’ It could be like, ‘walking is good.’ So I mean, there’s not a lot of clarity with just having the simplistic reaction.” - P38 “I was confused about that otter...out of my confusion I replied with him because he looked pretty chill.... I was just trying to say no hostility as well, ’cause I didn’t\nknow what the other otter was doing. So that was a pretty safe response.” - P33\nOur results suggest that biosignals helped reduce this ambiguity, where participants no longer assigned diferent meanings to the animations. Instead, the animations became meaningful on their own, where participants understood them as simply representative of their own or their partner’s current state. This facilitated sending state animations, because participants no longer had to think about what they could mean and, like in prior work [41], sent them primarily to share their current state. This also facilitated understanding and responding to those animations, because they could appropriately react when they understood what they meant, such as by agreeing, reciprocating, or showing concern for their partner’s state.\n“When I was sending the message, my intent behind it wasn’t, ‘Oh, I’m reminding you to do something.’ I’m sharing my mood with you...[sensing OFF] was just more inclined to him and [sensing ON] was more inclined to me.” - P36 “I think it’s diferent insofar that I felt like she really wasn’t sending random ones. I feel like they were more based on what she was doing. So for that reason I felt like my reactions were more consistent.” - P39"},{"header":"5.1.2 Efects on Social Connection.","body":"Authenticity. Participants felt that sharing sensed otter animations enabled more open and genuine communication with their partner. While couples used both versions of the app to keep in touch with each other’s current state, they felt that sensing ON enabled a more personal experience with each other because it was backed by data. Participants described feeling more connected to both their own and their partner’s otter because they were tied to their bodies’ physical states, as if they were the otters themselves.\n“It’s personal to me because it’s reading what I’m doing...it’s almost as if you could go through the phone yourself and wave or something like that....[With sensing OFF, it] could have just been a sticker app, an iMessage where you’re just sending from a collection of animated stickers. Once it [sensed] what you were doing throughout the day, it [became] a more personal experience...because it’s sensing what you’re wanting to say throughout the day.” - P35 “It was interesting that both of our body’s responses were being recorded. That’s what I mean by feeling connected like we’re not physically together, but you’re still able to get a sense of their actual bodily responses through the app, like through technology, and that was cool.” - P31\nSeeing their own sensed state also encouraged them to refect on how they were feeling, and be more honest with both themselves and their partner by sharing it with them. Participants similarly felt that their partner was conveying their honest state with them. Some couples noted that even if they are fairly open with each other, they appreciated knowing that their partner’s state was backed by data and that their partner was not just putting up a front.\n“I’m pretty open with my feelings overall in life and with my partner, [but with Signifcant Otter] I’m more open to be like, honest, I guess, like totally 100% honest compared to 95% honest...the 5% can sometimes make a big diference.... I would send the [stressed otter] instead of being like, ‘Oh, I don’t want to look weak right now by showing that I am stressed.”’ - P14 “I feel like [with sensing OFF]...I wouldn’t know if that was actually how he was feeling or if he just picked [a smiley one]...just to send something nice. So knowing that he actually felt that way and [was] probably a little bit happy...was good.” - P37\nThis motivated a few participants to be more thoughtful and responsive in their reactions to their partner, such as reacting more quickly or deliberately. For example, P31, who tended to not respond immediately to her partner’s state with sensing OFF, felt more urgency to respond with sensing ON:\n“ I feel like [the otter’s] a way of him reaching out. So for me to just wait [to] respond and not really think much of it, it feels rude not to validate whatever he sent out, because that is...like a virtual extension of him. So I felt like I needed to respond to it as soon as I saw.” - P31\nP36, who frequently used the quick reacts with sensing OFF, used them less with sensing ON. She explained that since her partner was sharing his emotions with her, she should put more efort into reacting:\n“Although [quick reacts were] very convenient, I just felt more of a responsibility this time to [open the app]. Just because I felt like my partner was sending me state otters of his emotion. [Doing] a quick react otter...it was kind of dismissing the notifcation in a sense. Opening up the app and scrolling through all reacts so I could choose the right one made me feel like I was more connected with my partner in the interaction.” - P36"},{"header":"5.2 Challenges for Biosignals: Me vs the System","body":"As a system that recommends a user’s current state, Signifcant Otter with sensing ON experienced challenges in how participants perceived and trusted the sensed states. Though most participants felt that their sensed otter accurately refected their feelings and activities, six participants were skeptical of the system’s ability to sense states and disagreed with the suggestions they saw. The sensed states were also restrictive, where the participants believed they were less likely to fnd an animation they wanted to send, while randomization presented equal probability of seeing all states. These participants stated that they would have preferred a list of states with more variety to choose from.\n“Whenever it would send something I would usually get the same otters. So I wish when it was sensing something I would be able to get a variety of otters at diferent times...compared to just one all the time.” - P29"},{"header":"5.2.1 Efects on the Stages of Communication.","body":"Subjective understandings of sensing and emotions. While perceptions of inaccuracy were a barrier for some participants, participants\nranged in their defnition of accuracy, which afected their ability to send their own otter and understand their partner’s otter. Some participants were accepting of the system’s small set of possible sensed states, and gave the app room for error. They did not expect the sensed states to be 100% accurate and reasoned why the app would suggest states that did not quite match them, based on their knowledge of their heart rate or physical state. These participants also described typically being satisfed with at least one state in the list of suggested states, and did not mind if the other states did not fully match them.\n“I would say most of the time it defnitely matched. I mean it was pretty much on par with what I was doing, which was really cool to see. Sometimes after I would go for a walk or something, it would tell me I was surprised rather than like working out. But it was like a walk, so I was not doing crazy workouts. So I could see how that happened.” - P34 “Most people at any given time throughout the day, you might be feeling a lot of diferent things...at least with the sensed version...at least one of the things that it was showing you [matched].” - P38\nConversely, participants who perceived the app as inaccurate tended to expect exactly one accurate state, giving less fexibility for the app to suggest other states that may not match their feelings. These discrepancies in perceptions of accuracy appear to stem from participants’ diferent lay understanding of emotions and how they relate to heart rate. For instance, P1 was confdent in knowing her own feelings better than the app, while P15 was conficted on whether to follow his body (what the app suggested to him) or mind (how he thinks he feels). On the other hand, P14, quoted above, felt his heart was an indicator of how he truly felt, as opposed to how he thought he felt in his mind.\n“I feel like I know what I feel like...this thing is guessing how I feel based on I don’t know what my heartbeat or...I don’t think that’s accurate.” - P1 “I just never knew which one was the most accurate.... I really just thought it was that frst one [in the state list and] the other ones could have been random [or] maybe a second best choice. I just didn’t really fgure out which one to go with, you know? I’m like betraying my heart rate if I choose a diferent one [than the frst one] or something.” - P15"},{"header":"5.2.2 Efects on Social Connection.","body":"Agency and efort in communicating feelings. On the other extreme, a few participants described blindly trusting the system and sending their otter from the sensed state notifcations even if they did not know which animation they were sending. Though the sensing feature was not intended to be highly accurate, these participants felt the system knew their feelings better than they did, and helped them to convey those feelings to their partner.\n“The frst two or three times [that I got the sensed notifcations] they were on target as far as...the way I was feeling. . . . That would be the otter that I was trying to send anyway...so once I realized that that’s what was\nhappening, I wouldn’t think too much about it anymore as far as opening up the app and seeing if it was the otter I wanted to send or anything like that.” - P23\nOne participant warned against this “power of suggestion,” where the system could infuence them into thinking they felt a certain way. This aligns with prior work by Hollis and colleagues [19], which suggests that people may overly trust emotion sensing systems and be infuenced by the system’s interpretations of their emotions.\n“With [sensing ON] it was like always asking yourself whether or not you really felt that way before sending it. And so I don’t know if sometimes that would infuence you to send it anyways or infuence you to maybe feel that way. Yeah so, I do prefer [sensing OFF,] that way whatever you’re feeling...you’re able to just think of it on your own and just send it.” - P18\nAnother participant noticed that by simply accepting and sharing the system’s recommendation, he put less thought into curating a message to send to his partner. He pointed out that while the message itself was personalized to himself, he no longer took the time and efort to consider what to send:\n“I think with [sensing ON] it was me sending stuf based on what I think the watch read that I felt. So it wasn’t me taking the time and going through and saying, yeah, this is the one. It was like, the watch said this is how I feel. So I guess this is how I feel. Let me send it. [It] was almost more impersonal, even though it was reading of of my data.” - P2\nThough the reduced efort made keeping in touch easier, efort is an important quality of communication that contributes to meaningful connection and close relationships [30, 31]. Moreover, work on AI-mediated communication suggests that systems that generate messages for communication, such as Signifcant Otter’s sensed state animations, can afect perceptions of authenticity [51] and trustworthiness [25] in the sender of the message. Thus, despite sensed states being inherently more personal and intimate, they could potentially prompt less personal ways of communicating if the system has more agency than the user. In the following section, we recommend future research directions and system designs to explore how to reconcile this tension."},{"header":"6 DISCUSSION","body":""},{"header":"6.1 Summary of Results","body":"Overall, participants viewed both versions of Signifcant Otter as a lightweight communication channel that enabled them to easily to keep in touch with their partner and let each other know how they are doing. In their baseline usage of the app with sensing OFF, participants felt the otter animations were an easy way to communicate without words, using them to convey their current state and suggest activities. However, this communication was also limited because a simple animation could mean multiple things or required more detail.\nFor most participants, Signifcant Otter with sensing ON mitigated some of the issues with sensing OFF and enhanced participants’ ability to connect with each other. Our results show that\nbiosignals can facilitate each stage of communication (RQ1), where sending, understanding, and responding to the state animations were easier with sensing ON than with sensing OFF, because the app curated more straightforward messages for them to send, distilled to participants’ sensed states as opposed to user-prescribed meanings. Biosignals also supported feelings of connection between romantic partners (RQ2), where participants described feeling compelled to share honest emotions through the sensed state animations, rather than put up a front. Additionally, they felt the sensed otters were more representative of them and their partner, conveying a sense of their body’s physical responses. Taken together, our results describe the role of biosignals in dyadic communication, distinct from system features such as the smartwatch or animated avatars [42], as promoting easier and more authentic communication. However, despite these benefts, biosignals also introduced new concerns around accuracy and agency over the message, where some participants felt the system was overly suggestive on how they were feeling or what to communicate to their partner. This further illustrates the tensions in AI-recommended versus subjectively interpreted emotions found in prior work [19, 22], particularly due to variations in lay understanding or confdence around one’s own emotions."},{"header":"6.2 Design Implications and Future Directions","body":"6.2.1 Sharing sensed states on existing platforms. While having a separate platform like Signifcant Otter dedicated to sharing states can create an intimate experience for couples, the sensed otter animations could easily integrate with existing platforms as “enhanced emojis.” People already increasingly need to navigate multiple communication apps, which can cause “expression breakdowns” when they are unable to consistently express themselves across those apps [13]. By integrating biosignals into existing platforms, people could beneft from centralized communication with their partners while expressing themselves in more authentic ways through the sensed states. In platforms such as texting and mobile messaging, they could also could easily start new conversations about the states they share, a common pattern we observed in our study.\nAs part of existing platforms, biosignals would primarily function as a means to augment communication as opposed to acting as standalone messages like in Signifcant Otter. Rather than relying on relationship context, people would reference the augmented communication content to interpret the biosignals (e.g., text in mobile messaging [18, 41]). Researchers and designers of communication platforms could explore how biosignals could augment various types of communication content, such as images, videos, or emojis, and new interaction patterns that may emerge. For example, biosignals could become new types of “emojis” or integrate with existing emojis by suggesting specifc emojis or limiting the available options. This could help people navigate the ever growing list of emojis, as well as clarify potentially ambiguous emojis. Suggested emojis could be annotated in order to designate them as sensed states (e.g., a heart symbol, beats per minute, or special efect or badge attached to the image).\n6.2.2 Addressing user expectations for sensing. We found that varying perceptions of accuracy and agency over the animations affected participants’ ability to use the sensing ON version of the app. Given people’s own subjective understanding of their state\nas well as ongoing research on emotion detection, designers need to consider how to present and incorporate sensing technology both in its current and future levels of accuracy. That is, even if the system claims to be accurate based on the user’s physical state, the detected emotion may confict with how the user subjectively believes they feel [42] or overly infuence their feelings [19, 22]. For Signifcant Otter, we lowered the autonomy of the system [25], where the app suggested both a single state in notifcations and a list of possible states within the app. Some participants continued to be skeptical of the suggested states, having strong beliefs about how they are feeling, while others were confused by our design, believing that they should see only one recommendation. In fact, a few people did focus solely on the one recommendation in the notifcation, ignoring the list of in-app states.\nFuture directions in this area should investigate new ways for expressive biosignals systems to collaborate with people’s subjective understanding of their own state. For example, researchers could explore systems that support diferent lay theories of emotions and how they afect perceptions of the system’s accuracy, such as whether the user interprets emotions based on external contextual cues or internal physiological experiences [62, 69]. Designers of these systems should clearly and carefully introduce how sensing in the system works. For example, onboarding steps could detail the system’s approach to emotion (e.g., its relationship to the body’s physiological state, why the system might suggest multiple possible emotions), or provide adjustable settings that match one’s personal understanding of their own state. Future work could also explore how to involve people in system recommendations, such that they can have more control over what they are feeling and how they share those feelings. For example, the system could allow people to provide feedback on their state in order to improve the system and feel involved in the system’s suggestions, or prompt them to interpret the suggested state before sharing it with their partner. This could encourage people to engage in more efort and meaning-making with their partner, and enhance the authenticity of the AI-recommended message.\nFinally, researchers should consider how people’s understanding of their state and expectations for the system may be afected by diferent types of expressive biosignals. People may have a more developed understanding about their heart rate given its accessibility, including in ftness trackers and watches, or simply being able to feel when one’s own heart beats faster. On the other hand, less accessible biosignals such as skin conductance or brain activity may be less understood or produce diferent lay interpretations (e.g., associating the brain with cognitive functions), which could potentially afect people’s willingness to accept the system’s state recommendations."},{"header":"7 LIMITATIONS","body":"Though our fndings elucidate the value of expressive biosignals in communication, there are several limitations to this work. First, we ran a non-counterbalanced within-subjects study in order to reduce confusion in participants’ mental model of the app, where sensing was a “feature update” rather than a feature being removed. Most participants perceived sensing ON as a feature update that enhanced their use of the app; however, a few were strongly infuenced by\ntheir mental model of the app with sensing OFF and expected it to work the same way. Moreover, novelty efects were much stronger for sensing OFF than for sensing ON. The number of sent messages dropped by 605 messages between the frst and second week of using sensing OFF, compared to a drop of 77 messages between the frst and second week of using sensing ON. Many participants also described getting used to the app during the second half of the study. We took these diferences into consideration during both our interviews and analyses; however, future work should consider a between-subjects design or longer longitudinal study to reduce potential order or novelty efects.\nSecond, we deployed the app in situ on participants’ own smartwatches for use in their everyday lives, in order to achieve high ecological validity. Given the diferences in participants’ lifestyles, especially during the COVID-19 pandemic, as well as tendencies towards diferent devices (e.g., participants with large hands experiencing difculty interacting with the watch app interface), participants naturally had diverse experiences with the app. Additionally, the app had hard-coded times set for certain states, which may not have matched people’s typical patterns. Future systems should consider providing options for people to set their typical meal or sleeping times, or sense additional signals such as location to better predict their state. Limitations of the Apple Watch OS also afected whether the app worked as intended for all participants, where some participants received no notifcations while others felt that they received too many. Thus, while our qualitative fndings present a variety of interesting communication patterns that stem from participants’ diverse usage, studies with greater levels of control or larger sample sizes are necessary to clarify potential causal effects that biosignals have on communication. More granular data collection would also help to capture and further understand the diferences in participants’ usage, such as the number of notifcations that infuenced sending a state or participants’ perceptions of each sent state.\nFinally, while we recruited a diverse sample of participants from diferent backgrounds, participants were self-selected and may have shown a greater interest in wearable and couple-specifc technologies. Additionally, the shortest relationship length among participants was 11 months. People in earlier stages of their relationship or without established communication practices with each other may use the app in diferent ways. Given stay-at-home orders, we also restricted recruitment to people who were living apart from their partner or living together if one or both of them were essential workers. Thus, we were unable to capture how people that did not match these criteria might use the app outside of these unusual circumstances. It is also possible that our participants would engage with the app diferently outside of these circumstances, as many had to adjust to changes in their daily routine during the study."},{"header":"8 CONCLUSION","body":"We ran a month-long within-subjects feld study on Signifcant Otter, an Apple Watch and iPhone app that enables biosignals sharing through animated otter messages, to explore the role of biosignals in communication. We compared participants’ usage of Signifcant Otter with and without biosignals. Results showed that biosignals\ncan support easier and more authentic communication, while eliciting concerns around accuracy and agency over the communication content based on participants’ diverse understandings of emotions. We provide insights on the opportunities and challenges around integrating biosignals into communication and make recommendations for future research and design, including applying biosignals to existing communication platforms to promote open communication as “enhanced emojis,” and exploring greater user involvement in AI-recommended states."},{"header":"ACKNOWLEDGMENTS","body":"We would like to thank John Tang and Mayank Goel for their early suggestions that helped shape our study design, as well as their feedback on our results. We are also grateful to David Lin for his help with our qualitative analysis, and Sven Kratz for his feedback on our paper submission."}],"type":"Sections"}