{"sections":[{"body":"ar X\niv :1\n90 8.\n07 81\n6v 1\n[ cs\n.C L\n] 1\nOpen-domain dialog systems (also known as chatbots) have increasingly drawn attention in natural language processing. Some of the recent work aims at incorporating affect information into sequence-to-sequence neural dialog modeling, making the response emotionally richer, while others use hand-crafted rules to determine the desired emotion response. However, they do not explicitly learn the subtle emotional interactions captured in real human dialogs. In this paper, we propose a multi-turn dialog system capable of learning and generating emotional responses that so far only humans know how to do. Compared to two baseline models, offline experiments show that our method performs the best in perplexity scores. Further human evaluations confirm that our chatbot can keep track of the conversation context and generate emotionally more appropriate responses while performing equally well on grammar.\nKeywords Dialog systems · Natural language processing · Human-computer interaction"},{"header":"1 Introduction","body":"Recent development in neural language modeling has generated significant excitement in the open-domain dialog generation community. The success of sequence-to-sequence learning [1, 2] in the field of neural machine translation has inspired researchers to apply the recurrent neural network (RNN) encoder-decoder structure to response generation [3]. Specifically, the encoder RNN reads the input message, encodes it into a fixed context vector, and the decoder RNN uses it to generate the response. Shang et al. [4] applied the same structure combined with attention mechanism [5] on Twitter-style microblogging data. Following the vanilla sequence-to-sequence structure, various improvements have been made on the neural conversation model—for example, increasing the diversity of the response [6, 7], modeling personalities of the speakers [8], and developing topic aware dialog systems [9].\nSome of the recent work aims at incorporating affect information into neural conversational models. While making the responses emotionally richer, existing approaches either explicitly require an emotion label as input [10], or rely on hand-crafted rules to determine the desired emotion responses [11, 12], ignoring the subtle emotional interactions captured in multi-turn conversations, which we believe to be an important aspect of human dialogs. For example, Gottman [13] found that couples are likely to practice the so called emotional reciprocity. When an argument starts, one partner’s angry and aggressive utterance is often met with equally furious and negative utterance, resulting in more heated exchanges. On the other hand, responding with complementary emotions (such as reassurance and sympathy) is more likely to lead to a successful relationship. However, to the best of our knowledge, the psychology and social science literature does not offer clear rules for emotional interaction. It seems such social and emotional intelligence is captured in our conversations. This is why we believe that the data driven approach will have an advantage.\nIn this paper, we propose an end-to-end data driven multi-turn dialog system capable of learning and generating emotionally appropriate and human-like responses with the ultimate goal of reproducing social behaviors that are habitual in human-human conversations. We chose the multi-turn setting because only in such cases is the emotion appropriateness most necessary. To this end, we employ the latest multi-turn dialog model by Xing et al. [14], but\nwe add an additional emotion RNN to process the emotional information in each history utterance. By leveraging an external text analysis program, we encode the emotion aspects of each utterance into a fixed-sized one-zero vector. This emotion RNN reads and encodes the input affect information, and then uses the final hidden state as the emotion representation vector for the context. When decoding, at each time step, this emotion vector is concatenated with the hidden state of the decoder and passed to the softmax layer to produce the probability distribution over the vocabulary.\nThereby, our contributions are threefold. (1) We propose a novel emotion-tracking dialog generation model that learns the emotional interactions directly from the data. This approach is free of human-defined heuristic rules, and hence, is more robust and fundamental than those described in existing work [10, 11, 12]. (2) We apply the emotion-tracking mechanism to multi-turn dialogs, which has never been attempted before. Human evaluation shows that our model produces responses that are emotionally more appropriate than the baselines, while slightly improving the language fluency. (3) We illustrate a human-evaluation approach for judging machine-produced emotional dialogs. We consider factors such as the balance of positive and negative sentiments in test dialogs, a well-chosen range of topics, and dialogs that our human evaluators can relate. It is the first time such an approach is designed with consideration for the human judges. Our main goal is to increase the objectivity of the results and reduce judges’ mistakes due to out-of-context dialogs they have to evaluate.\nThe rest of the paper unfolds as follows. Section 2 discusses some related work. In Section 3, we give detailed description of the methodology. We present experimental results and some analysis in Section 4. The paper is concluded in Section 5, followed by some future work we plan to do."},{"header":"2 Related Work","body":"Many early open-domain dialog systems are rule-based and often require expert knowledge to develop. More recent work in response generation seeks data-driven solutions, leveraging on machine learning techniques and the availability of data. Ritter et al. [15] first applied statistical machine translation (SMT) methods to this area. However, it turns out that bilingual translation and response generation are different. The source and target sentences in translation share the same meaning; thus the words in the two sentences tend to align well with each other. However, for response generation, one could have many equally good responses for a single input. Later studies use the sequence-to-sequence neural framework to model dialogs, followed by various improving work on the quality of the responses, especially the emotional aspects of the conversations.\nThe vanilla RNN encoder-decoder is usually applied to single-turn response generation, where the response is generated based on one single input message. In multi-turn settings, where a context with multiple history utterances is given, the same structure often ignores the hierarchical characteristic of the context. Some recent work addresses this problem by adopting a hierarchical recurrent encoder-decoder (HRED) structure [16, 17, 18]. To give attention to different parts of the context while generating responses, Xing et al. [14] proposed the hierarchical recurrent attention network (HRAN) that uses a hierarchical attention mechanism. However, these multi-turn dialog models do not take into account the turn-taking emotional changes of the dialog.\nRecent work on incorporating affect information into natural language processing tasks, such as building emotional dialog systems and affect language models, has inspired our current work. For example, the Emotional Chatting Machine (ECM) [10] takes as input a post and a specified emotional category and generates a response that belongs to the pre-defined emotion category. The main idea is to use an internal memory module to capture the emotion dynamics during decoding, and an external memory module to model emotional expressions explicitly by assigning different probability values to emotional words as opposed to regular words. However, the problem setting requires an emotional label as an input, which might be unpractical in real scenarios. Asghar et al. [11] proposed to augment the word embeddings with a VAD (valence, arousal, and dominance) affective space by using an external dictionary, and designed three affect-related loss functions, namely minimizing affective dissonance, maximizing affective dissonance, and maximizing affective content. The paper also proposed the affectively diverse beam search during decoding, so that the generated candidate responses are as affectively diverse as possible. However, literature in affective science does not necessarily validate such rules. In fact, the best strategy to speak to an angry customer is the de-escalation strategy (using neutral words to validate anger) rather than employing equally emotional words (minimizing affect dissonance) or words that convey happiness (maximizing affect dissonance). Zhong et al. [12] proposed a biased attention mechanism on affect-rich words in the input message, also by taking advantage of the VAD embeddings. The model is trained with a weighted cross-entropy loss function, which encourages the generation of emotional words. However, these models only deal with single-turn conversations. More importantly, they all adopt hand-coded emotion responding mechanisms. To our knowledge, we are the first to consider modeling the emotional flow and its appropriateness in a multi-turn dialog system by learning from humans."},{"header":"3 Model","body":"In this paper, we consider the problem of generating response y given a context X consisting of multiple previous utterances by estimating the probability distribution p(y |X) from a data set D = {(X(i),y(i))}Ni=1 containing N context-response pairs. Here\nX(i) = ( x (i) 1 ,x (i) 2 , . . . ,x (i) mi )\n(1)\nis a sequence of mi utterances, and x (i) j = ( x (i) j,1, x (i) j,2, . . . , x (i) j,nij )\n(2)\nis a sequence of nij words. Similarly,\ny(i) = ( y (i) 1 , y (i) 2 , . . . , y (i) Ti )\n(3)\nis the response with Ti words.\nUsually the probability distribution p(y |X) can be modeled by an RNN language model conditioned on X . When generating the word yt at time step t, the context X is encoded into a fixed-sized dialog context vector ct by following the hierarchical attention structure in HRAN [14]. Additionally, we extract the emotion information from the utterances in X by leveraging an external text analysis program, and use an RNN to encode it into an emotion context vector e, which is combined with ct to produce the distribution. The overall architecture of the model is depicted in Figure 1. We are going to elaborate on how to obtain ct and e, and how they are combined in the decoding part."},{"header":"3.1 Hierarchical Attention","body":"The hierarchical attention structure involves two encoders to produce the dialog context vector ct, namely the wordlevel encoder and the utterance-level encoder. The word-level encoder is essentially a bidirectional RNN with gated recurrent units (GRU) [2]. For utterance xj in X (j = 1, 2, . . . ,m), the bidirectional encoder produces two hidden states at each word position k, the forward hidden state hfjk and the backward hidden state h b jk . The final hidden state hjk is then obtained by concatenating the two,\nhjk = concat ( hfjk ,h b jk ) . (4)\nThe utterance-level encoder is a unidirectional RNN with GRU that goes from the last utterance in the context to the first, with its input at each step as the summary of the corresponding utterance, which is obtained by applying a Bahdanau-style attention mechanism [5] on the word-level encoder output. More specifically, at decoding step t, the summary of utterance xj is a linear combination of hjk , for k = 1, 2, . . . , nj ,\nrtj =\nnj ∑\nk=1\nαtjkhjk. (5)\nHere αtjk is the word-level attention score placed on hjk , and can be calculated as\natjk = v T a tanh(Uast−1 + Vaℓ t j+1 +Wahjk), (6)\nαtjk = exp(atjk)\n∑nj k′=1 exp(a t jk′ )\n, (7)\nwhere st−1 is the previous hidden state of the decoder, ℓtj+1 is the previous hidden state of the utterance-level encoder, and va, Ua, Va and Wa are word-level attention parameters. The final dialog context vector ct is then obtained as another linear combination of the outputs of the utterance-level encoder ℓtj , for j = 1, 2, . . . ,m,\nct =\nm ∑\nj=1\nβtjℓ t j . (8)\nHere βtj is the utterance-level attention score placed on ℓ t j , and can be calculated as\nbtj = v T b tanh(Ubst−1 +Wbℓ t j), (9)\nβtj = exp(btj) ∑m\nj′=1 exp(b t j′)\n, (10)\nwhere st−1 is the previous hidden state of the decoder, and vb, Ub and Wb are utterance-level attention parameters."},{"header":"3.2 Emotion Encoder","body":"In order to capture the emotion information carried in the context X , we utilize an external text analysis program called the Linguistic Inquiry and Word Count (LIWC) [19]. LIWC accepts text files as input, and then compares each word in the input with a user-defined dictionary, assigning it to one or more of the pre-defined psychologically-relevant categories. We make use of five of these categories, related to emotion, namely positive emotion, negative emotion, anxious, angry, and sad. Using the newest version of the program LIWC2015,1 we are able to map each utterance xj in the context to a six-dimensional indicator vector 1(xj), with the first five entries corresponding to the five emotion categories, and the last one corresponding to neutral. If any word in xj belongs to one of the five categories, then the corresponding entry in 1(xj) is set to 1; otherwise, xj is treated as neutral, with the last entry of 1(xj) set to 1. For example, assuming xj = “he is worried about me”, then\n1(xj) = [0, 1, 1, 0, 0, 0], (11)\nsince the word “worried” is assigned to both negative emotion and anxious. We apply a dense layer with sigmoid activation function on top of 1(xj) to embed the emotion indicator vector into a continuous space,\naj = σ(We1(xj) + be), (12)\nwhere We and be are trainable parameters. The emotion flow of the context X is then modeled by an unidirectional RNN with GRU going from the first utterance in the context to the last, with its input being aj at each step. The final emotion context vector e is obtained as the last hidden state of this emotion encoding RNN."},{"header":"3.3 Decoding","body":"The probability distribution p(y |X) can be written as\np(y |X) = p(y1, y2, . . . , yT |X)\n= p(y1 | c1, e) T ∏\nt=2\np(yt | y1, . . . , yt−1, ct, e). (13)\n1https://liwc.wpengine.com/\nWe model the probability distribution using an RNN language model along with the emotion context vector e. Specifically, at time step t, the hidden state of the decoder st is obtained by applying the GRU function,\nst = GRU(st−1, concat(ct,wyt−1)), (14)\nwhere wyt−1 is the word embedding of yt−1. Similar to Affect-LM [20], we then define a new feature vector ot by concatenating st with the emotion context vector e,\not = concat(st, e), (15)\non which we apply a softmax layer to obtain a probability distribution over the vocabulary,\npt = softmax(ot). (16)\nEach term in Equation (13) is then given by\np(yt | y1, . . . , yt−1, ct, e) = pt,yt . (17)\nWe use the cross-entropy loss as our objective function\nL = − 1\n∑N\ni=1 Ti\nN ∑\ni=1\nlog p ( y(i) |X(i) ) . (18)"},{"header":"4 Evaluation","body":"We trained our model using two different datasets and compared its performance with HRAN as well as the basic sequence-to-sequence model by performing both offline and online testings."},{"header":"4.1 Datasets","body":"We use two different dialog corpora to train our model—the Cornell Movie Dialogs Corpus [21] and the DailyDialog dataset [22].\n• Cornell Movie Dialogs Corpus. The dataset contains 83,097 dialogs (220,579 conversational exchanges) extracted from raw movie scripts. In total there are 304,713 utterances.\n• DailyDialog. The dataset is developed by crawling raw data from websites used for language learners to learn English dialogs in daily life. It contains 13,118 dialogs in total.\nWe summarize some of the basic information regarding the two datasets in Table 1.\nIn our experiments, the models are first trained on the Cornell Movie Dialogs Corpus, and then fine-tuned on the DailyDialog dataset. We adopted this training pattern because the Cornell dataset is bigger but noisier, while DailyDialog is smaller but more daily-based. To create a training set and a validation set for each of the two datasets, we take segments of each dialog with number of turns no more than six, to serve as the training/validation examples. Specifically, for each dialog D = (x1,x2, . . . ,xM ), we create M − 1 context-response pairs, namely Ui = (xsi , . . . ,xi) and yi = xi+1, for i = 1, 2, . . . ,M−1, where si = max(1, i−4). We filter out those pairs that have at least one utterance with length greater than 30. We also reduce the frequency of those pairs whose responses appear too many times (the threshold is set to 10 for Cornell, and 5 for DailyDialog), to prevent them from dominating the learning procedure. See Table 1 for the sizes of the training and validation sets. The test set consists of 100 dialogs with four turns. We give more detailed description of how we create the test set in Section 4.3."},{"header":"4.2 Baselines and Implementation","body":"We compared our multi-turn emotionally engaging dialog model (denoted as MEED) with two baselines—the vanilla sequence-to-sequence model (denoted as S2S) and HRAN. We chose S2S and HRAN as baselines because we would like to evaluate our model’s capability to keep track of the multi-turn context and to produce emotionally more appropriate responses, respectively. In order to adapt S2S to the multi-turn setting, we concatenate all the history utterances in the context into one.\nFor all the models, the vocabulary consists of 20,000 most frequent words in the Cornell and DailyDialog datasets, plus three extra tokens: <unk> for words that do not exist in the vocabulary, <go> indicating the begin of an utterance, and <eos> indicating the end of an utterance. Here we summarize the configurations and parameters of our experiments:\n• We set the word embedding size to 256. We initialized the word embeddings in the models with word2vec [23] vectors first trained on Cornell and then fine-tuned on DailyDialog, consistent with the training procedure of the models.\n• We set the number of hidden units of each RNN to 256, the word-level attention depth to 256, and utterancelevel 128. The output size of the emotion embedding layer is 256.\n• We optimized the objective function using the Adam optimizer [24] with an initial learning rate of 0.001. We stopped training the models when the lowest perplexity on the validation sets was achieved.\n• For prediction, we used beam search [25] with a beam width of 256."},{"header":"4.3 Evaluation Metrics","body":"The evaluation of chatbots remains an open problem in the field. Recent work [26] has shown that the automatic evaluation metrics borrowed from machine translation such as BLEU score [27] tend to align poorly with human judgement. Therefore, in this paper, we mainly adopt human evaluation, along with perplexity, following the existing work."},{"header":"4.3.1 Human evaluation setup","body":"To develop a test set for human evaluation, we first selected the emotionally colored dialogs with exactly four turns from the DailyDialog dataset. In the dataset each dialog turn is annotated with a corresponding emotional category, including the neutral one. For our purposes we filtered out only those dialogs where more than a half of utterances have non-neutral emotional labels. This gave us 78 emotionally positive dialogs and 14 emotionally negative dialogs. In order to have a balanced test set with equal number of positive and negative dialogs, we recruited two English-speaking students from our university without any relationship to the authors’ lab and instructed them to create five negative dialogs with four turns, as if they were interacting with another human, according to each of the following topics: relationships, entertainment, service, work and study, and everyday situations. Thus each person produced 25 dialogs, and in total we obtained 50 emotionally negative daily dialogs in addition to the 14 already available. To form the test set, we randomly selected 50 emotionally positive and 50 emotionally negative dialogs from the two pools of dialogs described above (78 positive dialogs from DailyDialog, 64 negative dialogs from DailyDialog and human-generated).\nFor human evaluation of the models, we recruited another four English-speaking students from our university without any relationship to the authors’ lab to rate the responses generated by the models. Specifically, we randomly shuffled the 100 dialogs in the test set, then we used the first three utterances of each dialog as the input to the three models being compared and let them generate the responses. According to the context given, the raters were instructed to evaluate the quality of the responses based on three criteria: (1) grammatical correctness—whether or not the response is fluent and free of grammatical mistakes; (2) contextual coherence—whether or not the response is context sensitive to the previous dialog history; (3) emotional appropriateness—whether or not the response conveys the right emotion and feels as if it had been produced by a human. For each criterion, the raters gave scores of either 0, 1 or 2, where 0 means bad, 2 means good, and 1 indicates neutral."},{"header":"4.4 Results","body":"Table 2 gives the perplexity scores obtained by the three models on the two validation sets and the test set. As shown in the table, MEED achieves the lowest perplexity score on all three sets. We also conducted t-test on the perplexity obtained, and results show significant improvements (with p-value < 0.05).\nTable 3, 4 and 5 summarize the human evaluation results on the responses’ grammatical correctness, contextual coherence, and emotional appropriateness, respectively. In the tables, we give the percentage of votes each model received\nfor the three scores, the average score obtained with improvements over S2S, and the agreement score among the raters. Note that we report Fleiss’ κ score [28] for contextual coherence and emotional appropriateness, and Finn’s r score [29] for grammatical correctness. We did not use Fleiss’ κ score for grammatical correctness. As agreement is extremely high, this can make Fleiss’ κ very sensitive to prevalence [30]. On the contrary, we did not use Finn’s r score for contextual coherence and emotional appropriateness because it is only reasonable when the observed variance is significantly less than the chance variance [31], which did not apply to these two criteria. As shown in the tables, we got high agreement among the raters for grammatical correctness, and fair agreement among the raters for contextual coherence and emotional appropriateness.2 For grammatical correctness, all three models achieved high scores, which means all models are capable of generating fluent utterances that make sense. For contextual coherence and emotional appropriateness, MEED achieved higher average scores than S2S and HRAN, which means MEED keeps better track of the context and can generate responses that are emotionally more appropriate and natural. We conducted Friedman test [32] on the human evaluation results, showing the improvements of MEED are significant (with p-value < 0.01)."},{"header":"4.4.1 Case Study","body":"We present four sample dialogs in Table 6, along with the responses generated by the three models. Dialog 1 and 2 are emotionally positive and dialog 3 and 4 are negative. For the first two examples, we can see that MEED is able to generate more emotional content (like “fun” and “congratulations”) that is appropriate according to the context. For dialog 4, MEED responds in sympathy to the other speaker, which is consistent with the second utterance in the context. On the contrary, HRAN poses a question in reply, contradicting the dialog history."},{"header":"5 Conclusion and Future Work","body":"According to the Media Equation Theory [33], people respond to computers socially. This means humans expect talking to computers as they talk to other human beings. This is why we believe reproducing social and conversational intelligence will make social chatbots more believable and socially engaging. In this paper, we propose a multi-turn dialog system capable of generating emotionally appropriate responses, which is the first step toward such a goal. We have demonstrated how to do so by (1) modeling utterances with extra affect vectors, (2) creating an emotional encoding mechanism that learns emotion exchanges in the dataset, (3) curating a multi-turn dialog dataset, and (4) evaluating the model with offline and online experiments.\nAs future work, we would like to investigate the diversity issue of the responses generated, possibly by extending the mutual information objective function [6] to multi-turn settings. We would also like to evaluate our model on a larger dataset, for example by extracting multi-turn dialogs from the OpenSubtitles corpus [34].\n2https://en.wikipedia.org/wiki/Fleiss%27_kappa#Interpretation"}],"type":"Sections"}